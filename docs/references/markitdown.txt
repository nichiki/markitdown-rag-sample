├── .devcontainer
    └── devcontainer.json
├── .dockerignore
├── .gitattributes
├── .github
    ├── dependabot.yml
    └── workflows
    │   ├── pre-commit.yml
    │   └── tests.yml
├── .gitignore
├── .pre-commit-config.yaml
├── CODE_OF_CONDUCT.md
├── Dockerfile
├── LICENSE
├── README.md
├── SECURITY.md
├── SUPPORT.md
└── packages
    ├── markitdown-mcp
        ├── Dockerfile
        ├── README.md
        ├── pyproject.toml
        ├── src
        │   └── markitdown_mcp
        │   │   ├── __about__.py
        │   │   ├── __init__.py
        │   │   ├── __main__.py
        │   │   └── py.typed
        └── tests
        │   └── __init__.py
    ├── markitdown-sample-plugin
        ├── README.md
        ├── pyproject.toml
        ├── src
        │   └── markitdown_sample_plugin
        │   │   ├── __about__.py
        │   │   ├── __init__.py
        │   │   ├── _plugin.py
        │   │   └── py.typed
        └── tests
        │   ├── __init__.py
        │   ├── test_files
        │       └── test.rtf
        │   └── test_sample_plugin.py
    └── markitdown
        ├── README.md
        ├── ThirdPartyNotices.md
        ├── pyproject.toml
        ├── src
            └── markitdown
            │   ├── __about__.py
            │   ├── __init__.py
            │   ├── __main__.py
            │   ├── _base_converter.py
            │   ├── _exceptions.py
            │   ├── _markitdown.py
            │   ├── _stream_info.py
            │   ├── _uri_utils.py
            │   ├── converter_utils
            │       ├── __init__.py
            │       └── docx
            │       │   ├── __init__.py
            │       │   ├── math
            │       │       ├── __init__.py
            │       │       ├── latex_dict.py
            │       │       └── omml.py
            │       │   └── pre_process.py
            │   ├── converters
            │       ├── __init__.py
            │       ├── _audio_converter.py
            │       ├── _bing_serp_converter.py
            │       ├── _doc_intel_converter.py
            │       ├── _docx_converter.py
            │       ├── _epub_converter.py
            │       ├── _exiftool.py
            │       ├── _html_converter.py
            │       ├── _image_converter.py
            │       ├── _ipynb_converter.py
            │       ├── _llm_caption.py
            │       ├── _markdownify.py
            │       ├── _outlook_msg_converter.py
            │       ├── _pdf_converter.py
            │       ├── _plain_text_converter.py
            │       ├── _pptx_converter.py
            │       ├── _rss_converter.py
            │       ├── _transcribe_audio.py
            │       ├── _wikipedia_converter.py
            │       ├── _xlsx_converter.py
            │       ├── _youtube_converter.py
            │       └── _zip_converter.py
            │   └── py.typed
        └── tests
            ├── __init__.py
            ├── _test_vectors.py
            ├── test_cli_misc.py
            ├── test_cli_vectors.py
            ├── test_files
                ├── equations.docx
                ├── random.bin
                ├── test.docx
                ├── test.epub
                ├── test.jpg
                ├── test.json
                ├── test.m4a
                ├── test.mp3
                ├── test.pdf
                ├── test.pptx
                ├── test.wav
                ├── test.xls
                ├── test.xlsx
                ├── test_blog.html
                ├── test_files.zip
                ├── test_llm.jpg
                ├── test_mskanji.csv
                ├── test_notebook.ipynb
                ├── test_outlook_msg.msg
                ├── test_rss.xml
                ├── test_serp.html
                ├── test_wikipedia.html
                └── test_with_comment.docx
            ├── test_module_misc.py
            └── test_module_vectors.py


/.devcontainer/devcontainer.json:
--------------------------------------------------------------------------------
 1 | // For format details, see https://aka.ms/devcontainer.json. For config options, see the
 2 | // README at: https://github.com/devcontainers/templates/tree/main/src/docker-existing-dockerfile
 3 | {
 4 | 	"name": "Existing Dockerfile",
 5 | 	"build": {
 6 | 		// Sets the run context to one level up instead of the .devcontainer folder.
 7 | 		"context": "..",
 8 | 		// Update the 'dockerFile' property if you aren't using the standard 'Dockerfile' filename.
 9 | 		"dockerfile": "../Dockerfile",
10 | 		"args": {
11 | 			"INSTALL_GIT": "true"
12 | 		}
13 | 	},
14 | 
15 | 	// Features to add to the dev container. More info: https://containers.dev/features.
16 | 	// "features": {},
17 | 	"features": {
18 | 		"ghcr.io/devcontainers-extra/features/hatch:2": {}
19 | 	},
20 | 
21 | 	// Use 'forwardPorts' to make a list of ports inside the container available locally.
22 | 	// "forwardPorts": [],
23 | 
24 | 	// Uncomment the next line to run commands after the container is created.
25 | 	// "postCreateCommand": "cat /etc/os-release",
26 | 
27 | 	// Configure tool-specific properties.
28 | 	// "customizations": {},
29 | 
30 | 	// Uncomment to connect as an existing user other than the container default. More info: https://aka.ms/dev-containers-non-root.
31 | 	"remoteUser": "root"
32 | }
33 | 


--------------------------------------------------------------------------------
/.dockerignore:
--------------------------------------------------------------------------------
1 | *
2 | !packages/
3 | 


--------------------------------------------------------------------------------
/.gitattributes:
--------------------------------------------------------------------------------
1 | packages/markitdown/tests/test_files/** linguist-vendored
2 | packages/markitdown-sample-plugin/tests/test_files/** linguist-vendored
3 | 


--------------------------------------------------------------------------------
/.github/dependabot.yml:
--------------------------------------------------------------------------------
1 | version: 2
2 | updates:
3 |   - package-ecosystem: "github-actions"
4 |     directory: "/"
5 |     schedule:
6 |       interval: "weekly"
7 | 


--------------------------------------------------------------------------------
/.github/workflows/pre-commit.yml:
--------------------------------------------------------------------------------
 1 | name: pre-commit
 2 | on: [pull_request]
 3 | 
 4 | jobs:
 5 |   pre-commit:
 6 |     runs-on: ubuntu-latest
 7 |     steps:
 8 |       - uses: actions/checkout@v4
 9 |       - name: Set up Python
10 |         uses: actions/setup-python@v5
11 |         with:
12 |           python-version: "3.x"
13 | 
14 |       - name: Install pre-commit
15 |         run: |
16 |           pip install pre-commit
17 |           pre-commit install --install-hooks
18 | 
19 |       - name: Run pre-commit
20 |         run: pre-commit run --all-files
21 | 


--------------------------------------------------------------------------------
/.github/workflows/tests.yml:
--------------------------------------------------------------------------------
 1 | name: tests
 2 | on: [pull_request]
 3 | 
 4 | jobs:
 5 |   tests:
 6 |     runs-on: ubuntu-latest
 7 |     steps:
 8 |       - uses: actions/checkout@v4
 9 |       - uses: actions/setup-python@v5
10 |         with:
11 |           python-version: |
12 |             3.10
13 |             3.11
14 |             3.12
15 |       - name: Install Hatch
16 |         run: pipx install hatch
17 |       - name: Run tests
18 |         run: cd packages/markitdown; hatch test
19 | 


--------------------------------------------------------------------------------
/.gitignore:
--------------------------------------------------------------------------------
  1 | .vscode
  2 | 
  3 | # Byte-compiled / optimized / DLL files
  4 | __pycache__/
  5 | *.py[cod]
  6 | *$py.class
  7 | 
  8 | # C extensions
  9 | *.so
 10 | 
 11 | # Distribution / packaging
 12 | .Python
 13 | build/
 14 | develop-eggs/
 15 | dist/
 16 | downloads/
 17 | eggs/
 18 | .eggs/
 19 | lib/
 20 | lib64/
 21 | parts/
 22 | sdist/
 23 | var/
 24 | wheels/
 25 | share/python-wheels/
 26 | *.egg-info/
 27 | .installed.cfg
 28 | *.egg
 29 | MANIFEST
 30 | 
 31 | # PyInstaller
 32 | #  Usually these files are written by a python script from a template
 33 | #  before PyInstaller builds the exe, so as to inject date/other infos into it.
 34 | *.manifest
 35 | *.spec
 36 | 
 37 | # Installer logs
 38 | pip-log.txt
 39 | pip-delete-this-directory.txt
 40 | 
 41 | # Unit test / coverage reports
 42 | htmlcov/
 43 | .tox/
 44 | .nox/
 45 | .coverage
 46 | .coverage.*
 47 | .cache
 48 | nosetests.xml
 49 | coverage.xml
 50 | *.cover
 51 | *.py,cover
 52 | .hypothesis/
 53 | .pytest_cache/
 54 | cover/
 55 | 
 56 | # Translations
 57 | *.mo
 58 | *.pot
 59 | 
 60 | # Django stuff:
 61 | *.log
 62 | local_settings.py
 63 | db.sqlite3
 64 | db.sqlite3-journal
 65 | 
 66 | # Flask stuff:
 67 | instance/
 68 | .webassets-cache
 69 | 
 70 | # Scrapy stuff:
 71 | .scrapy
 72 | 
 73 | # Sphinx documentation
 74 | docs/_build/
 75 | 
 76 | # PyBuilder
 77 | .pybuilder/
 78 | target/
 79 | 
 80 | # Jupyter Notebook
 81 | .ipynb_checkpoints
 82 | 
 83 | # IPython
 84 | profile_default/
 85 | ipython_config.py
 86 | 
 87 | # pyenv
 88 | #   For a library or package, you might want to ignore these files since the code is
 89 | #   intended to run in multiple environments; otherwise, check them in:
 90 | # .python-version
 91 | 
 92 | # pipenv
 93 | #   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
 94 | #   However, in case of collaboration, if having platform-specific dependencies or dependencies
 95 | #   having no cross-platform support, pipenv may install dependencies that don't work, or not
 96 | #   install all needed dependencies.
 97 | #Pipfile.lock
 98 | 
 99 | # poetry
100 | #   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
101 | #   This is especially recommended for binary packages to ensure reproducibility, and is more
102 | #   commonly ignored for libraries.
103 | #   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
104 | #poetry.lock
105 | 
106 | # pdm
107 | #   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
108 | #pdm.lock
109 | #   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
110 | #   in version control.
111 | #   https://pdm.fming.dev/latest/usage/project/#working-with-version-control
112 | .pdm.toml
113 | .pdm-python
114 | .pdm-build/
115 | 
116 | # PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
117 | __pypackages__/
118 | 
119 | # Celery stuff
120 | celerybeat-schedule
121 | celerybeat.pid
122 | 
123 | # SageMath parsed files
124 | *.sage.py
125 | 
126 | # Environments
127 | .env
128 | .venv
129 | env/
130 | venv/
131 | ENV/
132 | env.bak/
133 | venv.bak/
134 | 
135 | # Spyder project settings
136 | .spyderproject
137 | .spyproject
138 | 
139 | # Rope project settings
140 | .ropeproject
141 | 
142 | # mkdocs documentation
143 | /site
144 | 
145 | # mypy
146 | .mypy_cache/
147 | .dmypy.json
148 | dmypy.json
149 | 
150 | # Pyre type checker
151 | .pyre/
152 | 
153 | # pytype static type analyzer
154 | .pytype/
155 | 
156 | # Cython debug symbols
157 | cython_debug/
158 | 
159 | # PyCharm
160 | #  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
161 | #  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
162 | #  and can be added to the global gitignore or merged into this file.  For a more nuclear
163 | #  option (not recommended) you can uncomment the following to ignore the entire idea folder.
164 | #.idea/
165 | src/.DS_Store
166 | .DS_Store
167 | 


--------------------------------------------------------------------------------
/.pre-commit-config.yaml:
--------------------------------------------------------------------------------
1 | repos:
2 |   - repo: https://github.com/psf/black
3 |     rev: 23.7.0 # Use the latest version of Black
4 |     hooks:
5 |       - id: black
6 | 


--------------------------------------------------------------------------------
/CODE_OF_CONDUCT.md:
--------------------------------------------------------------------------------
 1 | # Microsoft Open Source Code of Conduct
 2 | 
 3 | This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
 4 | 
 5 | Resources:
 6 | 
 7 | - [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/)
 8 | - [Microsoft Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/)
 9 | - Contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with questions or concerns
10 | 


--------------------------------------------------------------------------------
/Dockerfile:
--------------------------------------------------------------------------------
 1 | FROM python:3.13-slim-bullseye
 2 | 
 3 | ENV DEBIAN_FRONTEND=noninteractive
 4 | ENV EXIFTOOL_PATH=/usr/bin/exiftool
 5 | ENV FFMPEG_PATH=/usr/bin/ffmpeg
 6 | 
 7 | # Runtime dependency
 8 | RUN apt-get update && apt-get install -y --no-install-recommends \
 9 |     ffmpeg \
10 |     exiftool
11 | 
12 | ARG INSTALL_GIT=false
13 | RUN if [ "$INSTALL_GIT" = "true" ]; then \
14 |     apt-get install -y --no-install-recommends \
15 |     git; \
16 |     fi
17 | 
18 | # Cleanup
19 | RUN rm -rf /var/lib/apt/lists/*
20 | 
21 | WORKDIR /app
22 | COPY . /app
23 | RUN pip --no-cache-dir install \
24 |     /app/packages/markitdown[all] \
25 |     /app/packages/markitdown-sample-plugin
26 | 
27 | # Default USERID and GROUPID
28 | ARG USERID=nobody
29 | ARG GROUPID=nogroup
30 | 
31 | USER $USERID:$GROUPID
32 | 
33 | ENTRYPOINT [ "markitdown" ]
34 | 


--------------------------------------------------------------------------------
/LICENSE:
--------------------------------------------------------------------------------
 1 |     MIT License
 2 | 
 3 |     Copyright (c) Microsoft Corporation.
 4 | 
 5 |     Permission is hereby granted, free of charge, to any person obtaining a copy
 6 |     of this software and associated documentation files (the "Software"), to deal
 7 |     in the Software without restriction, including without limitation the rights
 8 |     to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 9 |     copies of the Software, and to permit persons to whom the Software is
10 |     furnished to do so, subject to the following conditions:
11 | 
12 |     The above copyright notice and this permission notice shall be included in all
13 |     copies or substantial portions of the Software.
14 | 
15 |     THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
16 |     IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
17 |     FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
18 |     AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
19 |     LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
20 |     OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
21 |     SOFTWARE
22 | 


--------------------------------------------------------------------------------
/README.md:
--------------------------------------------------------------------------------
  1 | # MarkItDown
  2 | 
  3 | [![PyPI](https://img.shields.io/pypi/v/markitdown.svg)](https://pypi.org/project/markitdown/)
  4 | ![PyPI - Downloads](https://img.shields.io/pypi/dd/markitdown)
  5 | [![Built by AutoGen Team](https://img.shields.io/badge/Built%20by-AutoGen%20Team-blue)](https://github.com/microsoft/autogen)
  6 | 
  7 | > [!TIP]
  8 | > MarkItDown now offers an MCP (Model Context Protocol) server for integration with LLM applications like Claude Desktop. See [markitdown-mcp](https://github.com/microsoft/markitdown/tree/main/packages/markitdown-mcp) for more information.
  9 | 
 10 | > [!IMPORTANT]
 11 | > Breaking changes between 0.0.1 to 0.1.0:
 12 | > * Dependencies are now organized into optional feature-groups (further details below). Use `pip install 'markitdown[all]'` to have backward-compatible behavior. 
 13 | > * convert\_stream() now requires a binary file-like object (e.g., a file opened in binary mode, or an io.BytesIO object). This is a breaking change from the previous version, where it previously also accepted text file-like objects, like io.StringIO.
 14 | > * The DocumentConverter class interface has changed to read from file-like streams rather than file paths. *No temporary files are created anymore*. If you are the maintainer of a plugin, or custom DocumentConverter, you likely need to update your code. Otherwise, if only using the MarkItDown class or CLI (as in these examples), you should not need to change anything.
 15 | 
 16 | MarkItDown is a lightweight Python utility for converting various files to Markdown for use with LLMs and related text analysis pipelines. To this end, it is most comparable to [textract](https://github.com/deanmalmgren/textract), but with a focus on preserving important document structure and content as Markdown (including: headings, lists, tables, links, etc.) While the output is often reasonably presentable and human-friendly, it is meant to be consumed by text analysis tools -- and may not be the best option for high-fidelity document conversions for human consumption.
 17 | 
 18 | At present, MarkItDown supports:
 19 | 
 20 | - PDF
 21 | - PowerPoint
 22 | - Word
 23 | - Excel
 24 | - Images (EXIF metadata and OCR)
 25 | - Audio (EXIF metadata and speech transcription)
 26 | - HTML
 27 | - Text-based formats (CSV, JSON, XML)
 28 | - ZIP files (iterates over contents)
 29 | - Youtube URLs
 30 | - EPubs
 31 | - ... and more!
 32 | 
 33 | ## Why Markdown?
 34 | 
 35 | Markdown is extremely close to plain text, with minimal markup or formatting, but still
 36 | provides a way to represent important document structure. Mainstream LLMs, such as
 37 | OpenAI's GPT-4o, natively "_speak_" Markdown, and often incorporate Markdown into their
 38 | responses unprompted. This suggests that they have been trained on vast amounts of
 39 | Markdown-formatted text, and understand it well. As a side benefit, Markdown conventions
 40 | are also highly token-efficient.
 41 | 
 42 | ## Installation
 43 | 
 44 | To install MarkItDown, use pip: `pip install 'markitdown[all]'`. Alternatively, you can install it from the source:
 45 | 
 46 | ```bash
 47 | git clone git@github.com:microsoft/markitdown.git
 48 | cd markitdown
 49 | pip install -e packages/markitdown[all]
 50 | ```
 51 | 
 52 | ## Usage
 53 | 
 54 | ### Command-Line
 55 | 
 56 | ```bash
 57 | markitdown path-to-file.pdf > document.md
 58 | ```
 59 | 
 60 | Or use `-o` to specify the output file:
 61 | 
 62 | ```bash
 63 | markitdown path-to-file.pdf -o document.md
 64 | ```
 65 | 
 66 | You can also pipe content:
 67 | 
 68 | ```bash
 69 | cat path-to-file.pdf | markitdown
 70 | ```
 71 | 
 72 | ### Optional Dependencies
 73 | MarkItDown has optional dependencies for activating various file formats. Earlier in this document, we installed all optional dependencies with the `[all]` option. However, you can also install them individually for more control. For example:
 74 | 
 75 | ```bash
 76 | pip install markitdown[pdf, docx, pptx]
 77 | ```
 78 | 
 79 | will install only the dependencies for PDF, DOCX, and PPTX files.
 80 | 
 81 | At the moment, the following optional dependencies are available:
 82 | 
 83 | * `[all]` Installs all optional dependencies
 84 | * `[pptx]` Installs dependencies for PowerPoint files
 85 | * `[docx]` Installs dependencies for Word files
 86 | * `[xlsx]` Installs dependencies for Excel files
 87 | * `[xls]` Installs dependencies for older Excel files
 88 | * `[pdf]` Installs dependencies for PDF files
 89 | * `[outlook]` Installs dependencies for Outlook messages
 90 | * `[az-doc-intel]` Installs dependencies for Azure Document Intelligence
 91 | * `[audio-transcription]` Installs dependencies for audio transcription of wav and mp3 files
 92 | * `[youtube-transcription]` Installs dependencies for fetching YouTube video transcription
 93 | 
 94 | ### Plugins
 95 | 
 96 | MarkItDown also supports 3rd-party plugins. Plugins are disabled by default. To list installed plugins:
 97 | 
 98 | ```bash
 99 | markitdown --list-plugins
100 | ```
101 | 
102 | To enable plugins use:
103 | 
104 | ```bash
105 | markitdown --use-plugins path-to-file.pdf
106 | ```
107 | 
108 | To find available plugins, search GitHub for the hashtag `#markitdown-plugin`. To develop a plugin, see `packages/markitdown-sample-plugin`.
109 | 
110 | ### Azure Document Intelligence
111 | 
112 | To use Microsoft Document Intelligence for conversion:
113 | 
114 | ```bash
115 | markitdown path-to-file.pdf -o document.md -d -e "<document_intelligence_endpoint>"
116 | ```
117 | 
118 | More information about how to set up an Azure Document Intelligence Resource can be found [here](https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/how-to-guides/create-document-intelligence-resource?view=doc-intel-4.0.0)
119 | 
120 | ### Python API
121 | 
122 | Basic usage in Python:
123 | 
124 | ```python
125 | from markitdown import MarkItDown
126 | 
127 | md = MarkItDown(enable_plugins=False) # Set to True to enable plugins
128 | result = md.convert("test.xlsx")
129 | print(result.text_content)
130 | ```
131 | 
132 | Document Intelligence conversion in Python:
133 | 
134 | ```python
135 | from markitdown import MarkItDown
136 | 
137 | md = MarkItDown(docintel_endpoint="<document_intelligence_endpoint>")
138 | result = md.convert("test.pdf")
139 | print(result.text_content)
140 | ```
141 | 
142 | To use Large Language Models for image descriptions, provide `llm_client` and `llm_model`:
143 | 
144 | ```python
145 | from markitdown import MarkItDown
146 | from openai import OpenAI
147 | 
148 | client = OpenAI()
149 | md = MarkItDown(llm_client=client, llm_model="gpt-4o")
150 | result = md.convert("example.jpg")
151 | print(result.text_content)
152 | ```
153 | 
154 | ### Docker
155 | 
156 | ```sh
157 | docker build -t markitdown:latest .
158 | docker run --rm -i markitdown:latest < ~/your-file.pdf > output.md
159 | ```
160 | 
161 | ## Contributing
162 | 
163 | This project welcomes contributions and suggestions. Most contributions require you to agree to a
164 | Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us
165 | the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.
166 | 
167 | When you submit a pull request, a CLA bot will automatically determine whether you need to provide
168 | a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions
169 | provided by the bot. You will only need to do this once across all repos using our CLA.
170 | 
171 | This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
172 | For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or
173 | contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.
174 | 
175 | ### How to Contribute
176 | 
177 | You can help by looking at issues or helping review PRs. Any issue or PR is welcome, but we have also marked some as 'open for contribution' and 'open for reviewing' to help facilitate community contributions. These are ofcourse just suggestions and you are welcome to contribute in any way you like.
178 | 
179 | <div align="center">
180 | 
181 | |            | All                                                          | Especially Needs Help from Community                                                                                                      |
182 | | ---------- | ------------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------- |
183 | | **Issues** | [All Issues](https://github.com/microsoft/markitdown/issues) | [Issues open for contribution](https://github.com/microsoft/markitdown/issues?q=is%3Aissue+is%3Aopen+label%3A%22open+for+contribution%22) |
184 | | **PRs**    | [All PRs](https://github.com/microsoft/markitdown/pulls)     | [PRs open for reviewing](https://github.com/microsoft/markitdown/pulls?q=is%3Apr+is%3Aopen+label%3A%22open+for+reviewing%22)              |
185 | 
186 | </div>
187 | 
188 | ### Running Tests and Checks
189 | 
190 | - Navigate to the MarkItDown package:
191 | 
192 |   ```sh
193 |   cd packages/markitdown
194 |   ```
195 | 
196 | - Install `hatch` in your environment and run tests:
197 | 
198 |   ```sh
199 |   pip install hatch  # Other ways of installing hatch: https://hatch.pypa.io/dev/install/
200 |   hatch shell
201 |   hatch test
202 |   ```
203 | 
204 |   (Alternative) Use the Devcontainer which has all the dependencies installed:
205 | 
206 |   ```sh
207 |   # Reopen the project in Devcontainer and run:
208 |   hatch test
209 |   ```
210 | 
211 | - Run pre-commit checks before submitting a PR: `pre-commit run --all-files`
212 | 
213 | ### Contributing 3rd-party Plugins
214 | 
215 | You can also contribute by creating and sharing 3rd party plugins. See `packages/markitdown-sample-plugin` for more details.
216 | 
217 | ## Trademarks
218 | 
219 | This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft
220 | trademarks or logos is subject to and must follow
221 | [Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).
222 | Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.
223 | Any use of third-party trademarks or logos are subject to those third-party's policies.
224 | 


--------------------------------------------------------------------------------
/SECURITY.md:
--------------------------------------------------------------------------------
 1 | <!-- BEGIN MICROSOFT SECURITY.MD V0.0.9 BLOCK -->
 2 | 
 3 | ## Security
 4 | 
 5 | Microsoft takes the security of our software products and services seriously, which includes all source code repositories managed through our GitHub organizations, which include [Microsoft](https://github.com/Microsoft), [Azure](https://github.com/Azure), [DotNet](https://github.com/dotnet), [AspNet](https://github.com/aspnet) and [Xamarin](https://github.com/xamarin).
 6 | 
 7 | If you believe you have found a security vulnerability in any Microsoft-owned repository that meets [Microsoft's definition of a security vulnerability](https://aka.ms/security.md/definition), please report it to us as described below.
 8 | 
 9 | ## Reporting Security Issues
10 | 
11 | **Please do not report security vulnerabilities through public GitHub issues.**
12 | 
13 | Instead, please report them to the Microsoft Security Response Center (MSRC) at [https://msrc.microsoft.com/create-report](https://aka.ms/security.md/msrc/create-report).
14 | 
15 | If you prefer to submit without logging in, send email to [secure@microsoft.com](mailto:secure@microsoft.com).  If possible, encrypt your message with our PGP key; please download it from the [Microsoft Security Response Center PGP Key page](https://aka.ms/security.md/msrc/pgp).
16 | 
17 | You should receive a response within 24 hours. If for some reason you do not, please follow up via email to ensure we received your original message. Additional information can be found at [microsoft.com/msrc](https://www.microsoft.com/msrc). 
18 | 
19 | Please include the requested information listed below (as much as you can provide) to help us better understand the nature and scope of the possible issue:
20 | 
21 |   * Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.)
22 |   * Full paths of source file(s) related to the manifestation of the issue
23 |   * The location of the affected source code (tag/branch/commit or direct URL)
24 |   * Any special configuration required to reproduce the issue
25 |   * Step-by-step instructions to reproduce the issue
26 |   * Proof-of-concept or exploit code (if possible)
27 |   * Impact of the issue, including how an attacker might exploit the issue
28 | 
29 | This information will help us triage your report more quickly.
30 | 
31 | If you are reporting for a bug bounty, more complete reports can contribute to a higher bounty award. Please visit our [Microsoft Bug Bounty Program](https://aka.ms/security.md/msrc/bounty) page for more details about our active programs.
32 | 
33 | ## Preferred Languages
34 | 
35 | We prefer all communications to be in English.
36 | 
37 | ## Policy
38 | 
39 | Microsoft follows the principle of [Coordinated Vulnerability Disclosure](https://aka.ms/security.md/cvd).
40 | 
41 | <!-- END MICROSOFT SECURITY.MD BLOCK -->
42 | 


--------------------------------------------------------------------------------
/SUPPORT.md:
--------------------------------------------------------------------------------
 1 | # TODO: The maintainer of this repo has not yet edited this file
 2 | 
 3 | **REPO OWNER**: Do you want Customer Service & Support (CSS) support for this product/project?
 4 | 
 5 | - **No CSS support:** Fill out this template with information about how to file issues and get help.
 6 | - **Yes CSS support:** Fill out an intake form at [aka.ms/onboardsupport](https://aka.ms/onboardsupport). CSS will work with/help you to determine next steps.
 7 | - **Not sure?** Fill out an intake as though the answer were "Yes". CSS will help you decide.
 8 | 
 9 | *Then remove this first heading from this SUPPORT.MD file before publishing your repo.*
10 | 
11 | # Support
12 | 
13 | ## How to file issues and get help  
14 | 
15 | This project uses GitHub Issues to track bugs and feature requests. Please search the existing 
16 | issues before filing new issues to avoid duplicates.  For new issues, file your bug or 
17 | feature request as a new Issue.
18 | 
19 | For help and questions about using this project, please **REPO MAINTAINER: INSERT INSTRUCTIONS HERE 
20 | FOR HOW TO ENGAGE REPO OWNERS OR COMMUNITY FOR HELP. COULD BE A STACK OVERFLOW TAG OR OTHER
21 | CHANNEL. WHERE WILL YOU HELP PEOPLE?**.
22 | 
23 | ## Microsoft Support Policy  
24 | 
25 | Support for this **PROJECT or PRODUCT** is limited to the resources listed above.
26 | 


--------------------------------------------------------------------------------
/packages/markitdown-mcp/Dockerfile:
--------------------------------------------------------------------------------
 1 | FROM python:3.13-slim-bullseye
 2 | 
 3 | ENV DEBIAN_FRONTEND=noninteractive
 4 | ENV EXIFTOOL_PATH=/usr/bin/exiftool
 5 | ENV FFMPEG_PATH=/usr/bin/ffmpeg
 6 | 
 7 | # Runtime dependency
 8 | RUN apt-get update && apt-get install -y --no-install-recommends \
 9 |     ffmpeg \
10 |     exiftool
11 | 
12 | # Cleanup
13 | RUN rm -rf /var/lib/apt/lists/*
14 | 
15 | COPY . /app
16 | RUN pip --no-cache-dir install /app
17 | 
18 | WORKDIR /workdir
19 | 
20 | # Default USERID and GROUPID
21 | ARG USERID=nobody
22 | ARG GROUPID=nogroup
23 | 
24 | USER $USERID:$GROUPID
25 | 
26 | ENTRYPOINT [ "markitdown-mcp" ]
27 | 


--------------------------------------------------------------------------------
/packages/markitdown-mcp/README.md:
--------------------------------------------------------------------------------
  1 | # MarkItDown-MCP
  2 | 
  3 | [![PyPI](https://img.shields.io/pypi/v/markitdown-mcp.svg)](https://pypi.org/project/markitdown-mcp/)
  4 | ![PyPI - Downloads](https://img.shields.io/pypi/dd/markitdown-mcp)
  5 | [![Built by AutoGen Team](https://img.shields.io/badge/Built%20by-AutoGen%20Team-blue)](https://github.com/microsoft/autogen)
  6 | 
  7 | The `markitdown-mcp` package provides a lightweight STDIO and SSE MCP server for calling MarkItDown.
  8 | 
  9 | It exposes one tool: `convert_to_markdown(uri)`, where uri can be any `http:`, `https:`, `file:`, or `data:` URI.
 10 | 
 11 | ## Installation
 12 | 
 13 | To install the package, use pip:
 14 | 
 15 | ```bash
 16 | pip install markitdown-mcp
 17 | ```
 18 | 
 19 | ## Usage
 20 | 
 21 | To run the MCP server, ussing STDIO (default) use the following command:
 22 | 
 23 | 
 24 | ```bash	
 25 | markitdown-mcp
 26 | ```
 27 | 
 28 | To run the MCP server, ussing SSE use the following command:
 29 | 
 30 | ```bash	
 31 | markitdown-mcp --sse --host 127.0.0.1 --port 3001
 32 | ```
 33 | 
 34 | ## Running in Docker
 35 | 
 36 | To run `markitdown-mcp` in Docker, build the Docker image using the provided Dockerfile:
 37 | ```bash
 38 | docker build -t markitdown-mcp:latest .
 39 | ```
 40 | 
 41 | And run it using:
 42 | ```bash
 43 | docker run -it --rm markitdown-mcp:latest
 44 | ```
 45 | This will be sufficient for remote URIs. To access local files, you need to mount the local directory into the container. For example, if you want to access files in `/home/user/data`, you can run:
 46 | 
 47 | ```bash
 48 | docker run -it --rm -v /home/user/data:/workdir markitdown-mcp:latest
 49 | ```
 50 | 
 51 | Once mounted, all files under data will be accessible under `/workdir` in the container. For example, if you have a file `example.txt` in `/home/user/data`, it will be accessible in the container at `/workdir/example.txt`.
 52 | 
 53 | ## Accessing from Claude Desktop
 54 | 
 55 | It is recommended to use the Docker image when running the MCP server for Claude Desktop.
 56 | 
 57 | Follow [these instrutions](https://modelcontextprotocol.io/quickstart/user#for-claude-desktop-users) to access Claude's `claude_desktop_config.json` file.
 58 | 
 59 | Edit it to include the following JSON entry:
 60 | 
 61 | ```json
 62 | {
 63 |   "mcpServers": {
 64 |     "markitdown": {
 65 |       "command": "docker",
 66 |       "args": [
 67 |         "run",
 68 |         "--rm",
 69 |         "-i",
 70 |         "markitdown-mcp:latest"
 71 |       ]
 72 |     }
 73 |   }
 74 | }
 75 | ```
 76 | 
 77 | If you want to mount a directory, adjust it accordingly:
 78 | 
 79 | ```json
 80 | {
 81 |   "mcpServers": {
 82 |     "markitdown": {
 83 |       "command": "docker",
 84 |       "args": [
 85 | 	"run",
 86 | 	"--rm",
 87 | 	"-i",
 88 | 	"-v",
 89 | 	"/home/user/data:/workdir",
 90 | 	"markitdown-mcp:latest"
 91 |       ]
 92 |     }
 93 |   }
 94 | }
 95 | ```
 96 | 
 97 | ## Debugging
 98 | 
 99 | To debug the MCP server you can use the `mcpinspector` tool.
100 | 
101 | ```bash
102 | npx @modelcontextprotocol/inspector
103 | ```
104 | 
105 | You can then connect to the insepctor through the specified host and port (e.g., `http://localhost:5173/`).
106 | 
107 | If using STDIO:
108 | * select `STDIO` as the transport type,
109 | * input `markitdown-mcp` as the command, and
110 | * click `Connect`
111 | 
112 | If using SSE:
113 | * select `SSE` as the transport type,
114 | * input `http://127.0.0.1:3001/sse` as the URL, and
115 | * click `Connect`
116 | 
117 | Finally:
118 | * click the `Tools` tab,
119 | * click `List Tools`,
120 | * click `convert_to_markdown`, and
121 | * run the tool on any valid URI.
122 | 
123 | ## Security Considerations
124 | 
125 | The server does not support authentication, and runs with the privileges if the user running it. For this reason, when running in SSE mode, it is recommended to run the server bound to `localhost` (default).
126 | 
127 | 
128 | ## Trademarks
129 | 
130 | This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft
131 | trademarks or logos is subject to and must follow
132 | [Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).
133 | Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.
134 | Any use of third-party trademarks or logos are subject to those third-party's policies.
135 | 


--------------------------------------------------------------------------------
/packages/markitdown-mcp/pyproject.toml:
--------------------------------------------------------------------------------
 1 | [build-system]
 2 | requires = ["hatchling"]
 3 | build-backend = "hatchling.build"
 4 | 
 5 | [project]
 6 | name = "markitdown-mcp"
 7 | dynamic = ["version"]
 8 | description = 'An MCP server for the "markitdown" library.'
 9 | readme = "README.md"
10 | requires-python = ">=3.10"
11 | license = "MIT"
12 | keywords = []
13 | authors = [
14 |   { name = "Adam Fourney", email = "adamfo@microsoft.com" },
15 | ]
16 | classifiers = [
17 |   "Development Status :: 4 - Beta",
18 |   "Programming Language :: Python",
19 |   "Programming Language :: Python :: 3.10",
20 |   "Programming Language :: Python :: 3.11",
21 |   "Programming Language :: Python :: 3.12",
22 |   "Programming Language :: Python :: 3.13",
23 |   "Programming Language :: Python :: Implementation :: CPython",
24 |   "Programming Language :: Python :: Implementation :: PyPy",
25 | ]
26 | dependencies = [
27 |   "mcp~=1.5.0",
28 |   "markitdown[all]>=0.1.1,<0.2.0",
29 | ]
30 | 
31 | [project.urls]
32 | Documentation = "https://github.com/microsoft/markitdown#readme"
33 | Issues = "https://github.com/microsoft/markitdown/issues"
34 | Source = "https://github.com/microsoft/markitdown"
35 | 
36 | [tool.hatch.version]
37 | path = "src/markitdown_mcp/__about__.py"
38 | 
39 | [project.scripts]
40 | markitdown-mcp = "markitdown_mcp.__main__:main"
41 | 
42 | [tool.hatch.envs.types]
43 | extra-dependencies = [
44 |   "mypy>=1.0.0",
45 | ]
46 | [tool.hatch.envs.types.scripts]
47 | check = "mypy --install-types --non-interactive {args:src/markitdown_mcp tests}"
48 | 
49 | [tool.coverage.run]
50 | source_pkgs = ["markitdown-mcp", "tests"]
51 | branch = true
52 | parallel = true
53 | omit = [
54 |   "src/markitdown_mcp/__about__.py",
55 | ]
56 | 
57 | [tool.coverage.paths]
58 | markitdown-mcp = ["src/markitdown_mcp", "*/markitdown-mcp/src/markitdown_mcp"]
59 | tests = ["tests", "*/markitdown-mcp/tests"]
60 | 
61 | [tool.coverage.report]
62 | exclude_lines = [
63 |   "no cov",
64 |   "if __name__ == .__main__.:",
65 |   "if TYPE_CHECKING:",
66 | ]
67 | 
68 | [tool.hatch.build.targets.sdist]
69 | only-include = ["src/markitdown_mcp"]
70 | 


--------------------------------------------------------------------------------
/packages/markitdown-mcp/src/markitdown_mcp/__about__.py:
--------------------------------------------------------------------------------
1 | # SPDX-FileCopyrightText: 2024-present Adam Fourney <adamfo@microsoft.com>
2 | #
3 | # SPDX-License-Identifier: MIT
4 | __version__ = "0.0.1a3"
5 | 


--------------------------------------------------------------------------------
/packages/markitdown-mcp/src/markitdown_mcp/__init__.py:
--------------------------------------------------------------------------------
 1 | # SPDX-FileCopyrightText: 2024-present Adam Fourney <adamfo@microsoft.com>
 2 | #
 3 | # SPDX-License-Identifier: MIT
 4 | 
 5 | from .__about__ import __version__
 6 | 
 7 | __all__ = [
 8 |     "__version__",
 9 | ]
10 | 


--------------------------------------------------------------------------------
/packages/markitdown-mcp/src/markitdown_mcp/__main__.py:
--------------------------------------------------------------------------------
 1 | import sys
 2 | from typing import Any
 3 | from mcp.server.fastmcp import FastMCP
 4 | from starlette.applications import Starlette
 5 | from mcp.server.sse import SseServerTransport
 6 | from starlette.requests import Request
 7 | from starlette.routing import Mount, Route
 8 | from mcp.server import Server
 9 | from markitdown import MarkItDown
10 | import uvicorn
11 | 
12 | # Initialize FastMCP server for MarkItDown (SSE)
13 | mcp = FastMCP("markitdown")
14 | 
15 | 
16 | @mcp.tool()
17 | async def convert_to_markdown(uri: str) -> str:
18 |     """Convert a resource described by an http:, https:, file: or data: URI to markdown"""
19 |     return MarkItDown().convert_uri(uri).markdown
20 | 
21 | 
22 | def create_starlette_app(mcp_server: Server, *, debug: bool = False) -> Starlette:
23 |     sse = SseServerTransport("/messages/")
24 | 
25 |     async def handle_sse(request: Request) -> None:
26 |         async with sse.connect_sse(
27 |             request.scope,
28 |             request.receive,
29 |             request._send,
30 |         ) as (read_stream, write_stream):
31 |             await mcp_server.run(
32 |                 read_stream,
33 |                 write_stream,
34 |                 mcp_server.create_initialization_options(),
35 |             )
36 | 
37 |     return Starlette(
38 |         debug=debug,
39 |         routes=[
40 |             Route("/sse", endpoint=handle_sse),
41 |             Mount("/messages/", app=sse.handle_post_message),
42 |         ],
43 |     )
44 | 
45 | 
46 | # Main entry point
47 | def main():
48 |     import argparse
49 | 
50 |     mcp_server = mcp._mcp_server
51 | 
52 |     parser = argparse.ArgumentParser(description="Run MCP SSE-based MarkItDown server")
53 | 
54 |     parser.add_argument(
55 |         "--sse",
56 |         action="store_true",
57 |         help="Run the server with SSE transport rather than STDIO (default: False)",
58 |     )
59 |     parser.add_argument(
60 |         "--host", default=None, help="Host to bind to (default: 127.0.0.1)"
61 |     )
62 |     parser.add_argument(
63 |         "--port", type=int, default=None, help="Port to listen on (default: 3001)"
64 |     )
65 |     args = parser.parse_args()
66 | 
67 |     if not args.sse and (args.host or args.port):
68 |         parser.error("Host and port arguments are only valid when using SSE transport.")
69 |         sys.exit(1)
70 | 
71 |     if args.sse:
72 |         starlette_app = create_starlette_app(mcp_server, debug=True)
73 |         uvicorn.run(
74 |             starlette_app,
75 |             host=args.host if args.host else "127.0.0.1",
76 |             port=args.port if args.port else 3001,
77 |         )
78 |     else:
79 |         mcp.run()
80 | 
81 | 
82 | if __name__ == "__main__":
83 |     main()
84 | 


--------------------------------------------------------------------------------
/packages/markitdown-mcp/src/markitdown_mcp/py.typed:
--------------------------------------------------------------------------------
https://raw.githubusercontent.com/microsoft/markitdown/3fcd48cdfc651cbf508071c8d2fb7d82aeb075de/packages/markitdown-mcp/src/markitdown_mcp/py.typed


--------------------------------------------------------------------------------
/packages/markitdown-mcp/tests/__init__.py:
--------------------------------------------------------------------------------
1 | # SPDX-FileCopyrightText: 2024-present Adam Fourney <adamfo@microsoft.com>
2 | #
3 | # SPDX-License-Identifier: MIT
4 | 


--------------------------------------------------------------------------------
/packages/markitdown-sample-plugin/README.md:
--------------------------------------------------------------------------------
  1 | # MarkItDown Sample Plugin
  2 | 
  3 | [![PyPI](https://img.shields.io/pypi/v/markitdown-sample-plugin.svg)](https://pypi.org/project/markitdown-sample-plugin/)
  4 | ![PyPI - Downloads](https://img.shields.io/pypi/dd/markitdown-sample-plugin)
  5 | [![Built by AutoGen Team](https://img.shields.io/badge/Built%20by-AutoGen%20Team-blue)](https://github.com/microsoft/autogen)
  6 | 
  7 | 
  8 | This project shows how to create a sample plugin for MarkItDown. The most important parts are as follows:
  9 | 
 10 | Next, implement your custom DocumentConverter:
 11 | 
 12 | ```python
 13 | from typing import BinaryIO, Any
 14 | from markitdown import MarkItDown, DocumentConverter, DocumentConverterResult, StreamInfo
 15 | 
 16 | class RtfConverter(DocumentConverter):
 17 | 
 18 |     def __init__(
 19 |         self, priority: float = DocumentConverter.PRIORITY_SPECIFIC_FILE_FORMAT
 20 |     ):
 21 |         super().__init__(priority=priority)
 22 | 
 23 |     def accepts(
 24 |         self,
 25 |         file_stream: BinaryIO,
 26 |         stream_info: StreamInfo,
 27 |         **kwargs: Any,
 28 |     ) -> bool:
 29 | 	
 30 | 	# Implement logic to check if the file stream is an RTF file
 31 | 	# ...
 32 | 	raise NotImplementedError()
 33 | 
 34 | 
 35 |     def convert(
 36 |         self,
 37 |         file_stream: BinaryIO,
 38 |         stream_info: StreamInfo,
 39 |         **kwargs: Any,
 40 |     ) -> DocumentConverterResult:
 41 | 
 42 | 	# Implement logic to convert the file stream to Markdown
 43 | 	# ...
 44 | 	raise NotImplementedError()
 45 | ```
 46 | 
 47 | Next, make sure your package implements and exports the following:
 48 | 
 49 | ```python
 50 | # The version of the plugin interface that this plugin uses. 
 51 | # The only supported version is 1 for now.
 52 | __plugin_interface_version__ = 1 
 53 | 
 54 | # The main entrypoint for the plugin. This is called each time MarkItDown instances are created.
 55 | def register_converters(markitdown: MarkItDown, **kwargs):
 56 |     """
 57 |     Called during construction of MarkItDown instances to register converters provided by plugins.
 58 |     """
 59 | 
 60 |     # Simply create and attach an RtfConverter instance
 61 |     markitdown.register_converter(RtfConverter())
 62 | ```
 63 | 
 64 | 
 65 | Finally, create an entrypoint in the `pyproject.toml` file:
 66 | 
 67 | ```toml
 68 | [project.entry-points."markitdown.plugin"]
 69 | sample_plugin = "markitdown_sample_plugin"
 70 | ```
 71 | 
 72 | Here, the value of `sample_plugin` can be any key, but should ideally be the name of the plugin. The value is the fully qualified name of the package implementing the plugin.
 73 | 
 74 | 
 75 | ## Installation
 76 | 
 77 | To use the plugin with MarkItDown, it must be installed. To install the plugin from the current directory use:
 78 | 
 79 | ```bash
 80 | pip install -e .
 81 | ```
 82 | 
 83 | Once the plugin package is installed, verify that it is available to MarkItDown by running:
 84 | 
 85 | ```bash
 86 | markitdown --list-plugins
 87 | ```
 88 | 
 89 | To use the plugin for a conversion use the `--use-plugins` flag. For example, to convert an RTF file:
 90 | 
 91 | ```bash
 92 | markitdown --use-plugins path-to-file.rtf
 93 | ```
 94 | 
 95 | In Python, plugins can be enabled as follows:
 96 | 
 97 | ```python
 98 | from markitdown import MarkItDown
 99 | 
100 | md = MarkItDown(enable_plugins=True) 
101 | result = md.convert("path-to-file.rtf")
102 | print(result.text_content)
103 | ```
104 | 
105 | ## Trademarks
106 | 
107 | This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft
108 | trademarks or logos is subject to and must follow
109 | [Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).
110 | Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.
111 | Any use of third-party trademarks or logos are subject to those third-party's policies.
112 | 


--------------------------------------------------------------------------------
/packages/markitdown-sample-plugin/pyproject.toml:
--------------------------------------------------------------------------------
 1 | [build-system]
 2 | requires = ["hatchling"]
 3 | build-backend = "hatchling.build"
 4 | 
 5 | [project]
 6 | name = "markitdown-sample-plugin"
 7 | dynamic = ["version"]
 8 | description = 'A sample plugin for the "markitdown" library.'
 9 | readme = "README.md"
10 | requires-python = ">=3.10"
11 | license = "MIT"
12 | keywords = []
13 | authors = [
14 |   { name = "Adam Fourney", email = "adamfo@microsoft.com" },
15 | ]
16 | classifiers = [
17 |   "Development Status :: 4 - Beta",
18 |   "Programming Language :: Python",
19 |   "Programming Language :: Python :: 3.10",
20 |   "Programming Language :: Python :: 3.11",
21 |   "Programming Language :: Python :: 3.12",
22 |   "Programming Language :: Python :: 3.13",
23 |   "Programming Language :: Python :: Implementation :: CPython",
24 |   "Programming Language :: Python :: Implementation :: PyPy",
25 | ]
26 | dependencies = [
27 |   "markitdown>=0.1.0a1",
28 |   "striprtf",
29 | ]
30 | 
31 | [project.urls]
32 | Documentation = "https://github.com/microsoft/markitdown#readme"
33 | Issues = "https://github.com/microsoft/markitdown/issues"
34 | Source = "https://github.com/microsoft/markitdown"
35 | 
36 | [tool.hatch.version]
37 | path = "src/markitdown_sample_plugin/__about__.py"
38 | 
39 | # IMPORTANT: MarkItDown will look for this entry point to find the plugin.
40 | [project.entry-points."markitdown.plugin"]
41 | sample_plugin = "markitdown_sample_plugin"
42 | 
43 | [tool.hatch.envs.types]
44 | extra-dependencies = [
45 |   "mypy>=1.0.0",
46 | ]
47 | [tool.hatch.envs.types.scripts]
48 | check = "mypy --install-types --non-interactive {args:src/markitdown_sample_plugin tests}"
49 | 
50 | [tool.coverage.run]
51 | source_pkgs = ["markitdown-sample-plugin", "tests"]
52 | branch = true
53 | parallel = true
54 | omit = [
55 |   "src/markitdown_sample_plugin/__about__.py",
56 | ]
57 | 
58 | [tool.coverage.paths]
59 | markitdown-sample-plugin = ["src/markitdown_sample_plugin", "*/markitdown-sample-plugin/src/markitdown_sample_plugin"]
60 | tests = ["tests", "*/markitdown-sample-plugin/tests"]
61 | 
62 | [tool.coverage.report]
63 | exclude_lines = [
64 |   "no cov",
65 |   "if __name__ == .__main__.:",
66 |   "if TYPE_CHECKING:",
67 | ]
68 | 
69 | [tool.hatch.build.targets.sdist]
70 | only-include = ["src/markitdown_sample_plugin"]
71 | 


--------------------------------------------------------------------------------
/packages/markitdown-sample-plugin/src/markitdown_sample_plugin/__about__.py:
--------------------------------------------------------------------------------
1 | # SPDX-FileCopyrightText: 2024-present Adam Fourney <adamfo@microsoft.com>
2 | #
3 | # SPDX-License-Identifier: MIT
4 | __version__ = "0.1.0a1"
5 | 


--------------------------------------------------------------------------------
/packages/markitdown-sample-plugin/src/markitdown_sample_plugin/__init__.py:
--------------------------------------------------------------------------------
 1 | # SPDX-FileCopyrightText: 2024-present Adam Fourney <adamfo@microsoft.com>
 2 | #
 3 | # SPDX-License-Identifier: MIT
 4 | 
 5 | from ._plugin import __plugin_interface_version__, register_converters, RtfConverter
 6 | from .__about__ import __version__
 7 | 
 8 | __all__ = [
 9 |     "__version__",
10 |     "__plugin_interface_version__",
11 |     "register_converters",
12 |     "RtfConverter",
13 | ]
14 | 


--------------------------------------------------------------------------------
/packages/markitdown-sample-plugin/src/markitdown_sample_plugin/_plugin.py:
--------------------------------------------------------------------------------
 1 | import locale
 2 | from typing import BinaryIO, Any
 3 | from striprtf.striprtf import rtf_to_text
 4 | 
 5 | from markitdown import (
 6 |     MarkItDown,
 7 |     DocumentConverter,
 8 |     DocumentConverterResult,
 9 |     StreamInfo,
10 | )
11 | 
12 | 
13 | __plugin_interface_version__ = (
14 |     1  # The version of the plugin interface that this plugin uses
15 | )
16 | 
17 | ACCEPTED_MIME_TYPE_PREFIXES = [
18 |     "text/rtf",
19 |     "application/rtf",
20 | ]
21 | 
22 | ACCEPTED_FILE_EXTENSIONS = [".rtf"]
23 | 
24 | 
25 | def register_converters(markitdown: MarkItDown, **kwargs):
26 |     """
27 |     Called during construction of MarkItDown instances to register converters provided by plugins.
28 |     """
29 | 
30 |     # Simply create and attach an RtfConverter instance
31 |     markitdown.register_converter(RtfConverter())
32 | 
33 | 
34 | class RtfConverter(DocumentConverter):
35 |     """
36 |     Converts an RTF file to in the simplest possible way.
37 |     """
38 | 
39 |     def accepts(
40 |         self,
41 |         file_stream: BinaryIO,
42 |         stream_info: StreamInfo,
43 |         **kwargs: Any,
44 |     ) -> bool:
45 |         mimetype = (stream_info.mimetype or "").lower()
46 |         extension = (stream_info.extension or "").lower()
47 | 
48 |         if extension in ACCEPTED_FILE_EXTENSIONS:
49 |             return True
50 | 
51 |         for prefix in ACCEPTED_MIME_TYPE_PREFIXES:
52 |             if mimetype.startswith(prefix):
53 |                 return True
54 | 
55 |         return False
56 | 
57 |     def convert(
58 |         self,
59 |         file_stream: BinaryIO,
60 |         stream_info: StreamInfo,
61 |         **kwargs: Any,
62 |     ) -> DocumentConverterResult:
63 |         # Read the file stream into an str using hte provided charset encoding, or using the system default
64 |         encoding = stream_info.charset or locale.getpreferredencoding()
65 |         stream_data = file_stream.read().decode(encoding)
66 | 
67 |         # Return the result
68 |         return DocumentConverterResult(
69 |             title=None,
70 |             markdown=rtf_to_text(stream_data),
71 |         )
72 | 


--------------------------------------------------------------------------------
/packages/markitdown-sample-plugin/src/markitdown_sample_plugin/py.typed:
--------------------------------------------------------------------------------
https://raw.githubusercontent.com/microsoft/markitdown/3fcd48cdfc651cbf508071c8d2fb7d82aeb075de/packages/markitdown-sample-plugin/src/markitdown_sample_plugin/py.typed


--------------------------------------------------------------------------------
/packages/markitdown-sample-plugin/tests/__init__.py:
--------------------------------------------------------------------------------
1 | # SPDX-FileCopyrightText: 2024-present Adam Fourney <adamfo@microsoft.com>
2 | #
3 | # SPDX-License-Identifier: MIT
4 | 


--------------------------------------------------------------------------------
/packages/markitdown-sample-plugin/tests/test_sample_plugin.py:
--------------------------------------------------------------------------------
 1 | #!/usr/bin/env python3 -m pytest
 2 | import os
 3 | import pytest
 4 | 
 5 | from markitdown import MarkItDown, StreamInfo
 6 | from markitdown_sample_plugin import RtfConverter
 7 | 
 8 | TEST_FILES_DIR = os.path.join(os.path.dirname(__file__), "test_files")
 9 | 
10 | RTF_TEST_STRINGS = {
11 |     "This is a Sample RTF File",
12 |     "It is included to test if the MarkItDown sample plugin can correctly convert RTF files.",
13 | }
14 | 
15 | 
16 | def test_converter() -> None:
17 |     """Tests the RTF converter dirctly."""
18 |     with open(os.path.join(TEST_FILES_DIR, "test.rtf"), "rb") as file_stream:
19 |         converter = RtfConverter()
20 |         result = converter.convert(
21 |             file_stream=file_stream,
22 |             stream_info=StreamInfo(
23 |                 mimetype="text/rtf", extension=".rtf", filename="test.rtf"
24 |             ),
25 |         )
26 | 
27 |         for test_string in RTF_TEST_STRINGS:
28 |             assert test_string in result.text_content
29 | 
30 | 
31 | def test_markitdown() -> None:
32 |     """Tests that MarkItDown correctly loads the plugin."""
33 |     md = MarkItDown(enable_plugins=True)
34 |     result = md.convert(os.path.join(TEST_FILES_DIR, "test.rtf"))
35 | 
36 |     for test_string in RTF_TEST_STRINGS:
37 |         assert test_string in result.text_content
38 | 
39 | 
40 | if __name__ == "__main__":
41 |     """Runs this file's tests from the command line."""
42 |     test_converter()
43 |     test_markitdown()
44 |     print("All tests passed.")
45 | 


--------------------------------------------------------------------------------
/packages/markitdown/README.md:
--------------------------------------------------------------------------------
 1 | # MarkItDown
 2 | 
 3 | > [!IMPORTANT]
 4 | > MarkItDown is a Python package and command-line utility for converting various files to Markdown (e.g., for indexing, text analysis, etc). 
 5 | >
 6 | > For more information, and full documentation, see the project [README.md](https://github.com/microsoft/markitdown) on GitHub.
 7 | 
 8 | ## Installation
 9 | 
10 | From PyPI:
11 | 
12 | ```bash
13 | pip install markitdown[all]
14 | ```
15 | 
16 | From source:
17 | 
18 | ```bash
19 | git clone git@github.com:microsoft/markitdown.git
20 | cd markitdown
21 | pip install -e packages/markitdown[all]
22 | ```
23 | 
24 | ## Usage
25 | 
26 | ### Command-Line
27 | 
28 | ```bash
29 | markitdown path-to-file.pdf > document.md
30 | ```
31 | 
32 | ### Python API
33 | 
34 | ```python
35 | from markitdown import MarkItDown
36 | 
37 | md = MarkItDown()
38 | result = md.convert("test.xlsx")
39 | print(result.text_content)
40 | ```
41 | 
42 | ### More Information
43 | 
44 | For more information, and full documentation, see the project [README.md](https://github.com/microsoft/markitdown) on GitHub.
45 | 
46 | ## Trademarks
47 | 
48 | This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft
49 | trademarks or logos is subject to and must follow
50 | [Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).
51 | Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.
52 | Any use of third-party trademarks or logos are subject to those third-party's policies.
53 | 


--------------------------------------------------------------------------------
/packages/markitdown/pyproject.toml:
--------------------------------------------------------------------------------
  1 | [build-system]
  2 | requires = ["hatchling"]
  3 | build-backend = "hatchling.build"
  4 | 
  5 | [project]
  6 | name = "markitdown"
  7 | dynamic = ["version"]
  8 | description = 'Utility tool for converting various files to Markdown'
  9 | readme = "README.md"
 10 | requires-python = ">=3.10"
 11 | license = "MIT"
 12 | keywords = []
 13 | authors = [
 14 |   { name = "Adam Fourney", email = "adamfo@microsoft.com" },
 15 | ]
 16 | classifiers = [
 17 |   "Development Status :: 4 - Beta",
 18 |   "Programming Language :: Python",
 19 |   "Programming Language :: Python :: 3.10",
 20 |   "Programming Language :: Python :: 3.11",
 21 |   "Programming Language :: Python :: 3.12",
 22 |   "Programming Language :: Python :: 3.13",
 23 |   "Programming Language :: Python :: Implementation :: CPython",
 24 |   "Programming Language :: Python :: Implementation :: PyPy",
 25 | ]
 26 | dependencies = [
 27 |   "beautifulsoup4",
 28 |   "requests",
 29 |   "markdownify",
 30 |   "magika~=0.6.1",
 31 |   "charset-normalizer",
 32 | ]
 33 | 
 34 | [project.optional-dependencies]
 35 | all = [
 36 |   "python-pptx",
 37 |   "mammoth",
 38 |   "pandas",
 39 |   "openpyxl",
 40 |   "xlrd",
 41 |   "lxml",
 42 |   "pdfminer.six",
 43 |   "olefile",
 44 |   "pydub",
 45 |   "SpeechRecognition",
 46 |   "youtube-transcript-api~=1.0.0",
 47 |   "azure-ai-documentintelligence",
 48 |   "azure-identity"
 49 | ]
 50 | pptx = ["python-pptx"]
 51 | docx = ["mammoth", "lxml"]
 52 | xlsx = ["pandas", "openpyxl"]
 53 | xls = ["pandas", "xlrd"]
 54 | pdf = ["pdfminer.six"]
 55 | outlook = ["olefile"]
 56 | audio-transcription = ["pydub", "SpeechRecognition"]
 57 | youtube-transcription = ["youtube-transcript-api"]
 58 | az-doc-intel = ["azure-ai-documentintelligence", "azure-identity"]
 59 | 
 60 | [project.urls]
 61 | Documentation = "https://github.com/microsoft/markitdown#readme"
 62 | Issues = "https://github.com/microsoft/markitdown/issues"
 63 | Source = "https://github.com/microsoft/markitdown"
 64 | 
 65 | [tool.hatch.version]
 66 | path = "src/markitdown/__about__.py"
 67 | 
 68 | [project.scripts]
 69 | markitdown = "markitdown.__main__:main"
 70 | 
 71 | [tool.hatch.envs.default]
 72 | features = ["all"]
 73 | 
 74 | [tool.hatch.envs.hatch-test]
 75 | features = ["all"]
 76 | extra-dependencies = [
 77 |   "openai",
 78 | ]
 79 | 
 80 | [tool.hatch.envs.types]
 81 | features = ["all"]
 82 | extra-dependencies = [
 83 |   "openai",
 84 |   "mypy>=1.0.0",
 85 | ]
 86 | 
 87 | [tool.hatch.envs.types.scripts]
 88 | check = "mypy --install-types --non-interactive --ignore-missing-imports {args:src/markitdown tests}"
 89 | 
 90 | [tool.coverage.run]
 91 | source_pkgs = ["markitdown", "tests"]
 92 | branch = true
 93 | parallel = true
 94 | omit = [
 95 |   "src/markitdown/__about__.py",
 96 | ]
 97 | 
 98 | [tool.coverage.paths]
 99 | markitdown = ["src/markitdown", "*/markitdown/src/markitdown"]
100 | tests = ["tests", "*/markitdown/tests"]
101 | 
102 | [tool.coverage.report]
103 | exclude_lines = [
104 |   "no cov",
105 |   "if __name__ == .__main__.:",
106 |   "if TYPE_CHECKING:",
107 | ]
108 | 
109 | [tool.hatch.build.targets.sdist]
110 | only-include = ["src/markitdown"]
111 | 


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/__about__.py:
--------------------------------------------------------------------------------
1 | # SPDX-FileCopyrightText: 2024-present Adam Fourney <adamfo@microsoft.com>
2 | #
3 | # SPDX-License-Identifier: MIT
4 | __version__ = "0.1.1"
5 | 


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/__init__.py:
--------------------------------------------------------------------------------
 1 | # SPDX-FileCopyrightText: 2024-present Adam Fourney <adamfo@microsoft.com>
 2 | #
 3 | # SPDX-License-Identifier: MIT
 4 | 
 5 | from .__about__ import __version__
 6 | from ._markitdown import (
 7 |     MarkItDown,
 8 |     PRIORITY_SPECIFIC_FILE_FORMAT,
 9 |     PRIORITY_GENERIC_FILE_FORMAT,
10 | )
11 | from ._base_converter import DocumentConverterResult, DocumentConverter
12 | from ._stream_info import StreamInfo
13 | from ._exceptions import (
14 |     MarkItDownException,
15 |     MissingDependencyException,
16 |     FailedConversionAttempt,
17 |     FileConversionException,
18 |     UnsupportedFormatException,
19 | )
20 | 
21 | __all__ = [
22 |     "__version__",
23 |     "MarkItDown",
24 |     "DocumentConverter",
25 |     "DocumentConverterResult",
26 |     "MarkItDownException",
27 |     "MissingDependencyException",
28 |     "FailedConversionAttempt",
29 |     "FileConversionException",
30 |     "UnsupportedFormatException",
31 |     "StreamInfo",
32 |     "PRIORITY_SPECIFIC_FILE_FORMAT",
33 |     "PRIORITY_GENERIC_FILE_FORMAT",
34 | ]
35 | 


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/__main__.py:
--------------------------------------------------------------------------------
  1 | # SPDX-FileCopyrightText: 2024-present Adam Fourney <adamfo@microsoft.com>
  2 | #
  3 | # SPDX-License-Identifier: MIT
  4 | import argparse
  5 | import sys
  6 | import codecs
  7 | import locale
  8 | from textwrap import dedent
  9 | from importlib.metadata import entry_points
 10 | from .__about__ import __version__
 11 | from ._markitdown import MarkItDown, StreamInfo, DocumentConverterResult
 12 | 
 13 | 
 14 | def main():
 15 |     parser = argparse.ArgumentParser(
 16 |         description="Convert various file formats to markdown.",
 17 |         prog="markitdown",
 18 |         formatter_class=argparse.RawDescriptionHelpFormatter,
 19 |         usage=dedent(
 20 |             """
 21 |             SYNTAX:
 22 | 
 23 |                 markitdown <OPTIONAL: FILENAME>
 24 |                 If FILENAME is empty, markitdown reads from stdin.
 25 | 
 26 |             EXAMPLE:
 27 | 
 28 |                 markitdown example.pdf
 29 | 
 30 |                 OR
 31 | 
 32 |                 cat example.pdf | markitdown
 33 | 
 34 |                 OR
 35 | 
 36 |                 markitdown < example.pdf
 37 |                 
 38 |                 OR to save to a file use
 39 |     
 40 |                 markitdown example.pdf -o example.md
 41 |                 
 42 |                 OR
 43 |                 
 44 |                 markitdown example.pdf > example.md
 45 |             """
 46 |         ).strip(),
 47 |     )
 48 | 
 49 |     parser.add_argument(
 50 |         "-v",
 51 |         "--version",
 52 |         action="version",
 53 |         version=f"%(prog)s {__version__}",
 54 |         help="show the version number and exit",
 55 |     )
 56 | 
 57 |     parser.add_argument(
 58 |         "-o",
 59 |         "--output",
 60 |         help="Output file name. If not provided, output is written to stdout.",
 61 |     )
 62 | 
 63 |     parser.add_argument(
 64 |         "-x",
 65 |         "--extension",
 66 |         help="Provide a hint about the file extension (e.g., when reading from stdin).",
 67 |     )
 68 | 
 69 |     parser.add_argument(
 70 |         "-m",
 71 |         "--mime-type",
 72 |         help="Provide a hint about the file's MIME type.",
 73 |     )
 74 | 
 75 |     parser.add_argument(
 76 |         "-c",
 77 |         "--charset",
 78 |         help="Provide a hint about the file's charset (e.g, UTF-8).",
 79 |     )
 80 | 
 81 |     parser.add_argument(
 82 |         "-d",
 83 |         "--use-docintel",
 84 |         action="store_true",
 85 |         help="Use Document Intelligence to extract text instead of offline conversion. Requires a valid Document Intelligence Endpoint.",
 86 |     )
 87 | 
 88 |     parser.add_argument(
 89 |         "-e",
 90 |         "--endpoint",
 91 |         type=str,
 92 |         help="Document Intelligence Endpoint. Required if using Document Intelligence.",
 93 |     )
 94 | 
 95 |     parser.add_argument(
 96 |         "-p",
 97 |         "--use-plugins",
 98 |         action="store_true",
 99 |         help="Use 3rd-party plugins to convert files. Use --list-plugins to see installed plugins.",
100 |     )
101 | 
102 |     parser.add_argument(
103 |         "--list-plugins",
104 |         action="store_true",
105 |         help="List installed 3rd-party plugins. Plugins are loaded when using the -p or --use-plugin option.",
106 |     )
107 | 
108 |     parser.add_argument(
109 |         "--keep-data-uris",
110 |         action="store_true",
111 |         help="Keep data URIs (like base64-encoded images) in the output. By default, data URIs are truncated.",
112 |     )
113 | 
114 |     parser.add_argument("filename", nargs="?")
115 |     args = parser.parse_args()
116 | 
117 |     # Parse the extension hint
118 |     extension_hint = args.extension
119 |     if extension_hint is not None:
120 |         extension_hint = extension_hint.strip().lower()
121 |         if len(extension_hint) > 0:
122 |             if not extension_hint.startswith("."):
123 |                 extension_hint = "." + extension_hint
124 |         else:
125 |             extension_hint = None
126 | 
127 |     # Parse the mime type
128 |     mime_type_hint = args.mime_type
129 |     if mime_type_hint is not None:
130 |         mime_type_hint = mime_type_hint.strip()
131 |         if len(mime_type_hint) > 0:
132 |             if mime_type_hint.count("/") != 1:
133 |                 _exit_with_error(f"Invalid MIME type: {mime_type_hint}")
134 |         else:
135 |             mime_type_hint = None
136 | 
137 |     # Parse the charset
138 |     charset_hint = args.charset
139 |     if charset_hint is not None:
140 |         charset_hint = charset_hint.strip()
141 |         if len(charset_hint) > 0:
142 |             try:
143 |                 charset_hint = codecs.lookup(charset_hint).name
144 |             except LookupError:
145 |                 _exit_with_error(f"Invalid charset: {charset_hint}")
146 |         else:
147 |             charset_hint = None
148 | 
149 |     stream_info = None
150 |     if (
151 |         extension_hint is not None
152 |         or mime_type_hint is not None
153 |         or charset_hint is not None
154 |     ):
155 |         stream_info = StreamInfo(
156 |             extension=extension_hint, mimetype=mime_type_hint, charset=charset_hint
157 |         )
158 | 
159 |     if args.list_plugins:
160 |         # List installed plugins, then exit
161 |         print("Installed MarkItDown 3rd-party Plugins:\n")
162 |         plugin_entry_points = list(entry_points(group="markitdown.plugin"))
163 |         if len(plugin_entry_points) == 0:
164 |             print("  * No 3rd-party plugins installed.")
165 |             print(
166 |                 "\nFind plugins by searching for the hashtag #markitdown-plugin on GitHub.\n"
167 |             )
168 |         else:
169 |             for entry_point in plugin_entry_points:
170 |                 print(f"  * {entry_point.name:<16}\t(package: {entry_point.value})")
171 |             print(
172 |                 "\nUse the -p (or --use-plugins) option to enable 3rd-party plugins.\n"
173 |             )
174 |         sys.exit(0)
175 | 
176 |     if args.use_docintel:
177 |         if args.endpoint is None:
178 |             _exit_with_error(
179 |                 "Document Intelligence Endpoint is required when using Document Intelligence."
180 |             )
181 |         elif args.filename is None:
182 |             _exit_with_error("Filename is required when using Document Intelligence.")
183 | 
184 |         markitdown = MarkItDown(
185 |             enable_plugins=args.use_plugins, docintel_endpoint=args.endpoint
186 |         )
187 |     else:
188 |         markitdown = MarkItDown(enable_plugins=args.use_plugins)
189 | 
190 |     if args.filename is None:
191 |         result = markitdown.convert_stream(
192 |             sys.stdin.buffer,
193 |             stream_info=stream_info,
194 |             keep_data_uris=args.keep_data_uris,
195 |         )
196 |     else:
197 |         result = markitdown.convert(
198 |             args.filename, stream_info=stream_info, keep_data_uris=args.keep_data_uris
199 |         )
200 | 
201 |     _handle_output(args, result)
202 | 
203 | 
204 | def _handle_output(args, result: DocumentConverterResult):
205 |     """Handle output to stdout or file"""
206 |     if args.output:
207 |         with open(args.output, "w", encoding="utf-8") as f:
208 |             f.write(result.markdown)
209 |     else:
210 |         # Handle stdout encoding errors more gracefully
211 |         print(
212 |             result.markdown.encode(sys.stdout.encoding, errors="replace").decode(
213 |                 sys.stdout.encoding
214 |             )
215 |         )
216 | 
217 | 
218 | def _exit_with_error(message: str):
219 |     print(message)
220 |     sys.exit(1)
221 | 
222 | 
223 | if __name__ == "__main__":
224 |     main()
225 | 


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/_base_converter.py:
--------------------------------------------------------------------------------
  1 | import os
  2 | import tempfile
  3 | from warnings import warn
  4 | from typing import Any, Union, BinaryIO, Optional, List
  5 | from ._stream_info import StreamInfo
  6 | 
  7 | 
  8 | class DocumentConverterResult:
  9 |     """The result of converting a document to Markdown."""
 10 | 
 11 |     def __init__(
 12 |         self,
 13 |         markdown: str,
 14 |         *,
 15 |         title: Optional[str] = None,
 16 |     ):
 17 |         """
 18 |         Initialize the DocumentConverterResult.
 19 | 
 20 |         The only required parameter is the converted Markdown text.
 21 |         The title, and any other metadata that may be added in the future, are optional.
 22 | 
 23 |         Parameters:
 24 |         - markdown: The converted Markdown text.
 25 |         - title: Optional title of the document.
 26 |         """
 27 |         self.markdown = markdown
 28 |         self.title = title
 29 | 
 30 |     @property
 31 |     def text_content(self) -> str:
 32 |         """Soft-deprecated alias for `markdown`. New code should migrate to using `markdown` or __str__."""
 33 |         return self.markdown
 34 | 
 35 |     @text_content.setter
 36 |     def text_content(self, markdown: str):
 37 |         """Soft-deprecated alias for `markdown`. New code should migrate to using `markdown` or __str__."""
 38 |         self.markdown = markdown
 39 | 
 40 |     def __str__(self) -> str:
 41 |         """Return the converted Markdown text."""
 42 |         return self.markdown
 43 | 
 44 | 
 45 | class DocumentConverter:
 46 |     """Abstract superclass of all DocumentConverters."""
 47 | 
 48 |     def accepts(
 49 |         self,
 50 |         file_stream: BinaryIO,
 51 |         stream_info: StreamInfo,
 52 |         **kwargs: Any,  # Options to pass to the converter
 53 |     ) -> bool:
 54 |         """
 55 |         Return a quick determination on if the converter should attempt converting the document.
 56 |         This is primarily based `stream_info` (typically, `stream_info.mimetype`, `stream_info.extension`).
 57 |         In cases where the data is retrieved via HTTP, the `steam_info.url` might also be referenced to
 58 |         make a determination (e.g., special converters for Wikipedia, YouTube etc).
 59 |         Finally, it is conceivable that the `stream_info.filename` might be used to in cases
 60 |         where the filename is well-known (e.g., `Dockerfile`, `Makefile`, etc)
 61 | 
 62 |         NOTE: The method signature is designed to match that of the convert() method. This provides some
 63 |         assurance that, if accepts() returns True, the convert() method will also be able to handle the document.
 64 | 
 65 |         IMPORTANT: In rare cases, (e.g., OutlookMsgConverter) we need to read more from the stream to make a final
 66 |         determination. Read operations inevitably advances the position in file_stream. In these case, the position
 67 |         MUST be reset it MUST be reset before returning. This is because the convert() method may be called immediately
 68 |         after accepts(), and will expect the file_stream to be at the original position.
 69 | 
 70 |         E.g.,
 71 |         cur_pos = file_stream.tell() # Save the current position
 72 |         data = file_stream.read(100) # ... peek at the first 100 bytes, etc.
 73 |         file_stream.seek(cur_pos)    # Reset the position to the original position
 74 | 
 75 |         Prameters:
 76 |         - file_stream: The file-like object to convert. Must support seek(), tell(), and read() methods.
 77 |         - stream_info: The StreamInfo object containing metadata about the file (mimetype, extension, charset, set)
 78 |         - kwargs: Additional keyword arguments for the converter.
 79 | 
 80 |         Returns:
 81 |         - bool: True if the converter can handle the document, False otherwise.
 82 |         """
 83 |         raise NotImplementedError(
 84 |             f"The subclass, {type(self).__name__}, must implement the accepts() method to determine if they can handle the document."
 85 |         )
 86 | 
 87 |     def convert(
 88 |         self,
 89 |         file_stream: BinaryIO,
 90 |         stream_info: StreamInfo,
 91 |         **kwargs: Any,  # Options to pass to the converter
 92 |     ) -> DocumentConverterResult:
 93 |         """
 94 |         Convert a document to Markdown text.
 95 | 
 96 |         Prameters:
 97 |         - file_stream: The file-like object to convert. Must support seek(), tell(), and read() methods.
 98 |         - stream_info: The StreamInfo object containing metadata about the file (mimetype, extension, charset, set)
 99 |         - kwargs: Additional keyword arguments for the converter.
100 | 
101 |         Returns:
102 |         - DocumentConverterResult: The result of the conversion, which includes the title and markdown content.
103 | 
104 |         Raises:
105 |         - FileConversionException: If the mimetype is recognized, but the conversion fails for some other reason.
106 |         - MissingDependencyException: If the converter requires a dependency that is not installed.
107 |         """
108 |         raise NotImplementedError("Subclasses must implement this method")
109 | 


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/_exceptions.py:
--------------------------------------------------------------------------------
 1 | from typing import Optional, List, Any
 2 | 
 3 | MISSING_DEPENDENCY_MESSAGE = """{converter} recognized the input as a potential {extension} file, but the dependencies needed to read {extension} files have not been installed. To resolve this error, include the optional dependency [{feature}] or [all] when installing MarkItDown. For example:
 4 | 
 5 | * pip install markitdown[{feature}]
 6 | * pip install markitdown[all]
 7 | * pip install markitdown[{feature}, ...]
 8 | * etc."""
 9 | 
10 | 
11 | class MarkItDownException(Exception):
12 |     """
13 |     Base exception class for MarkItDown.
14 |     """
15 | 
16 |     pass
17 | 
18 | 
19 | class MissingDependencyException(MarkItDownException):
20 |     """
21 |     Converters shipped with MarkItDown may depend on optional
22 |     dependencies. This exception is thrown when a converter's
23 |     convert() method is called, but the required dependency is not
24 |     installed. This is not necessarily a fatal error, as the converter
25 |     will simply be skipped (an error will bubble up only if no other
26 |     suitable converter is found).
27 | 
28 |     Error messages should clearly indicate which dependency is missing.
29 |     """
30 | 
31 |     pass
32 | 
33 | 
34 | class UnsupportedFormatException(MarkItDownException):
35 |     """
36 |     Thrown when no suitable converter was found for the given file.
37 |     """
38 | 
39 |     pass
40 | 
41 | 
42 | class FailedConversionAttempt(object):
43 |     """
44 |     Represents an a single attempt to convert a file.
45 |     """
46 | 
47 |     def __init__(self, converter: Any, exc_info: Optional[tuple] = None):
48 |         self.converter = converter
49 |         self.exc_info = exc_info
50 | 
51 | 
52 | class FileConversionException(MarkItDownException):
53 |     """
54 |     Thrown when a suitable converter was found, but the conversion
55 |     process fails for any reason.
56 |     """
57 | 
58 |     def __init__(
59 |         self,
60 |         message: Optional[str] = None,
61 |         attempts: Optional[List[FailedConversionAttempt]] = None,
62 |     ):
63 |         self.attempts = attempts
64 | 
65 |         if message is None:
66 |             if attempts is None:
67 |                 message = "File conversion failed."
68 |             else:
69 |                 message = f"File conversion failed after {len(attempts)} attempts:\n"
70 |                 for attempt in attempts:
71 |                     if attempt.exc_info is None:
72 |                         message += f" -  {type(attempt.converter).__name__} provided no execution info."
73 |                     else:
74 |                         message += f" - {type(attempt.converter).__name__} threw {attempt.exc_info[0].__name__} with message: {attempt.exc_info[1]}\n"
75 | 
76 |         super().__init__(message)
77 | 


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/_stream_info.py:
--------------------------------------------------------------------------------
 1 | from dataclasses import dataclass, asdict
 2 | from typing import Optional
 3 | 
 4 | 
 5 | @dataclass(kw_only=True, frozen=True)
 6 | class StreamInfo:
 7 |     """The StreamInfo class is used to store information about a file stream.
 8 |     All fields can be None, and will depend on how the stream was opened.
 9 |     """
10 | 
11 |     mimetype: Optional[str] = None
12 |     extension: Optional[str] = None
13 |     charset: Optional[str] = None
14 |     filename: Optional[
15 |         str
16 |     ] = None  # From local path, url, or Content-Disposition header
17 |     local_path: Optional[str] = None  # If read from disk
18 |     url: Optional[str] = None  # If read from url
19 | 
20 |     def copy_and_update(self, *args, **kwargs):
21 |         """Copy the StreamInfo object and update it with the given StreamInfo
22 |         instance and/or other keyword arguments."""
23 |         new_info = asdict(self)
24 | 
25 |         for si in args:
26 |             assert isinstance(si, StreamInfo)
27 |             new_info.update({k: v for k, v in asdict(si).items() if v is not None})
28 | 
29 |         if len(kwargs) > 0:
30 |             new_info.update(kwargs)
31 | 
32 |         return StreamInfo(**new_info)
33 | 


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/_uri_utils.py:
--------------------------------------------------------------------------------
 1 | import base64
 2 | import os
 3 | from typing import Tuple, Dict
 4 | from urllib.request import url2pathname
 5 | from urllib.parse import urlparse, unquote_to_bytes
 6 | 
 7 | 
 8 | def file_uri_to_path(file_uri: str) -> Tuple[str | None, str]:
 9 |     """Convert a file URI to a local file path"""
10 |     parsed = urlparse(file_uri)
11 |     if parsed.scheme != "file":
12 |         raise ValueError(f"Not a file URL: {file_uri}")
13 | 
14 |     netloc = parsed.netloc if parsed.netloc else None
15 |     path = os.path.abspath(url2pathname(parsed.path))
16 |     return netloc, path
17 | 
18 | 
19 | def parse_data_uri(uri: str) -> Tuple[str | None, Dict[str, str], bytes]:
20 |     if not uri.startswith("data:"):
21 |         raise ValueError("Not a data URI")
22 | 
23 |     header, _, data = uri.partition(",")
24 |     if not _:
25 |         raise ValueError("Malformed data URI, missing ',' separator")
26 | 
27 |     meta = header[5:]  # Strip 'data:'
28 |     parts = meta.split(";")
29 | 
30 |     is_base64 = False
31 |     # Ends with base64?
32 |     if parts[-1] == "base64":
33 |         parts.pop()
34 |         is_base64 = True
35 | 
36 |     mime_type = None  # Normally this would default to text/plain but we won't assume
37 |     if len(parts) and len(parts[0]) > 0:
38 |         # First part is the mime type
39 |         mime_type = parts.pop(0)
40 | 
41 |     attributes: Dict[str, str] = {}
42 |     for part in parts:
43 |         # Handle key=value pairs in the middle
44 |         if "=" in part:
45 |             key, value = part.split("=", 1)
46 |             attributes[key] = value
47 |         elif len(part) > 0:
48 |             attributes[part] = ""
49 | 
50 |     content = base64.b64decode(data) if is_base64 else unquote_to_bytes(data)
51 | 
52 |     return mime_type, attributes, content
53 | 


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/converter_utils/__init__.py:
--------------------------------------------------------------------------------
https://raw.githubusercontent.com/microsoft/markitdown/3fcd48cdfc651cbf508071c8d2fb7d82aeb075de/packages/markitdown/src/markitdown/converter_utils/__init__.py


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/converter_utils/docx/__init__.py:
--------------------------------------------------------------------------------
https://raw.githubusercontent.com/microsoft/markitdown/3fcd48cdfc651cbf508071c8d2fb7d82aeb075de/packages/markitdown/src/markitdown/converter_utils/docx/__init__.py


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/converter_utils/docx/math/__init__.py:
--------------------------------------------------------------------------------
https://raw.githubusercontent.com/microsoft/markitdown/3fcd48cdfc651cbf508071c8d2fb7d82aeb075de/packages/markitdown/src/markitdown/converter_utils/docx/math/__init__.py


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/converter_utils/docx/math/latex_dict.py:
--------------------------------------------------------------------------------
  1 | # -*- coding: utf-8 -*-
  2 | 
  3 | """
  4 | Adapted from https://github.com/xiilei/dwml/blob/master/dwml/latex_dict.py
  5 | On 25/03/2025
  6 | """
  7 | 
  8 | from __future__ import unicode_literals
  9 | 
 10 | CHARS = ("{", "}", "_", "^", "#", "&", "$", "%", "~")
 11 | 
 12 | BLANK = ""
 13 | BACKSLASH = "\\"
 14 | ALN = "&"
 15 | 
 16 | CHR = {
 17 |     # Unicode : Latex Math Symbols
 18 |     # Top accents
 19 |     "\u0300": "\\grave{{{0}}}",
 20 |     "\u0301": "\\acute{{{0}}}",
 21 |     "\u0302": "\\hat{{{0}}}",
 22 |     "\u0303": "\\tilde{{{0}}}",
 23 |     "\u0304": "\\bar{{{0}}}",
 24 |     "\u0305": "\\overbar{{{0}}}",
 25 |     "\u0306": "\\breve{{{0}}}",
 26 |     "\u0307": "\\dot{{{0}}}",
 27 |     "\u0308": "\\ddot{{{0}}}",
 28 |     "\u0309": "\\ovhook{{{0}}}",
 29 |     "\u030a": "\\ocirc{{{0}}}}",
 30 |     "\u030c": "\\check{{{0}}}}",
 31 |     "\u0310": "\\candra{{{0}}}",
 32 |     "\u0312": "\\oturnedcomma{{{0}}}",
 33 |     "\u0315": "\\ocommatopright{{{0}}}",
 34 |     "\u031a": "\\droang{{{0}}}",
 35 |     "\u0338": "\\not{{{0}}}",
 36 |     "\u20d0": "\\leftharpoonaccent{{{0}}}",
 37 |     "\u20d1": "\\rightharpoonaccent{{{0}}}",
 38 |     "\u20d2": "\\vertoverlay{{{0}}}",
 39 |     "\u20d6": "\\overleftarrow{{{0}}}",
 40 |     "\u20d7": "\\vec{{{0}}}",
 41 |     "\u20db": "\\dddot{{{0}}}",
 42 |     "\u20dc": "\\ddddot{{{0}}}",
 43 |     "\u20e1": "\\overleftrightarrow{{{0}}}",
 44 |     "\u20e7": "\\annuity{{{0}}}",
 45 |     "\u20e9": "\\widebridgeabove{{{0}}}",
 46 |     "\u20f0": "\\asteraccent{{{0}}}",
 47 |     # Bottom accents
 48 |     "\u0330": "\\wideutilde{{{0}}}",
 49 |     "\u0331": "\\underbar{{{0}}}",
 50 |     "\u20e8": "\\threeunderdot{{{0}}}",
 51 |     "\u20ec": "\\underrightharpoondown{{{0}}}",
 52 |     "\u20ed": "\\underleftharpoondown{{{0}}}",
 53 |     "\u20ee": "\\underledtarrow{{{0}}}",
 54 |     "\u20ef": "\\underrightarrow{{{0}}}",
 55 |     # Over | group
 56 |     "\u23b4": "\\overbracket{{{0}}}",
 57 |     "\u23dc": "\\overparen{{{0}}}",
 58 |     "\u23de": "\\overbrace{{{0}}}",
 59 |     # Under| group
 60 |     "\u23b5": "\\underbracket{{{0}}}",
 61 |     "\u23dd": "\\underparen{{{0}}}",
 62 |     "\u23df": "\\underbrace{{{0}}}",
 63 | }
 64 | 
 65 | CHR_BO = {
 66 |     # Big operators,
 67 |     "\u2140": "\\Bbbsum",
 68 |     "\u220f": "\\prod",
 69 |     "\u2210": "\\coprod",
 70 |     "\u2211": "\\sum",
 71 |     "\u222b": "\\int",
 72 |     "\u22c0": "\\bigwedge",
 73 |     "\u22c1": "\\bigvee",
 74 |     "\u22c2": "\\bigcap",
 75 |     "\u22c3": "\\bigcup",
 76 |     "\u2a00": "\\bigodot",
 77 |     "\u2a01": "\\bigoplus",
 78 |     "\u2a02": "\\bigotimes",
 79 | }
 80 | 
 81 | T = {
 82 |     "\u2192": "\\rightarrow ",
 83 |     # Greek letters
 84 |     "\U0001d6fc": "\\alpha ",
 85 |     "\U0001d6fd": "\\beta ",
 86 |     "\U0001d6fe": "\\gamma ",
 87 |     "\U0001d6ff": "\\theta ",
 88 |     "\U0001d700": "\\epsilon ",
 89 |     "\U0001d701": "\\zeta ",
 90 |     "\U0001d702": "\\eta ",
 91 |     "\U0001d703": "\\theta ",
 92 |     "\U0001d704": "\\iota ",
 93 |     "\U0001d705": "\\kappa ",
 94 |     "\U0001d706": "\\lambda ",
 95 |     "\U0001d707": "\\m ",
 96 |     "\U0001d708": "\\n ",
 97 |     "\U0001d709": "\\xi ",
 98 |     "\U0001d70a": "\\omicron ",
 99 |     "\U0001d70b": "\\pi ",
100 |     "\U0001d70c": "\\rho ",
101 |     "\U0001d70d": "\\varsigma ",
102 |     "\U0001d70e": "\\sigma ",
103 |     "\U0001d70f": "\\ta ",
104 |     "\U0001d710": "\\upsilon ",
105 |     "\U0001d711": "\\phi ",
106 |     "\U0001d712": "\\chi ",
107 |     "\U0001d713": "\\psi ",
108 |     "\U0001d714": "\\omega ",
109 |     "\U0001d715": "\\partial ",
110 |     "\U0001d716": "\\varepsilon ",
111 |     "\U0001d717": "\\vartheta ",
112 |     "\U0001d718": "\\varkappa ",
113 |     "\U0001d719": "\\varphi ",
114 |     "\U0001d71a": "\\varrho ",
115 |     "\U0001d71b": "\\varpi ",
116 |     # Relation symbols
117 |     "\u2190": "\\leftarrow ",
118 |     "\u2191": "\\uparrow ",
119 |     "\u2192": "\\rightarrow ",
120 |     "\u2193": "\\downright ",
121 |     "\u2194": "\\leftrightarrow ",
122 |     "\u2195": "\\updownarrow ",
123 |     "\u2196": "\\nwarrow ",
124 |     "\u2197": "\\nearrow ",
125 |     "\u2198": "\\searrow ",
126 |     "\u2199": "\\swarrow ",
127 |     "\u22ee": "\\vdots ",
128 |     "\u22ef": "\\cdots ",
129 |     "\u22f0": "\\adots ",
130 |     "\u22f1": "\\ddots ",
131 |     "\u2260": "\\ne ",
132 |     "\u2264": "\\leq ",
133 |     "\u2265": "\\geq ",
134 |     "\u2266": "\\leqq ",
135 |     "\u2267": "\\geqq ",
136 |     "\u2268": "\\lneqq ",
137 |     "\u2269": "\\gneqq ",
138 |     "\u226a": "\\ll ",
139 |     "\u226b": "\\gg ",
140 |     "\u2208": "\\in ",
141 |     "\u2209": "\\notin ",
142 |     "\u220b": "\\ni ",
143 |     "\u220c": "\\nni ",
144 |     # Ordinary symbols
145 |     "\u221e": "\\infty ",
146 |     # Binary relations
147 |     "\u00b1": "\\pm ",
148 |     "\u2213": "\\mp ",
149 |     # Italic, Latin, uppercase
150 |     "\U0001d434": "A",
151 |     "\U0001d435": "B",
152 |     "\U0001d436": "C",
153 |     "\U0001d437": "D",
154 |     "\U0001d438": "E",
155 |     "\U0001d439": "F",
156 |     "\U0001d43a": "G",
157 |     "\U0001d43b": "H",
158 |     "\U0001d43c": "I",
159 |     "\U0001d43d": "J",
160 |     "\U0001d43e": "K",
161 |     "\U0001d43f": "L",
162 |     "\U0001d440": "M",
163 |     "\U0001d441": "N",
164 |     "\U0001d442": "O",
165 |     "\U0001d443": "P",
166 |     "\U0001d444": "Q",
167 |     "\U0001d445": "R",
168 |     "\U0001d446": "S",
169 |     "\U0001d447": "T",
170 |     "\U0001d448": "U",
171 |     "\U0001d449": "V",
172 |     "\U0001d44a": "W",
173 |     "\U0001d44b": "X",
174 |     "\U0001d44c": "Y",
175 |     "\U0001d44d": "Z",
176 |     # Italic, Latin, lowercase
177 |     "\U0001d44e": "a",
178 |     "\U0001d44f": "b",
179 |     "\U0001d450": "c",
180 |     "\U0001d451": "d",
181 |     "\U0001d452": "e",
182 |     "\U0001d453": "f",
183 |     "\U0001d454": "g",
184 |     "\U0001d456": "i",
185 |     "\U0001d457": "j",
186 |     "\U0001d458": "k",
187 |     "\U0001d459": "l",
188 |     "\U0001d45a": "m",
189 |     "\U0001d45b": "n",
190 |     "\U0001d45c": "o",
191 |     "\U0001d45d": "p",
192 |     "\U0001d45e": "q",
193 |     "\U0001d45f": "r",
194 |     "\U0001d460": "s",
195 |     "\U0001d461": "t",
196 |     "\U0001d462": "u",
197 |     "\U0001d463": "v",
198 |     "\U0001d464": "w",
199 |     "\U0001d465": "x",
200 |     "\U0001d466": "y",
201 |     "\U0001d467": "z",
202 | }
203 | 
204 | FUNC = {
205 |     "sin": "\\sin({fe})",
206 |     "cos": "\\cos({fe})",
207 |     "tan": "\\tan({fe})",
208 |     "arcsin": "\\arcsin({fe})",
209 |     "arccos": "\\arccos({fe})",
210 |     "arctan": "\\arctan({fe})",
211 |     "arccot": "\\arccot({fe})",
212 |     "sinh": "\\sinh({fe})",
213 |     "cosh": "\\cosh({fe})",
214 |     "tanh": "\\tanh({fe})",
215 |     "coth": "\\coth({fe})",
216 |     "sec": "\\sec({fe})",
217 |     "csc": "\\csc({fe})",
218 | }
219 | 
220 | FUNC_PLACE = "{fe}"
221 | 
222 | BRK = "\\\\"
223 | 
224 | CHR_DEFAULT = {
225 |     "ACC_VAL": "\\hat{{{0}}}",
226 | }
227 | 
228 | POS = {
229 |     "top": "\\overline{{{0}}}",  # not sure
230 |     "bot": "\\underline{{{0}}}",
231 | }
232 | 
233 | POS_DEFAULT = {
234 |     "BAR_VAL": "\\overline{{{0}}}",
235 | }
236 | 
237 | SUB = "_{{{0}}}"
238 | 
239 | SUP = "^{{{0}}}"
240 | 
241 | F = {
242 |     "bar": "\\frac{{{num}}}{{{den}}}",
243 |     "skw": r"^{{{num}}}/_{{{den}}}",
244 |     "noBar": "\\genfrac{{}}{{}}{{0pt}}{{}}{{{num}}}{{{den}}}",
245 |     "lin": "{{{num}}}/{{{den}}}",
246 | }
247 | F_DEFAULT = "\\frac{{{num}}}{{{den}}}"
248 | 
249 | D = "\\left{left}{text}\\right{right}"
250 | 
251 | D_DEFAULT = {
252 |     "left": "(",
253 |     "right": ")",
254 |     "null": ".",
255 | }
256 | 
257 | RAD = "\\sqrt[{deg}]{{{text}}}"
258 | 
259 | RAD_DEFAULT = "\\sqrt{{{text}}}"
260 | 
261 | ARR = "\\begin{{array}}{{c}}{text}\\end{{array}}"
262 | 
263 | LIM_FUNC = {
264 |     "lim": "\\lim_{{{lim}}}",
265 |     "max": "\\max_{{{lim}}}",
266 |     "min": "\\min_{{{lim}}}",
267 | }
268 | 
269 | LIM_TO = ("\\rightarrow", "\\to")
270 | 
271 | LIM_UPP = "\\overset{{{lim}}}{{{text}}}"
272 | 
273 | M = "\\begin{{matrix}}{text}\\end{{matrix}}"
274 | 


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/converter_utils/docx/pre_process.py:
--------------------------------------------------------------------------------
  1 | import zipfile
  2 | from io import BytesIO
  3 | from typing import BinaryIO
  4 | from xml.etree import ElementTree as ET
  5 | 
  6 | from bs4 import BeautifulSoup, Tag
  7 | 
  8 | from .math.omml import OMML_NS, oMath2Latex
  9 | 
 10 | MATH_ROOT_TEMPLATE = "".join(
 11 |     (
 12 |         "<w:document ",
 13 |         'xmlns:wpc="http://schemas.microsoft.com/office/word/2010/wordprocessingCanvas" ',
 14 |         'xmlns:mc="http://schemas.openxmlformats.org/markup-compatibility/2006" ',
 15 |         'xmlns:o="urn:schemas-microsoft-com:office:office" ',
 16 |         'xmlns:r="http://schemas.openxmlformats.org/officeDocument/2006/relationships" ',
 17 |         'xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math" ',
 18 |         'xmlns:v="urn:schemas-microsoft-com:vml" ',
 19 |         'xmlns:wp14="http://schemas.microsoft.com/office/word/2010/wordprocessingDrawing" ',
 20 |         'xmlns:wp="http://schemas.openxmlformats.org/drawingml/2006/wordprocessingDrawing" ',
 21 |         'xmlns:w10="urn:schemas-microsoft-com:office:word" ',
 22 |         'xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main" ',
 23 |         'xmlns:w14="http://schemas.microsoft.com/office/word/2010/wordml" ',
 24 |         'xmlns:wpg="http://schemas.microsoft.com/office/word/2010/wordprocessingGroup" ',
 25 |         'xmlns:wpi="http://schemas.microsoft.com/office/word/2010/wordprocessingInk" ',
 26 |         'xmlns:wne="http://schemas.microsoft.com/office/word/2006/wordml" ',
 27 |         'xmlns:wps="http://schemas.microsoft.com/office/word/2010/wordprocessingShape" mc:Ignorable="w14 wp14">',
 28 |         "{0}</w:document>",
 29 |     )
 30 | )
 31 | 
 32 | 
 33 | def _convert_omath_to_latex(tag: Tag) -> str:
 34 |     """
 35 |     Converts an OMML (Office Math Markup Language) tag to LaTeX format.
 36 | 
 37 |     Args:
 38 |         tag (Tag): A BeautifulSoup Tag object representing the OMML element.
 39 | 
 40 |     Returns:
 41 |         str: The LaTeX representation of the OMML element.
 42 |     """
 43 |     # Format the tag into a complete XML document string
 44 |     math_root = ET.fromstring(MATH_ROOT_TEMPLATE.format(str(tag)))
 45 |     # Find the 'oMath' element within the XML document
 46 |     math_element = math_root.find(OMML_NS + "oMath")
 47 |     # Convert the 'oMath' element to LaTeX using the oMath2Latex function
 48 |     latex = oMath2Latex(math_element).latex
 49 |     return latex
 50 | 
 51 | 
 52 | def _get_omath_tag_replacement(tag: Tag, block: bool = False) -> Tag:
 53 |     """
 54 |     Creates a replacement tag for an OMML (Office Math Markup Language) element.
 55 | 
 56 |     Args:
 57 |         tag (Tag): A BeautifulSoup Tag object representing the "oMath" element.
 58 |         block (bool, optional): If True, the LaTeX will be wrapped in double dollar signs for block mode. Defaults to False.
 59 | 
 60 |     Returns:
 61 |         Tag: A BeautifulSoup Tag object representing the replacement element.
 62 |     """
 63 |     t_tag = Tag(name="w:t")
 64 |     t_tag.string = (
 65 |         f"$${_convert_omath_to_latex(tag)}$$"
 66 |         if block
 67 |         else f"${_convert_omath_to_latex(tag)}$"
 68 |     )
 69 |     r_tag = Tag(name="w:r")
 70 |     r_tag.append(t_tag)
 71 |     return r_tag
 72 | 
 73 | 
 74 | def _replace_equations(tag: Tag):
 75 |     """
 76 |     Replaces OMML (Office Math Markup Language) elements with their LaTeX equivalents.
 77 | 
 78 |     Args:
 79 |         tag (Tag): A BeautifulSoup Tag object representing the OMML element. Could be either "oMathPara" or "oMath".
 80 | 
 81 |     Raises:
 82 |         ValueError: If the tag is not supported.
 83 |     """
 84 |     if tag.name == "oMathPara":
 85 |         # Create a new paragraph tag
 86 |         p_tag = Tag(name="w:p")
 87 |         # Replace each 'oMath' child tag with its LaTeX equivalent as block equations
 88 |         for child_tag in tag.find_all("oMath"):
 89 |             p_tag.append(_get_omath_tag_replacement(child_tag, block=True))
 90 |         # Replace the original 'oMathPara' tag with the new paragraph tag
 91 |         tag.replace_with(p_tag)
 92 |     elif tag.name == "oMath":
 93 |         # Replace the 'oMath' tag with its LaTeX equivalent as inline equation
 94 |         tag.replace_with(_get_omath_tag_replacement(tag, block=False))
 95 |     else:
 96 |         raise ValueError(f"Not supported tag: {tag.name}")
 97 | 
 98 | 
 99 | def _pre_process_math(content: bytes) -> bytes:
100 |     """
101 |     Pre-processes the math content in a DOCX -> XML file by converting OMML (Office Math Markup Language) elements to LaTeX.
102 |     This preprocessed content can be directly replaced in the DOCX file -> XMLs.
103 | 
104 |     Args:
105 |         content (bytes): The XML content of the DOCX file as bytes.
106 | 
107 |     Returns:
108 |         bytes: The processed content with OMML elements replaced by their LaTeX equivalents, encoded as bytes.
109 |     """
110 |     soup = BeautifulSoup(content.decode(), features="xml")
111 |     for tag in soup.find_all("oMathPara"):
112 |         _replace_equations(tag)
113 |     for tag in soup.find_all("oMath"):
114 |         _replace_equations(tag)
115 |     return str(soup).encode()
116 | 
117 | 
118 | def pre_process_docx(input_docx: BinaryIO) -> BinaryIO:
119 |     """
120 |     Pre-processes a DOCX file with provided steps.
121 | 
122 |     The process works by unzipping the DOCX file in memory, transforming specific XML files
123 |     (such as converting OMML elements to LaTeX), and then zipping everything back into a
124 |     DOCX file without writing to disk.
125 | 
126 |     Args:
127 |         input_docx (BinaryIO): A binary input stream representing the DOCX file.
128 | 
129 |     Returns:
130 |         BinaryIO: A binary output stream representing the processed DOCX file.
131 |     """
132 |     output_docx = BytesIO()
133 |     # The files that need to be pre-processed from .docx
134 |     pre_process_enable_files = [
135 |         "word/document.xml",
136 |         "word/footnotes.xml",
137 |         "word/endnotes.xml",
138 |     ]
139 |     with zipfile.ZipFile(input_docx, mode="r") as zip_input:
140 |         files = {name: zip_input.read(name) for name in zip_input.namelist()}
141 |         with zipfile.ZipFile(output_docx, mode="w") as zip_output:
142 |             zip_output.comment = zip_input.comment
143 |             for name, content in files.items():
144 |                 if name in pre_process_enable_files:
145 |                     try:
146 |                         # Pre-process the content
147 |                         updated_content = _pre_process_math(content)
148 |                         # In the future, if there are more pre-processing steps, they can be added here
149 |                         zip_output.writestr(name, updated_content)
150 |                     except:
151 |                         # If there is an error in processing the content, write the original content
152 |                         zip_output.writestr(name, content)
153 |                 else:
154 |                     zip_output.writestr(name, content)
155 |     output_docx.seek(0)
156 |     return output_docx
157 | 


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/converters/__init__.py:
--------------------------------------------------------------------------------
 1 | # SPDX-FileCopyrightText: 2024-present Adam Fourney <adamfo@microsoft.com>
 2 | #
 3 | # SPDX-License-Identifier: MIT
 4 | 
 5 | from ._plain_text_converter import PlainTextConverter
 6 | from ._html_converter import HtmlConverter
 7 | from ._rss_converter import RssConverter
 8 | from ._wikipedia_converter import WikipediaConverter
 9 | from ._youtube_converter import YouTubeConverter
10 | from ._ipynb_converter import IpynbConverter
11 | from ._bing_serp_converter import BingSerpConverter
12 | from ._pdf_converter import PdfConverter
13 | from ._docx_converter import DocxConverter
14 | from ._xlsx_converter import XlsxConverter, XlsConverter
15 | from ._pptx_converter import PptxConverter
16 | from ._image_converter import ImageConverter
17 | from ._audio_converter import AudioConverter
18 | from ._outlook_msg_converter import OutlookMsgConverter
19 | from ._zip_converter import ZipConverter
20 | from ._doc_intel_converter import (
21 |     DocumentIntelligenceConverter,
22 |     DocumentIntelligenceFileType,
23 | )
24 | from ._epub_converter import EpubConverter
25 | 
26 | __all__ = [
27 |     "PlainTextConverter",
28 |     "HtmlConverter",
29 |     "RssConverter",
30 |     "WikipediaConverter",
31 |     "YouTubeConverter",
32 |     "IpynbConverter",
33 |     "BingSerpConverter",
34 |     "PdfConverter",
35 |     "DocxConverter",
36 |     "XlsxConverter",
37 |     "XlsConverter",
38 |     "PptxConverter",
39 |     "ImageConverter",
40 |     "AudioConverter",
41 |     "OutlookMsgConverter",
42 |     "ZipConverter",
43 |     "DocumentIntelligenceConverter",
44 |     "DocumentIntelligenceFileType",
45 |     "EpubConverter",
46 | ]
47 | 


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/converters/_audio_converter.py:
--------------------------------------------------------------------------------
  1 | import io
  2 | from typing import Any, BinaryIO, Optional
  3 | 
  4 | from ._exiftool import exiftool_metadata
  5 | from ._transcribe_audio import transcribe_audio
  6 | from .._base_converter import DocumentConverter, DocumentConverterResult
  7 | from .._stream_info import StreamInfo
  8 | from .._exceptions import MissingDependencyException
  9 | 
 10 | ACCEPTED_MIME_TYPE_PREFIXES = [
 11 |     "audio/x-wav",
 12 |     "audio/mpeg",
 13 |     "video/mp4",
 14 | ]
 15 | 
 16 | ACCEPTED_FILE_EXTENSIONS = [
 17 |     ".wav",
 18 |     ".mp3",
 19 |     ".m4a",
 20 |     ".mp4",
 21 | ]
 22 | 
 23 | 
 24 | class AudioConverter(DocumentConverter):
 25 |     """
 26 |     Converts audio files to markdown via extraction of metadata (if `exiftool` is installed), and speech transcription (if `speech_recognition` is installed).
 27 |     """
 28 | 
 29 |     def accepts(
 30 |         self,
 31 |         file_stream: BinaryIO,
 32 |         stream_info: StreamInfo,
 33 |         **kwargs: Any,  # Options to pass to the converter
 34 |     ) -> bool:
 35 |         mimetype = (stream_info.mimetype or "").lower()
 36 |         extension = (stream_info.extension or "").lower()
 37 | 
 38 |         if extension in ACCEPTED_FILE_EXTENSIONS:
 39 |             return True
 40 | 
 41 |         for prefix in ACCEPTED_MIME_TYPE_PREFIXES:
 42 |             if mimetype.startswith(prefix):
 43 |                 return True
 44 | 
 45 |         return False
 46 | 
 47 |     def convert(
 48 |         self,
 49 |         file_stream: BinaryIO,
 50 |         stream_info: StreamInfo,
 51 |         **kwargs: Any,  # Options to pass to the converter
 52 |     ) -> DocumentConverterResult:
 53 |         md_content = ""
 54 | 
 55 |         # Add metadata
 56 |         metadata = exiftool_metadata(
 57 |             file_stream, exiftool_path=kwargs.get("exiftool_path")
 58 |         )
 59 |         if metadata:
 60 |             for f in [
 61 |                 "Title",
 62 |                 "Artist",
 63 |                 "Author",
 64 |                 "Band",
 65 |                 "Album",
 66 |                 "Genre",
 67 |                 "Track",
 68 |                 "DateTimeOriginal",
 69 |                 "CreateDate",
 70 |                 # "Duration", -- Wrong values when read from memory
 71 |                 "NumChannels",
 72 |                 "SampleRate",
 73 |                 "AvgBytesPerSec",
 74 |                 "BitsPerSample",
 75 |             ]:
 76 |                 if f in metadata:
 77 |                     md_content += f"{f}: {metadata[f]}\n"
 78 | 
 79 |         # Figure out the audio format for transcription
 80 |         if stream_info.extension == ".wav" or stream_info.mimetype == "audio/x-wav":
 81 |             audio_format = "wav"
 82 |         elif stream_info.extension == ".mp3" or stream_info.mimetype == "audio/mpeg":
 83 |             audio_format = "mp3"
 84 |         elif (
 85 |             stream_info.extension in [".mp4", ".m4a"]
 86 |             or stream_info.mimetype == "video/mp4"
 87 |         ):
 88 |             audio_format = "mp4"
 89 |         else:
 90 |             audio_format = None
 91 | 
 92 |         # Transcribe
 93 |         if audio_format:
 94 |             try:
 95 |                 transcript = transcribe_audio(file_stream, audio_format=audio_format)
 96 |                 if transcript:
 97 |                     md_content += "\n\n### Audio Transcript:\n" + transcript
 98 |             except MissingDependencyException:
 99 |                 pass
100 | 
101 |         # Return the result
102 |         return DocumentConverterResult(markdown=md_content.strip())
103 | 


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/converters/_bing_serp_converter.py:
--------------------------------------------------------------------------------
  1 | import io
  2 | import re
  3 | import base64
  4 | import binascii
  5 | from urllib.parse import parse_qs, urlparse
  6 | from typing import Any, BinaryIO, Optional
  7 | from bs4 import BeautifulSoup
  8 | 
  9 | from .._base_converter import DocumentConverter, DocumentConverterResult
 10 | from .._stream_info import StreamInfo
 11 | from ._markdownify import _CustomMarkdownify
 12 | 
 13 | ACCEPTED_MIME_TYPE_PREFIXES = [
 14 |     "text/html",
 15 |     "application/xhtml",
 16 | ]
 17 | 
 18 | ACCEPTED_FILE_EXTENSIONS = [
 19 |     ".html",
 20 |     ".htm",
 21 | ]
 22 | 
 23 | 
 24 | class BingSerpConverter(DocumentConverter):
 25 |     """
 26 |     Handle Bing results pages (only the organic search results).
 27 |     NOTE: It is better to use the Bing API
 28 |     """
 29 | 
 30 |     def accepts(
 31 |         self,
 32 |         file_stream: BinaryIO,
 33 |         stream_info: StreamInfo,
 34 |         **kwargs: Any,  # Options to pass to the converter
 35 |     ) -> bool:
 36 |         """
 37 |         Make sure we're dealing with HTML content *from* Bing.
 38 |         """
 39 | 
 40 |         url = stream_info.url or ""
 41 |         mimetype = (stream_info.mimetype or "").lower()
 42 |         extension = (stream_info.extension or "").lower()
 43 | 
 44 |         if not re.search(r"^https://www\.bing\.com/search\?q=", url):
 45 |             # Not a Bing SERP URL
 46 |             return False
 47 | 
 48 |         if extension in ACCEPTED_FILE_EXTENSIONS:
 49 |             return True
 50 | 
 51 |         for prefix in ACCEPTED_MIME_TYPE_PREFIXES:
 52 |             if mimetype.startswith(prefix):
 53 |                 return True
 54 | 
 55 |         # Not HTML content
 56 |         return False
 57 | 
 58 |     def convert(
 59 |         self,
 60 |         file_stream: BinaryIO,
 61 |         stream_info: StreamInfo,
 62 |         **kwargs: Any,  # Options to pass to the converter
 63 |     ) -> DocumentConverterResult:
 64 |         assert stream_info.url is not None
 65 | 
 66 |         # Parse the query parameters
 67 |         parsed_params = parse_qs(urlparse(stream_info.url).query)
 68 |         query = parsed_params.get("q", [""])[0]
 69 | 
 70 |         # Parse the stream
 71 |         encoding = "utf-8" if stream_info.charset is None else stream_info.charset
 72 |         soup = BeautifulSoup(file_stream, "html.parser", from_encoding=encoding)
 73 | 
 74 |         # Clean up some formatting
 75 |         for tptt in soup.find_all(class_="tptt"):
 76 |             if hasattr(tptt, "string") and tptt.string:
 77 |                 tptt.string += " "
 78 |         for slug in soup.find_all(class_="algoSlug_icon"):
 79 |             slug.extract()
 80 | 
 81 |         # Parse the algorithmic results
 82 |         _markdownify = _CustomMarkdownify(**kwargs)
 83 |         results = list()
 84 |         for result in soup.find_all(class_="b_algo"):
 85 |             if not hasattr(result, "find_all"):
 86 |                 continue
 87 | 
 88 |             # Rewrite redirect urls
 89 |             for a in result.find_all("a", href=True):
 90 |                 parsed_href = urlparse(a["href"])
 91 |                 qs = parse_qs(parsed_href.query)
 92 | 
 93 |                 # The destination is contained in the u parameter,
 94 |                 # but appears to be base64 encoded, with some prefix
 95 |                 if "u" in qs:
 96 |                     u = (
 97 |                         qs["u"][0][2:].strip() + "=="
 98 |                     )  # Python 3 doesn't care about extra padding
 99 | 
100 |                     try:
101 |                         # RFC 4648 / Base64URL" variant, which uses "-" and "_"
102 |                         a["href"] = base64.b64decode(u, altchars="-_").decode("utf-8")
103 |                     except UnicodeDecodeError:
104 |                         pass
105 |                     except binascii.Error:
106 |                         pass
107 | 
108 |             # Convert to markdown
109 |             md_result = _markdownify.convert_soup(result).strip()
110 |             lines = [line.strip() for line in re.split(r"\n+", md_result)]
111 |             results.append("\n".join([line for line in lines if len(line) > 0]))
112 | 
113 |         webpage_text = (
114 |             f"## A Bing search for '{query}' found the following results:\n\n"
115 |             + "\n\n".join(results)
116 |         )
117 | 
118 |         return DocumentConverterResult(
119 |             markdown=webpage_text,
120 |             title=None if soup.title is None else soup.title.string,
121 |         )
122 | 


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/converters/_doc_intel_converter.py:
--------------------------------------------------------------------------------
  1 | import sys
  2 | import re
  3 | import os
  4 | 
  5 | from typing import BinaryIO, Any, List
  6 | from enum import Enum
  7 | 
  8 | from ._html_converter import HtmlConverter
  9 | from .._base_converter import DocumentConverter, DocumentConverterResult
 10 | from .._stream_info import StreamInfo
 11 | from .._exceptions import MissingDependencyException, MISSING_DEPENDENCY_MESSAGE
 12 | 
 13 | # Try loading optional (but in this case, required) dependencies
 14 | # Save reporting of any exceptions for later
 15 | _dependency_exc_info = None
 16 | try:
 17 |     from azure.ai.documentintelligence import DocumentIntelligenceClient
 18 |     from azure.ai.documentintelligence.models import (
 19 |         AnalyzeDocumentRequest,
 20 |         AnalyzeResult,
 21 |         DocumentAnalysisFeature,
 22 |     )
 23 |     from azure.core.credentials import AzureKeyCredential, TokenCredential
 24 |     from azure.identity import DefaultAzureCredential
 25 | except ImportError:
 26 |     # Preserve the error and stack trace for later
 27 |     _dependency_exc_info = sys.exc_info()
 28 | 
 29 | 
 30 | # TODO: currently, there is a bug in the document intelligence SDK with importing the "ContentFormat" enum.
 31 | # This constant is a temporary fix until the bug is resolved.
 32 | CONTENT_FORMAT = "markdown"
 33 | 
 34 | 
 35 | class DocumentIntelligenceFileType(str, Enum):
 36 |     """Enum of file types supported by the Document Intelligence Converter."""
 37 | 
 38 |     # No OCR
 39 |     DOCX = "docx"
 40 |     PPTX = "pptx"
 41 |     XLSX = "xlsx"
 42 |     HTML = "html"
 43 |     # OCR
 44 |     PDF = "pdf"
 45 |     JPEG = "jpeg"
 46 |     PNG = "png"
 47 |     BMP = "bmp"
 48 |     TIFF = "tiff"
 49 | 
 50 | 
 51 | def _get_mime_type_prefixes(types: List[DocumentIntelligenceFileType]) -> List[str]:
 52 |     """Get the MIME type prefixes for the given file types."""
 53 |     prefixes: List[str] = []
 54 |     for type_ in types:
 55 |         if type_ == DocumentIntelligenceFileType.DOCX:
 56 |             prefixes.append(
 57 |                 "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
 58 |             )
 59 |         elif type_ == DocumentIntelligenceFileType.PPTX:
 60 |             prefixes.append(
 61 |                 "application/vnd.openxmlformats-officedocument.presentationml"
 62 |             )
 63 |         elif type_ == DocumentIntelligenceFileType.XLSX:
 64 |             prefixes.append(
 65 |                 "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
 66 |             )
 67 |         elif type_ == DocumentIntelligenceFileType.PDF:
 68 |             prefixes.append("application/pdf")
 69 |             prefixes.append("application/x-pdf")
 70 |         elif type_ == DocumentIntelligenceFileType.JPEG:
 71 |             prefixes.append("image/jpeg")
 72 |         elif type_ == DocumentIntelligenceFileType.PNG:
 73 |             prefixes.append("image/png")
 74 |         elif type_ == DocumentIntelligenceFileType.BMP:
 75 |             prefixes.append("image/bmp")
 76 |         elif type_ == DocumentIntelligenceFileType.TIFF:
 77 |             prefixes.append("image/tiff")
 78 |     return prefixes
 79 | 
 80 | 
 81 | def _get_file_extensions(types: List[DocumentIntelligenceFileType]) -> List[str]:
 82 |     """Get the file extensions for the given file types."""
 83 |     extensions: List[str] = []
 84 |     for type_ in types:
 85 |         if type_ == DocumentIntelligenceFileType.DOCX:
 86 |             extensions.append(".docx")
 87 |         elif type_ == DocumentIntelligenceFileType.PPTX:
 88 |             extensions.append(".pptx")
 89 |         elif type_ == DocumentIntelligenceFileType.XLSX:
 90 |             extensions.append(".xlsx")
 91 |         elif type_ == DocumentIntelligenceFileType.PDF:
 92 |             extensions.append(".pdf")
 93 |         elif type_ == DocumentIntelligenceFileType.JPEG:
 94 |             extensions.append(".jpg")
 95 |             extensions.append(".jpeg")
 96 |         elif type_ == DocumentIntelligenceFileType.PNG:
 97 |             extensions.append(".png")
 98 |         elif type_ == DocumentIntelligenceFileType.BMP:
 99 |             extensions.append(".bmp")
100 |         elif type_ == DocumentIntelligenceFileType.TIFF:
101 |             extensions.append(".tiff")
102 |     return extensions
103 | 
104 | 
105 | class DocumentIntelligenceConverter(DocumentConverter):
106 |     """Specialized DocumentConverter that uses Document Intelligence to extract text from documents."""
107 | 
108 |     def __init__(
109 |         self,
110 |         *,
111 |         endpoint: str,
112 |         api_version: str = "2024-07-31-preview",
113 |         credential: AzureKeyCredential | TokenCredential | None = None,
114 |         file_types: List[DocumentIntelligenceFileType] = [
115 |             DocumentIntelligenceFileType.DOCX,
116 |             DocumentIntelligenceFileType.PPTX,
117 |             DocumentIntelligenceFileType.XLSX,
118 |             DocumentIntelligenceFileType.PDF,
119 |             DocumentIntelligenceFileType.JPEG,
120 |             DocumentIntelligenceFileType.PNG,
121 |             DocumentIntelligenceFileType.BMP,
122 |             DocumentIntelligenceFileType.TIFF,
123 |         ],
124 |     ):
125 |         """
126 |         Initialize the DocumentIntelligenceConverter.
127 | 
128 |         Args:
129 |             endpoint (str): The endpoint for the Document Intelligence service.
130 |             api_version (str): The API version to use. Defaults to "2024-07-31-preview".
131 |             credential (AzureKeyCredential | TokenCredential | None): The credential to use for authentication.
132 |             file_types (List[DocumentIntelligenceFileType]): The file types to accept. Defaults to all supported file types.
133 |         """
134 | 
135 |         super().__init__()
136 |         self._file_types = file_types
137 | 
138 |         # Raise an error if the dependencies are not available.
139 |         # This is different than other converters since this one isn't even instantiated
140 |         # unless explicitly requested.
141 |         if _dependency_exc_info is not None:
142 |             raise MissingDependencyException(
143 |                 "DocumentIntelligenceConverter requires the optional dependency [az-doc-intel] (or [all]) to be installed. E.g., `pip install markitdown[az-doc-intel]`"
144 |             ) from _dependency_exc_info[
145 |                 1
146 |             ].with_traceback(  # type: ignore[union-attr]
147 |                 _dependency_exc_info[2]
148 |             )
149 | 
150 |         if credential is None:
151 |             if os.environ.get("AZURE_API_KEY") is None:
152 |                 credential = DefaultAzureCredential()
153 |             else:
154 |                 credential = AzureKeyCredential(os.environ["AZURE_API_KEY"])
155 | 
156 |         self.endpoint = endpoint
157 |         self.api_version = api_version
158 |         self.doc_intel_client = DocumentIntelligenceClient(
159 |             endpoint=self.endpoint,
160 |             api_version=self.api_version,
161 |             credential=credential,
162 |         )
163 | 
164 |     def accepts(
165 |         self,
166 |         file_stream: BinaryIO,
167 |         stream_info: StreamInfo,
168 |         **kwargs: Any,  # Options to pass to the converter
169 |     ) -> bool:
170 |         mimetype = (stream_info.mimetype or "").lower()
171 |         extension = (stream_info.extension or "").lower()
172 | 
173 |         if extension in _get_file_extensions(self._file_types):
174 |             return True
175 | 
176 |         for prefix in _get_mime_type_prefixes(self._file_types):
177 |             if mimetype.startswith(prefix):
178 |                 return True
179 | 
180 |         return False
181 | 
182 |     def _analysis_features(self, stream_info: StreamInfo) -> List[str]:
183 |         """
184 |         Helper needed to determine which analysis features to use.
185 |         Certain document analysis features are not availiable for
186 |         office filetypes (.xlsx, .pptx, .html, .docx)
187 |         """
188 |         mimetype = (stream_info.mimetype or "").lower()
189 |         extension = (stream_info.extension or "").lower()
190 | 
191 |         # Types that don't support ocr
192 |         no_ocr_types = [
193 |             DocumentIntelligenceFileType.DOCX,
194 |             DocumentIntelligenceFileType.PPTX,
195 |             DocumentIntelligenceFileType.XLSX,
196 |             DocumentIntelligenceFileType.HTML,
197 |         ]
198 | 
199 |         if extension in _get_file_extensions(no_ocr_types):
200 |             return []
201 | 
202 |         for prefix in _get_mime_type_prefixes(no_ocr_types):
203 |             if mimetype.startswith(prefix):
204 |                 return []
205 | 
206 |         return [
207 |             DocumentAnalysisFeature.FORMULAS,  # enable formula extraction
208 |             DocumentAnalysisFeature.OCR_HIGH_RESOLUTION,  # enable high resolution OCR
209 |             DocumentAnalysisFeature.STYLE_FONT,  # enable font style extraction
210 |         ]
211 | 
212 |     def convert(
213 |         self,
214 |         file_stream: BinaryIO,
215 |         stream_info: StreamInfo,
216 |         **kwargs: Any,  # Options to pass to the converter
217 |     ) -> DocumentConverterResult:
218 |         # Extract the text using Azure Document Intelligence
219 |         poller = self.doc_intel_client.begin_analyze_document(
220 |             model_id="prebuilt-layout",
221 |             body=AnalyzeDocumentRequest(bytes_source=file_stream.read()),
222 |             features=self._analysis_features(stream_info),
223 |             output_content_format=CONTENT_FORMAT,  # TODO: replace with "ContentFormat.MARKDOWN" when the bug is fixed
224 |         )
225 |         result: AnalyzeResult = poller.result()
226 | 
227 |         # remove comments from the markdown content generated by Doc Intelligence and append to markdown string
228 |         markdown_text = re.sub(r"<!--.*?-->", "", result.content, flags=re.DOTALL)
229 |         return DocumentConverterResult(markdown=markdown_text)
230 | 


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/converters/_docx_converter.py:
--------------------------------------------------------------------------------
 1 | import sys
 2 | 
 3 | from typing import BinaryIO, Any
 4 | 
 5 | from ._html_converter import HtmlConverter
 6 | from ..converter_utils.docx.pre_process import pre_process_docx
 7 | from .._base_converter import DocumentConverter, DocumentConverterResult
 8 | from .._stream_info import StreamInfo
 9 | from .._exceptions import MissingDependencyException, MISSING_DEPENDENCY_MESSAGE
10 | 
11 | # Try loading optional (but in this case, required) dependencies
12 | # Save reporting of any exceptions for later
13 | _dependency_exc_info = None
14 | try:
15 |     import mammoth
16 | except ImportError:
17 |     # Preserve the error and stack trace for later
18 |     _dependency_exc_info = sys.exc_info()
19 | 
20 | 
21 | ACCEPTED_MIME_TYPE_PREFIXES = [
22 |     "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
23 | ]
24 | 
25 | ACCEPTED_FILE_EXTENSIONS = [".docx"]
26 | 
27 | 
28 | class DocxConverter(HtmlConverter):
29 |     """
30 |     Converts DOCX files to Markdown. Style information (e.g.m headings) and tables are preserved where possible.
31 |     """
32 | 
33 |     def __init__(self):
34 |         super().__init__()
35 |         self._html_converter = HtmlConverter()
36 | 
37 |     def accepts(
38 |         self,
39 |         file_stream: BinaryIO,
40 |         stream_info: StreamInfo,
41 |         **kwargs: Any,  # Options to pass to the converter
42 |     ) -> bool:
43 |         mimetype = (stream_info.mimetype or "").lower()
44 |         extension = (stream_info.extension or "").lower()
45 | 
46 |         if extension in ACCEPTED_FILE_EXTENSIONS:
47 |             return True
48 | 
49 |         for prefix in ACCEPTED_MIME_TYPE_PREFIXES:
50 |             if mimetype.startswith(prefix):
51 |                 return True
52 | 
53 |         return False
54 | 
55 |     def convert(
56 |         self,
57 |         file_stream: BinaryIO,
58 |         stream_info: StreamInfo,
59 |         **kwargs: Any,  # Options to pass to the converter
60 |     ) -> DocumentConverterResult:
61 |         # Check: the dependencies
62 |         if _dependency_exc_info is not None:
63 |             raise MissingDependencyException(
64 |                 MISSING_DEPENDENCY_MESSAGE.format(
65 |                     converter=type(self).__name__,
66 |                     extension=".docx",
67 |                     feature="docx",
68 |                 )
69 |             ) from _dependency_exc_info[
70 |                 1
71 |             ].with_traceback(  # type: ignore[union-attr]
72 |                 _dependency_exc_info[2]
73 |             )
74 | 
75 |         style_map = kwargs.get("style_map", None)
76 |         pre_process_stream = pre_process_docx(file_stream)
77 |         return self._html_converter.convert_string(
78 |             mammoth.convert_to_html(pre_process_stream, style_map=style_map).value,
79 |             **kwargs,
80 |         )
81 | 


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/converters/_epub_converter.py:
--------------------------------------------------------------------------------
  1 | import os
  2 | import zipfile
  3 | import xml.dom.minidom as minidom
  4 | 
  5 | from typing import BinaryIO, Any, Dict, List
  6 | 
  7 | from ._html_converter import HtmlConverter
  8 | from .._base_converter import DocumentConverter, DocumentConverterResult
  9 | from .._stream_info import StreamInfo
 10 | 
 11 | ACCEPTED_MIME_TYPE_PREFIXES = [
 12 |     "application/epub",
 13 |     "application/epub+zip",
 14 |     "application/x-epub+zip",
 15 | ]
 16 | 
 17 | ACCEPTED_FILE_EXTENSIONS = [".epub"]
 18 | 
 19 | MIME_TYPE_MAPPING = {
 20 |     ".html": "text/html",
 21 |     ".xhtml": "application/xhtml+xml",
 22 | }
 23 | 
 24 | 
 25 | class EpubConverter(HtmlConverter):
 26 |     """
 27 |     Converts EPUB files to Markdown. Style information (e.g.m headings) and tables are preserved where possible.
 28 |     """
 29 | 
 30 |     def __init__(self):
 31 |         super().__init__()
 32 |         self._html_converter = HtmlConverter()
 33 | 
 34 |     def accepts(
 35 |         self,
 36 |         file_stream: BinaryIO,
 37 |         stream_info: StreamInfo,
 38 |         **kwargs: Any,  # Options to pass to the converter
 39 |     ) -> bool:
 40 |         mimetype = (stream_info.mimetype or "").lower()
 41 |         extension = (stream_info.extension or "").lower()
 42 | 
 43 |         if extension in ACCEPTED_FILE_EXTENSIONS:
 44 |             return True
 45 | 
 46 |         for prefix in ACCEPTED_MIME_TYPE_PREFIXES:
 47 |             if mimetype.startswith(prefix):
 48 |                 return True
 49 | 
 50 |         return False
 51 | 
 52 |     def convert(
 53 |         self,
 54 |         file_stream: BinaryIO,
 55 |         stream_info: StreamInfo,
 56 |         **kwargs: Any,  # Options to pass to the converter
 57 |     ) -> DocumentConverterResult:
 58 |         with zipfile.ZipFile(file_stream, "r") as z:
 59 |             # Extracts metadata (title, authors, language, publisher, date, description, cover) from an EPUB file."""
 60 | 
 61 |             # Locate content.opf
 62 |             container_dom = minidom.parse(z.open("META-INF/container.xml"))
 63 |             opf_path = container_dom.getElementsByTagName("rootfile")[0].getAttribute(
 64 |                 "full-path"
 65 |             )
 66 | 
 67 |             # Parse content.opf
 68 |             opf_dom = minidom.parse(z.open(opf_path))
 69 |             metadata: Dict[str, Any] = {
 70 |                 "title": self._get_text_from_node(opf_dom, "dc:title"),
 71 |                 "authors": self._get_all_texts_from_nodes(opf_dom, "dc:creator"),
 72 |                 "language": self._get_text_from_node(opf_dom, "dc:language"),
 73 |                 "publisher": self._get_text_from_node(opf_dom, "dc:publisher"),
 74 |                 "date": self._get_text_from_node(opf_dom, "dc:date"),
 75 |                 "description": self._get_text_from_node(opf_dom, "dc:description"),
 76 |                 "identifier": self._get_text_from_node(opf_dom, "dc:identifier"),
 77 |             }
 78 | 
 79 |             # Extract manifest items (ID → href mapping)
 80 |             manifest = {
 81 |                 item.getAttribute("id"): item.getAttribute("href")
 82 |                 for item in opf_dom.getElementsByTagName("item")
 83 |             }
 84 | 
 85 |             # Extract spine order (ID refs)
 86 |             spine_items = opf_dom.getElementsByTagName("itemref")
 87 |             spine_order = [item.getAttribute("idref") for item in spine_items]
 88 | 
 89 |             # Convert spine order to actual file paths
 90 |             base_path = "/".join(
 91 |                 opf_path.split("/")[:-1]
 92 |             )  # Get base directory of content.opf
 93 |             spine = [
 94 |                 f"{base_path}/{manifest[item_id]}" if base_path else manifest[item_id]
 95 |                 for item_id in spine_order
 96 |                 if item_id in manifest
 97 |             ]
 98 | 
 99 |             # Extract and convert the content
100 |             markdown_content: List[str] = []
101 |             for file in spine:
102 |                 if file in z.namelist():
103 |                     with z.open(file) as f:
104 |                         filename = os.path.basename(file)
105 |                         extension = os.path.splitext(filename)[1].lower()
106 |                         mimetype = MIME_TYPE_MAPPING.get(extension)
107 |                         converted_content = self._html_converter.convert(
108 |                             f,
109 |                             StreamInfo(
110 |                                 mimetype=mimetype,
111 |                                 extension=extension,
112 |                                 filename=filename,
113 |                             ),
114 |                         )
115 |                         markdown_content.append(converted_content.markdown.strip())
116 | 
117 |             # Format and add the metadata
118 |             metadata_markdown = []
119 |             for key, value in metadata.items():
120 |                 if isinstance(value, list):
121 |                     value = ", ".join(value)
122 |                 if value:
123 |                     metadata_markdown.append(f"**{key.capitalize()}:** {value}")
124 | 
125 |             markdown_content.insert(0, "\n".join(metadata_markdown))
126 | 
127 |             return DocumentConverterResult(
128 |                 markdown="\n\n".join(markdown_content), title=metadata["title"]
129 |             )
130 | 
131 |     def _get_text_from_node(self, dom: minidom.Document, tag_name: str) -> str | None:
132 |         """Convenience function to extract a single occurrence of a tag (e.g., title)."""
133 |         texts = self._get_all_texts_from_nodes(dom, tag_name)
134 |         if len(texts) > 0:
135 |             return texts[0]
136 |         else:
137 |             return None
138 | 
139 |     def _get_all_texts_from_nodes(
140 |         self, dom: minidom.Document, tag_name: str
141 |     ) -> List[str]:
142 |         """Helper function to extract all occurrences of a tag (e.g., multiple authors)."""
143 |         texts: List[str] = []
144 |         for node in dom.getElementsByTagName(tag_name):
145 |             if node.firstChild and hasattr(node.firstChild, "nodeValue"):
146 |                 texts.append(node.firstChild.nodeValue.strip())
147 |         return texts
148 | 


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/converters/_exiftool.py:
--------------------------------------------------------------------------------
 1 | import json
 2 | import subprocess
 3 | import locale
 4 | import sys
 5 | import shutil
 6 | import os
 7 | import warnings
 8 | from typing import BinaryIO, Any, Union
 9 | 
10 | 
11 | def exiftool_metadata(
12 |     file_stream: BinaryIO,
13 |     *,
14 |     exiftool_path: Union[str, None],
15 | ) -> Any:  # Need a better type for json data
16 |     # Nothing to do
17 |     if not exiftool_path:
18 |         return {}
19 | 
20 |     # Run exiftool
21 |     cur_pos = file_stream.tell()
22 |     try:
23 |         output = subprocess.run(
24 |             [exiftool_path, "-json", "-"],
25 |             input=file_stream.read(),
26 |             capture_output=True,
27 |             text=False,
28 |         ).stdout
29 | 
30 |         return json.loads(
31 |             output.decode(locale.getpreferredencoding(False)),
32 |         )[0]
33 |     finally:
34 |         file_stream.seek(cur_pos)
35 | 


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/converters/_html_converter.py:
--------------------------------------------------------------------------------
 1 | import io
 2 | from typing import Any, BinaryIO, Optional
 3 | from bs4 import BeautifulSoup
 4 | 
 5 | from .._base_converter import DocumentConverter, DocumentConverterResult
 6 | from .._stream_info import StreamInfo
 7 | from ._markdownify import _CustomMarkdownify
 8 | 
 9 | ACCEPTED_MIME_TYPE_PREFIXES = [
10 |     "text/html",
11 |     "application/xhtml",
12 | ]
13 | 
14 | ACCEPTED_FILE_EXTENSIONS = [
15 |     ".html",
16 |     ".htm",
17 | ]
18 | 
19 | 
20 | class HtmlConverter(DocumentConverter):
21 |     """Anything with content type text/html"""
22 | 
23 |     def accepts(
24 |         self,
25 |         file_stream: BinaryIO,
26 |         stream_info: StreamInfo,
27 |         **kwargs: Any,  # Options to pass to the converter
28 |     ) -> bool:
29 |         mimetype = (stream_info.mimetype or "").lower()
30 |         extension = (stream_info.extension or "").lower()
31 | 
32 |         if extension in ACCEPTED_FILE_EXTENSIONS:
33 |             return True
34 | 
35 |         for prefix in ACCEPTED_MIME_TYPE_PREFIXES:
36 |             if mimetype.startswith(prefix):
37 |                 return True
38 | 
39 |         return False
40 | 
41 |     def convert(
42 |         self,
43 |         file_stream: BinaryIO,
44 |         stream_info: StreamInfo,
45 |         **kwargs: Any,  # Options to pass to the converter
46 |     ) -> DocumentConverterResult:
47 |         # Parse the stream
48 |         encoding = "utf-8" if stream_info.charset is None else stream_info.charset
49 |         soup = BeautifulSoup(file_stream, "html.parser", from_encoding=encoding)
50 | 
51 |         # Remove javascript and style blocks
52 |         for script in soup(["script", "style"]):
53 |             script.extract()
54 | 
55 |         # Print only the main content
56 |         body_elm = soup.find("body")
57 |         webpage_text = ""
58 |         if body_elm:
59 |             webpage_text = _CustomMarkdownify(**kwargs).convert_soup(body_elm)
60 |         else:
61 |             webpage_text = _CustomMarkdownify(**kwargs).convert_soup(soup)
62 | 
63 |         assert isinstance(webpage_text, str)
64 | 
65 |         # remove leading and trailing \n
66 |         webpage_text = webpage_text.strip()
67 | 
68 |         return DocumentConverterResult(
69 |             markdown=webpage_text,
70 |             title=None if soup.title is None else soup.title.string,
71 |         )
72 | 
73 |     def convert_string(
74 |         self, html_content: str, *, url: Optional[str] = None, **kwargs
75 |     ) -> DocumentConverterResult:
76 |         """
77 |         Non-standard convenience method to convert a string to markdown.
78 |         Given that many converters produce HTML as intermediate output, this
79 |         allows for easy conversion of HTML to markdown.
80 |         """
81 |         return self.convert(
82 |             file_stream=io.BytesIO(html_content.encode("utf-8")),
83 |             stream_info=StreamInfo(
84 |                 mimetype="text/html",
85 |                 extension=".html",
86 |                 charset="utf-8",
87 |                 url=url,
88 |             ),
89 |             **kwargs,
90 |         )
91 | 


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/converters/_image_converter.py:
--------------------------------------------------------------------------------
  1 | from typing import BinaryIO, Any, Union
  2 | import base64
  3 | import mimetypes
  4 | from ._exiftool import exiftool_metadata
  5 | from .._base_converter import DocumentConverter, DocumentConverterResult
  6 | from .._stream_info import StreamInfo
  7 | 
  8 | ACCEPTED_MIME_TYPE_PREFIXES = [
  9 |     "image/jpeg",
 10 |     "image/png",
 11 | ]
 12 | 
 13 | ACCEPTED_FILE_EXTENSIONS = [".jpg", ".jpeg", ".png"]
 14 | 
 15 | 
 16 | class ImageConverter(DocumentConverter):
 17 |     """
 18 |     Converts images to markdown via extraction of metadata (if `exiftool` is installed), and description via a multimodal LLM (if an llm_client is configured).
 19 |     """
 20 | 
 21 |     def accepts(
 22 |         self,
 23 |         file_stream: BinaryIO,
 24 |         stream_info: StreamInfo,
 25 |         **kwargs: Any,
 26 |     ) -> bool:
 27 |         mimetype = (stream_info.mimetype or "").lower()
 28 |         extension = (stream_info.extension or "").lower()
 29 | 
 30 |         if extension in ACCEPTED_FILE_EXTENSIONS:
 31 |             return True
 32 | 
 33 |         for prefix in ACCEPTED_MIME_TYPE_PREFIXES:
 34 |             if mimetype.startswith(prefix):
 35 |                 return True
 36 | 
 37 |         return False
 38 | 
 39 |     def convert(
 40 |         self,
 41 |         file_stream: BinaryIO,
 42 |         stream_info: StreamInfo,
 43 |         **kwargs: Any,  # Options to pass to the converter
 44 |     ) -> DocumentConverterResult:
 45 |         md_content = ""
 46 | 
 47 |         # Add metadata
 48 |         metadata = exiftool_metadata(
 49 |             file_stream, exiftool_path=kwargs.get("exiftool_path")
 50 |         )
 51 | 
 52 |         if metadata:
 53 |             for f in [
 54 |                 "ImageSize",
 55 |                 "Title",
 56 |                 "Caption",
 57 |                 "Description",
 58 |                 "Keywords",
 59 |                 "Artist",
 60 |                 "Author",
 61 |                 "DateTimeOriginal",
 62 |                 "CreateDate",
 63 |                 "GPSPosition",
 64 |             ]:
 65 |                 if f in metadata:
 66 |                     md_content += f"{f}: {metadata[f]}\n"
 67 | 
 68 |         # Try describing the image with GPT
 69 |         llm_client = kwargs.get("llm_client")
 70 |         llm_model = kwargs.get("llm_model")
 71 |         if llm_client is not None and llm_model is not None:
 72 |             llm_description = self._get_llm_description(
 73 |                 file_stream,
 74 |                 stream_info,
 75 |                 client=llm_client,
 76 |                 model=llm_model,
 77 |                 prompt=kwargs.get("llm_prompt"),
 78 |             )
 79 | 
 80 |             if llm_description is not None:
 81 |                 md_content += "\n# Description:\n" + llm_description.strip() + "\n"
 82 | 
 83 |         return DocumentConverterResult(
 84 |             markdown=md_content,
 85 |         )
 86 | 
 87 |     def _get_llm_description(
 88 |         self,
 89 |         file_stream: BinaryIO,
 90 |         stream_info: StreamInfo,
 91 |         *,
 92 |         client,
 93 |         model,
 94 |         prompt=None,
 95 |     ) -> Union[None, str]:
 96 |         if prompt is None or prompt.strip() == "":
 97 |             prompt = "Write a detailed caption for this image."
 98 | 
 99 |         # Get the content type
100 |         content_type = stream_info.mimetype
101 |         if not content_type:
102 |             content_type, _ = mimetypes.guess_type(
103 |                 "_dummy" + (stream_info.extension or "")
104 |             )
105 |         if not content_type:
106 |             content_type = "application/octet-stream"
107 | 
108 |         # Convert to base64
109 |         cur_pos = file_stream.tell()
110 |         try:
111 |             base64_image = base64.b64encode(file_stream.read()).decode("utf-8")
112 |         except Exception as e:
113 |             return None
114 |         finally:
115 |             file_stream.seek(cur_pos)
116 | 
117 |         # Prepare the data-uri
118 |         data_uri = f"data:{content_type};base64,{base64_image}"
119 | 
120 |         # Prepare the OpenAI API request
121 |         messages = [
122 |             {
123 |                 "role": "user",
124 |                 "content": [
125 |                     {"type": "text", "text": prompt},
126 |                     {
127 |                         "type": "image_url",
128 |                         "image_url": {
129 |                             "url": data_uri,
130 |                         },
131 |                     },
132 |                 ],
133 |             }
134 |         ]
135 | 
136 |         # Call the OpenAI API
137 |         response = client.chat.completions.create(model=model, messages=messages)
138 |         return response.choices[0].message.content
139 | 


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/converters/_ipynb_converter.py:
--------------------------------------------------------------------------------
 1 | from typing import BinaryIO, Any
 2 | import json
 3 | 
 4 | from .._base_converter import DocumentConverter, DocumentConverterResult
 5 | from .._exceptions import FileConversionException
 6 | from .._stream_info import StreamInfo
 7 | 
 8 | CANDIDATE_MIME_TYPE_PREFIXES = [
 9 |     "application/json",
10 | ]
11 | 
12 | ACCEPTED_FILE_EXTENSIONS = [".ipynb"]
13 | 
14 | 
15 | class IpynbConverter(DocumentConverter):
16 |     """Converts Jupyter Notebook (.ipynb) files to Markdown."""
17 | 
18 |     def accepts(
19 |         self,
20 |         file_stream: BinaryIO,
21 |         stream_info: StreamInfo,
22 |         **kwargs: Any,  # Options to pass to the converter
23 |     ) -> bool:
24 |         mimetype = (stream_info.mimetype or "").lower()
25 |         extension = (stream_info.extension or "").lower()
26 | 
27 |         if extension in ACCEPTED_FILE_EXTENSIONS:
28 |             return True
29 | 
30 |         for prefix in CANDIDATE_MIME_TYPE_PREFIXES:
31 |             if mimetype.startswith(prefix):
32 |                 # Read further to see if it's a notebook
33 |                 cur_pos = file_stream.tell()
34 |                 try:
35 |                     encoding = stream_info.charset or "utf-8"
36 |                     notebook_content = file_stream.read().decode(encoding)
37 |                     return (
38 |                         "nbformat" in notebook_content
39 |                         and "nbformat_minor" in notebook_content
40 |                     )
41 |                 finally:
42 |                     file_stream.seek(cur_pos)
43 | 
44 |         return False
45 | 
46 |     def convert(
47 |         self,
48 |         file_stream: BinaryIO,
49 |         stream_info: StreamInfo,
50 |         **kwargs: Any,  # Options to pass to the converter
51 |     ) -> DocumentConverterResult:
52 |         # Parse and convert the notebook
53 |         result = None
54 | 
55 |         encoding = stream_info.charset or "utf-8"
56 |         notebook_content = file_stream.read().decode(encoding=encoding)
57 |         return self._convert(json.loads(notebook_content))
58 | 
59 |     def _convert(self, notebook_content: dict) -> DocumentConverterResult:
60 |         """Helper function that converts notebook JSON content to Markdown."""
61 |         try:
62 |             md_output = []
63 |             title = None
64 | 
65 |             for cell in notebook_content.get("cells", []):
66 |                 cell_type = cell.get("cell_type", "")
67 |                 source_lines = cell.get("source", [])
68 | 
69 |                 if cell_type == "markdown":
70 |                     md_output.append("".join(source_lines))
71 | 
72 |                     # Extract the first # heading as title if not already found
73 |                     if title is None:
74 |                         for line in source_lines:
75 |                             if line.startswith("# "):
76 |                                 title = line.lstrip("# ").strip()
77 |                                 break
78 | 
79 |                 elif cell_type == "code":
80 |                     # Code cells are wrapped in Markdown code blocks
81 |                     md_output.append(f"```python\n{''.join(source_lines)}\n```")
82 |                 elif cell_type == "raw":
83 |                     md_output.append(f"```\n{''.join(source_lines)}\n```")
84 | 
85 |             md_text = "\n\n".join(md_output)
86 | 
87 |             # Check for title in notebook metadata
88 |             title = notebook_content.get("metadata", {}).get("title", title)
89 | 
90 |             return DocumentConverterResult(
91 |                 markdown=md_text,
92 |                 title=title,
93 |             )
94 | 
95 |         except Exception as e:
96 |             raise FileConversionException(
97 |                 f"Error converting .ipynb file: {str(e)}"
98 |             ) from e
99 | 


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/converters/_llm_caption.py:
--------------------------------------------------------------------------------
 1 | from typing import BinaryIO, Any, Union
 2 | import base64
 3 | import mimetypes
 4 | from .._stream_info import StreamInfo
 5 | 
 6 | 
 7 | def llm_caption(
 8 |     file_stream: BinaryIO, stream_info: StreamInfo, *, client, model, prompt=None
 9 | ) -> Union[None, str]:
10 |     if prompt is None or prompt.strip() == "":
11 |         prompt = "Write a detailed caption for this image."
12 | 
13 |     # Get the content type
14 |     content_type = stream_info.mimetype
15 |     if not content_type:
16 |         content_type, _ = mimetypes.guess_type("_dummy" + (stream_info.extension or ""))
17 |     if not content_type:
18 |         content_type = "application/octet-stream"
19 | 
20 |     # Convert to base64
21 |     cur_pos = file_stream.tell()
22 |     try:
23 |         base64_image = base64.b64encode(file_stream.read()).decode("utf-8")
24 |     except Exception as e:
25 |         return None
26 |     finally:
27 |         file_stream.seek(cur_pos)
28 | 
29 |     # Prepare the data-uri
30 |     data_uri = f"data:{content_type};base64,{base64_image}"
31 | 
32 |     # Prepare the OpenAI API request
33 |     messages = [
34 |         {
35 |             "role": "user",
36 |             "content": [
37 |                 {"type": "text", "text": prompt},
38 |                 {
39 |                     "type": "image_url",
40 |                     "image_url": {
41 |                         "url": data_uri,
42 |                     },
43 |                 },
44 |             ],
45 |         }
46 |     ]
47 | 
48 |     # Call the OpenAI API
49 |     response = client.chat.completions.create(model=model, messages=messages)
50 |     return response.choices[0].message.content
51 | 


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/converters/_markdownify.py:
--------------------------------------------------------------------------------
  1 | import re
  2 | import markdownify
  3 | 
  4 | from typing import Any, Optional
  5 | from urllib.parse import quote, unquote, urlparse, urlunparse
  6 | 
  7 | 
  8 | class _CustomMarkdownify(markdownify.MarkdownConverter):
  9 |     """
 10 |     A custom version of markdownify's MarkdownConverter. Changes include:
 11 | 
 12 |     - Altering the default heading style to use '#', '##', etc.
 13 |     - Removing javascript hyperlinks.
 14 |     - Truncating images with large data:uri sources.
 15 |     - Ensuring URIs are properly escaped, and do not conflict with Markdown syntax
 16 |     """
 17 | 
 18 |     def __init__(self, **options: Any):
 19 |         options["heading_style"] = options.get("heading_style", markdownify.ATX)
 20 |         options["keep_data_uris"] = options.get("keep_data_uris", False)
 21 |         # Explicitly cast options to the expected type if necessary
 22 |         super().__init__(**options)
 23 | 
 24 |     def convert_hn(
 25 |         self,
 26 |         n: int,
 27 |         el: Any,
 28 |         text: str,
 29 |         convert_as_inline: Optional[bool] = False,
 30 |         **kwargs,
 31 |     ) -> str:
 32 |         """Same as usual, but be sure to start with a new line"""
 33 |         if not convert_as_inline:
 34 |             if not re.search(r"^\n", text):
 35 |                 return "\n" + super().convert_hn(n, el, text, convert_as_inline)  # type: ignore
 36 | 
 37 |         return super().convert_hn(n, el, text, convert_as_inline)  # type: ignore
 38 | 
 39 |     def convert_a(
 40 |         self,
 41 |         el: Any,
 42 |         text: str,
 43 |         convert_as_inline: Optional[bool] = False,
 44 |         **kwargs,
 45 |     ):
 46 |         """Same as usual converter, but removes Javascript links and escapes URIs."""
 47 |         prefix, suffix, text = markdownify.chomp(text)  # type: ignore
 48 |         if not text:
 49 |             return ""
 50 | 
 51 |         if el.find_parent("pre") is not None:
 52 |             return text
 53 | 
 54 |         href = el.get("href")
 55 |         title = el.get("title")
 56 | 
 57 |         # Escape URIs and skip non-http or file schemes
 58 |         if href:
 59 |             try:
 60 |                 parsed_url = urlparse(href)  # type: ignore
 61 |                 if parsed_url.scheme and parsed_url.scheme.lower() not in ["http", "https", "file"]:  # type: ignore
 62 |                     return "%s%s%s" % (prefix, text, suffix)
 63 |                 href = urlunparse(parsed_url._replace(path=quote(unquote(parsed_url.path))))  # type: ignore
 64 |             except ValueError:  # It's not clear if this ever gets thrown
 65 |                 return "%s%s%s" % (prefix, text, suffix)
 66 | 
 67 |         # For the replacement see #29: text nodes underscores are escaped
 68 |         if (
 69 |             self.options["autolinks"]
 70 |             and text.replace(r"\_", "_") == href
 71 |             and not title
 72 |             and not self.options["default_title"]
 73 |         ):
 74 |             # Shortcut syntax
 75 |             return "<%s>" % href
 76 |         if self.options["default_title"] and not title:
 77 |             title = href
 78 |         title_part = ' "%s"' % title.replace('"', r"\"") if title else ""
 79 |         return (
 80 |             "%s[%s](%s%s)%s" % (prefix, text, href, title_part, suffix)
 81 |             if href
 82 |             else text
 83 |         )
 84 | 
 85 |     def convert_img(
 86 |         self,
 87 |         el: Any,
 88 |         text: str,
 89 |         convert_as_inline: Optional[bool] = False,
 90 |         **kwargs,
 91 |     ) -> str:
 92 |         """Same as usual converter, but removes data URIs"""
 93 | 
 94 |         alt = el.attrs.get("alt", None) or ""
 95 |         src = el.attrs.get("src", None) or ""
 96 |         title = el.attrs.get("title", None) or ""
 97 |         title_part = ' "%s"' % title.replace('"', r"\"") if title else ""
 98 |         if (
 99 |             convert_as_inline
100 |             and el.parent.name not in self.options["keep_inline_images_in"]
101 |         ):
102 |             return alt
103 | 
104 |         # Remove dataURIs
105 |         if src.startswith("data:") and not self.options["keep_data_uris"]:
106 |             src = src.split(",")[0] + "..."
107 | 
108 |         return "![%s](%s%s)" % (alt, src, title_part)
109 | 
110 |     def convert_soup(self, soup: Any) -> str:
111 |         return super().convert_soup(soup)  # type: ignore
112 | 


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/converters/_outlook_msg_converter.py:
--------------------------------------------------------------------------------
  1 | import sys
  2 | from typing import Any, Union, BinaryIO
  3 | from .._stream_info import StreamInfo
  4 | from .._base_converter import DocumentConverter, DocumentConverterResult
  5 | from .._exceptions import MissingDependencyException, MISSING_DEPENDENCY_MESSAGE
  6 | 
  7 | # Try loading optional (but in this case, required) dependencies
  8 | # Save reporting of any exceptions for later
  9 | _dependency_exc_info = None
 10 | olefile = None
 11 | try:
 12 |     import olefile  # type: ignore[no-redef]
 13 | except ImportError:
 14 |     # Preserve the error and stack trace for later
 15 |     _dependency_exc_info = sys.exc_info()
 16 | 
 17 | ACCEPTED_MIME_TYPE_PREFIXES = [
 18 |     "application/vnd.ms-outlook",
 19 | ]
 20 | 
 21 | ACCEPTED_FILE_EXTENSIONS = [".msg"]
 22 | 
 23 | 
 24 | class OutlookMsgConverter(DocumentConverter):
 25 |     """Converts Outlook .msg files to markdown by extracting email metadata and content.
 26 | 
 27 |     Uses the olefile package to parse the .msg file structure and extract:
 28 |     - Email headers (From, To, Subject)
 29 |     - Email body content
 30 |     """
 31 | 
 32 |     def accepts(
 33 |         self,
 34 |         file_stream: BinaryIO,
 35 |         stream_info: StreamInfo,
 36 |         **kwargs: Any,  # Options to pass to the converter
 37 |     ) -> bool:
 38 |         mimetype = (stream_info.mimetype or "").lower()
 39 |         extension = (stream_info.extension or "").lower()
 40 | 
 41 |         # Check the extension and mimetype
 42 |         if extension in ACCEPTED_FILE_EXTENSIONS:
 43 |             return True
 44 | 
 45 |         for prefix in ACCEPTED_MIME_TYPE_PREFIXES:
 46 |             if mimetype.startswith(prefix):
 47 |                 return True
 48 | 
 49 |         # Brute force, check if we have an OLE file
 50 |         cur_pos = file_stream.tell()
 51 |         try:
 52 |             if olefile and not olefile.isOleFile(file_stream):
 53 |                 return False
 54 |         finally:
 55 |             file_stream.seek(cur_pos)
 56 | 
 57 |         # Brue force, check if it's an Outlook file
 58 |         try:
 59 |             if olefile is not None:
 60 |                 msg = olefile.OleFileIO(file_stream)
 61 |                 toc = "\n".join([str(stream) for stream in msg.listdir()])
 62 |                 return (
 63 |                     "__properties_version1.0" in toc
 64 |                     and "__recip_version1.0_#00000000" in toc
 65 |                 )
 66 |         except Exception as e:
 67 |             pass
 68 |         finally:
 69 |             file_stream.seek(cur_pos)
 70 | 
 71 |         return False
 72 | 
 73 |     def convert(
 74 |         self,
 75 |         file_stream: BinaryIO,
 76 |         stream_info: StreamInfo,
 77 |         **kwargs: Any,  # Options to pass to the converter
 78 |     ) -> DocumentConverterResult:
 79 |         # Check: the dependencies
 80 |         if _dependency_exc_info is not None:
 81 |             raise MissingDependencyException(
 82 |                 MISSING_DEPENDENCY_MESSAGE.format(
 83 |                     converter=type(self).__name__,
 84 |                     extension=".msg",
 85 |                     feature="outlook",
 86 |                 )
 87 |             ) from _dependency_exc_info[
 88 |                 1
 89 |             ].with_traceback(  # type: ignore[union-attr]
 90 |                 _dependency_exc_info[2]
 91 |             )
 92 | 
 93 |         assert (
 94 |             olefile is not None
 95 |         )  # If we made it this far, olefile should be available
 96 |         msg = olefile.OleFileIO(file_stream)
 97 | 
 98 |         # Extract email metadata
 99 |         md_content = "# Email Message\n\n"
100 | 
101 |         # Get headers
102 |         headers = {
103 |             "From": self._get_stream_data(msg, "__substg1.0_0C1F001F"),
104 |             "To": self._get_stream_data(msg, "__substg1.0_0E04001F"),
105 |             "Subject": self._get_stream_data(msg, "__substg1.0_0037001F"),
106 |         }
107 | 
108 |         # Add headers to markdown
109 |         for key, value in headers.items():
110 |             if value:
111 |                 md_content += f"**{key}:** {value}\n"
112 | 
113 |         md_content += "\n## Content\n\n"
114 | 
115 |         # Get email body
116 |         body = self._get_stream_data(msg, "__substg1.0_1000001F")
117 |         if body:
118 |             md_content += body
119 | 
120 |         msg.close()
121 | 
122 |         return DocumentConverterResult(
123 |             markdown=md_content.strip(),
124 |             title=headers.get("Subject"),
125 |         )
126 | 
127 |     def _get_stream_data(self, msg: Any, stream_path: str) -> Union[str, None]:
128 |         """Helper to safely extract and decode stream data from the MSG file."""
129 |         assert olefile is not None
130 |         assert isinstance(
131 |             msg, olefile.OleFileIO
132 |         )  # Ensure msg is of the correct type (type hinting is not possible with the optional olefile package)
133 | 
134 |         try:
135 |             if msg.exists(stream_path):
136 |                 data = msg.openstream(stream_path).read()
137 |                 # Try UTF-16 first (common for .msg files)
138 |                 try:
139 |                     return data.decode("utf-16-le").strip()
140 |                 except UnicodeDecodeError:
141 |                     # Fall back to UTF-8
142 |                     try:
143 |                         return data.decode("utf-8").strip()
144 |                     except UnicodeDecodeError:
145 |                         # Last resort - ignore errors
146 |                         return data.decode("utf-8", errors="ignore").strip()
147 |         except Exception:
148 |             pass
149 |         return None
150 | 


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/converters/_pdf_converter.py:
--------------------------------------------------------------------------------
 1 | import sys
 2 | import io
 3 | 
 4 | from typing import BinaryIO, Any
 5 | 
 6 | 
 7 | from ._html_converter import HtmlConverter
 8 | from .._base_converter import DocumentConverter, DocumentConverterResult
 9 | from .._stream_info import StreamInfo
10 | from .._exceptions import MissingDependencyException, MISSING_DEPENDENCY_MESSAGE
11 | 
12 | 
13 | # Try loading optional (but in this case, required) dependencies
14 | # Save reporting of any exceptions for later
15 | _dependency_exc_info = None
16 | try:
17 |     import pdfminer
18 |     import pdfminer.high_level
19 | except ImportError:
20 |     # Preserve the error and stack trace for later
21 |     _dependency_exc_info = sys.exc_info()
22 | 
23 | 
24 | ACCEPTED_MIME_TYPE_PREFIXES = [
25 |     "application/pdf",
26 |     "application/x-pdf",
27 | ]
28 | 
29 | ACCEPTED_FILE_EXTENSIONS = [".pdf"]
30 | 
31 | 
32 | class PdfConverter(DocumentConverter):
33 |     """
34 |     Converts PDFs to Markdown. Most style information is ignored, so the results are essentially plain-text.
35 |     """
36 | 
37 |     def accepts(
38 |         self,
39 |         file_stream: BinaryIO,
40 |         stream_info: StreamInfo,
41 |         **kwargs: Any,  # Options to pass to the converter
42 |     ) -> bool:
43 |         mimetype = (stream_info.mimetype or "").lower()
44 |         extension = (stream_info.extension or "").lower()
45 | 
46 |         if extension in ACCEPTED_FILE_EXTENSIONS:
47 |             return True
48 | 
49 |         for prefix in ACCEPTED_MIME_TYPE_PREFIXES:
50 |             if mimetype.startswith(prefix):
51 |                 return True
52 | 
53 |         return False
54 | 
55 |     def convert(
56 |         self,
57 |         file_stream: BinaryIO,
58 |         stream_info: StreamInfo,
59 |         **kwargs: Any,  # Options to pass to the converter
60 |     ) -> DocumentConverterResult:
61 |         # Check the dependencies
62 |         if _dependency_exc_info is not None:
63 |             raise MissingDependencyException(
64 |                 MISSING_DEPENDENCY_MESSAGE.format(
65 |                     converter=type(self).__name__,
66 |                     extension=".pdf",
67 |                     feature="pdf",
68 |                 )
69 |             ) from _dependency_exc_info[
70 |                 1
71 |             ].with_traceback(  # type: ignore[union-attr]
72 |                 _dependency_exc_info[2]
73 |             )
74 | 
75 |         assert isinstance(file_stream, io.IOBase)  # for mypy
76 |         return DocumentConverterResult(
77 |             markdown=pdfminer.high_level.extract_text(file_stream),
78 |         )
79 | 


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/converters/_plain_text_converter.py:
--------------------------------------------------------------------------------
 1 | import sys
 2 | 
 3 | from typing import BinaryIO, Any
 4 | from charset_normalizer import from_bytes
 5 | from .._base_converter import DocumentConverter, DocumentConverterResult
 6 | from .._stream_info import StreamInfo
 7 | 
 8 | # Try loading optional (but in this case, required) dependencies
 9 | # Save reporting of any exceptions for later
10 | _dependency_exc_info = None
11 | try:
12 |     import mammoth
13 | except ImportError:
14 |     # Preserve the error and stack trace for later
15 |     _dependency_exc_info = sys.exc_info()
16 | 
17 | ACCEPTED_MIME_TYPE_PREFIXES = [
18 |     "text/",
19 |     "application/json",
20 |     "application/markdown",
21 | ]
22 | 
23 | ACCEPTED_FILE_EXTENSIONS = [
24 |     ".txt",
25 |     ".text",
26 |     ".md",
27 |     ".markdown",
28 |     ".json",
29 |     ".jsonl",
30 | ]
31 | 
32 | 
33 | class PlainTextConverter(DocumentConverter):
34 |     """Anything with content type text/plain"""
35 | 
36 |     def accepts(
37 |         self,
38 |         file_stream: BinaryIO,
39 |         stream_info: StreamInfo,
40 |         **kwargs: Any,  # Options to pass to the converter
41 |     ) -> bool:
42 |         mimetype = (stream_info.mimetype or "").lower()
43 |         extension = (stream_info.extension or "").lower()
44 | 
45 |         # If we have a charset, we can safely assume it's text
46 |         # With Magika in the earlier stages, this handles most cases
47 |         if stream_info.charset is not None:
48 |             return True
49 | 
50 |         # Otherwise, check the mimetype and extension
51 |         if extension in ACCEPTED_FILE_EXTENSIONS:
52 |             return True
53 | 
54 |         for prefix in ACCEPTED_MIME_TYPE_PREFIXES:
55 |             if mimetype.startswith(prefix):
56 |                 return True
57 | 
58 |         return False
59 | 
60 |     def convert(
61 |         self,
62 |         file_stream: BinaryIO,
63 |         stream_info: StreamInfo,
64 |         **kwargs: Any,  # Options to pass to the converter
65 |     ) -> DocumentConverterResult:
66 |         if stream_info.charset:
67 |             text_content = file_stream.read().decode(stream_info.charset)
68 |         else:
69 |             text_content = str(from_bytes(file_stream.read()).best())
70 | 
71 |         return DocumentConverterResult(markdown=text_content)
72 | 


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/converters/_pptx_converter.py:
--------------------------------------------------------------------------------
  1 | import sys
  2 | import base64
  3 | import os
  4 | import io
  5 | import re
  6 | import html
  7 | 
  8 | from typing import BinaryIO, Any
  9 | from operator import attrgetter
 10 | 
 11 | from ._html_converter import HtmlConverter
 12 | from ._llm_caption import llm_caption
 13 | from .._base_converter import DocumentConverter, DocumentConverterResult
 14 | from .._stream_info import StreamInfo
 15 | from .._exceptions import MissingDependencyException, MISSING_DEPENDENCY_MESSAGE
 16 | 
 17 | # Try loading optional (but in this case, required) dependencies
 18 | # Save reporting of any exceptions for later
 19 | _dependency_exc_info = None
 20 | try:
 21 |     import pptx
 22 | except ImportError:
 23 |     # Preserve the error and stack trace for later
 24 |     _dependency_exc_info = sys.exc_info()
 25 | 
 26 | 
 27 | ACCEPTED_MIME_TYPE_PREFIXES = [
 28 |     "application/vnd.openxmlformats-officedocument.presentationml",
 29 | ]
 30 | 
 31 | ACCEPTED_FILE_EXTENSIONS = [".pptx"]
 32 | 
 33 | 
 34 | class PptxConverter(DocumentConverter):
 35 |     """
 36 |     Converts PPTX files to Markdown. Supports heading, tables and images with alt text.
 37 |     """
 38 | 
 39 |     def __init__(self):
 40 |         super().__init__()
 41 |         self._html_converter = HtmlConverter()
 42 | 
 43 |     def accepts(
 44 |         self,
 45 |         file_stream: BinaryIO,
 46 |         stream_info: StreamInfo,
 47 |         **kwargs: Any,  # Options to pass to the converter
 48 |     ) -> bool:
 49 |         mimetype = (stream_info.mimetype or "").lower()
 50 |         extension = (stream_info.extension or "").lower()
 51 | 
 52 |         if extension in ACCEPTED_FILE_EXTENSIONS:
 53 |             return True
 54 | 
 55 |         for prefix in ACCEPTED_MIME_TYPE_PREFIXES:
 56 |             if mimetype.startswith(prefix):
 57 |                 return True
 58 | 
 59 |         return False
 60 | 
 61 |     def convert(
 62 |         self,
 63 |         file_stream: BinaryIO,
 64 |         stream_info: StreamInfo,
 65 |         **kwargs: Any,  # Options to pass to the converter
 66 |     ) -> DocumentConverterResult:
 67 |         # Check the dependencies
 68 |         if _dependency_exc_info is not None:
 69 |             raise MissingDependencyException(
 70 |                 MISSING_DEPENDENCY_MESSAGE.format(
 71 |                     converter=type(self).__name__,
 72 |                     extension=".pptx",
 73 |                     feature="pptx",
 74 |                 )
 75 |             ) from _dependency_exc_info[
 76 |                 1
 77 |             ].with_traceback(  # type: ignore[union-attr]
 78 |                 _dependency_exc_info[2]
 79 |             )
 80 | 
 81 |         # Perform the conversion
 82 |         presentation = pptx.Presentation(file_stream)
 83 |         md_content = ""
 84 |         slide_num = 0
 85 |         for slide in presentation.slides:
 86 |             slide_num += 1
 87 | 
 88 |             md_content += f"\n\n<!-- Slide number: {slide_num} -->\n"
 89 | 
 90 |             title = slide.shapes.title
 91 | 
 92 |             def get_shape_content(shape, **kwargs):
 93 |                 nonlocal md_content
 94 |                 # Pictures
 95 |                 if self._is_picture(shape):
 96 |                     # https://github.com/scanny/python-pptx/pull/512#issuecomment-1713100069
 97 | 
 98 |                     llm_description = ""
 99 |                     alt_text = ""
100 | 
101 |                     # Potentially generate a description using an LLM
102 |                     llm_client = kwargs.get("llm_client")
103 |                     llm_model = kwargs.get("llm_model")
104 |                     if llm_client is not None and llm_model is not None:
105 |                         # Prepare a file_stream and stream_info for the image data
106 |                         image_filename = shape.image.filename
107 |                         image_extension = None
108 |                         if image_filename:
109 |                             image_extension = os.path.splitext(image_filename)[1]
110 |                         image_stream_info = StreamInfo(
111 |                             mimetype=shape.image.content_type,
112 |                             extension=image_extension,
113 |                             filename=image_filename,
114 |                         )
115 | 
116 |                         image_stream = io.BytesIO(shape.image.blob)
117 | 
118 |                         # Caption the image
119 |                         try:
120 |                             llm_description = llm_caption(
121 |                                 image_stream,
122 |                                 image_stream_info,
123 |                                 client=llm_client,
124 |                                 model=llm_model,
125 |                                 prompt=kwargs.get("llm_prompt"),
126 |                             )
127 |                         except Exception:
128 |                             # Unable to generate a description
129 |                             pass
130 | 
131 |                     # Also grab any description embedded in the deck
132 |                     try:
133 |                         alt_text = shape._element._nvXxPr.cNvPr.attrib.get("descr", "")
134 |                     except Exception:
135 |                         # Unable to get alt text
136 |                         pass
137 | 
138 |                     # Prepare the alt, escaping any special characters
139 |                     alt_text = "\n".join([llm_description, alt_text]) or shape.name
140 |                     alt_text = re.sub(r"[\r\n\[\]]", " ", alt_text)
141 |                     alt_text = re.sub(r"\s+", " ", alt_text).strip()
142 | 
143 |                     # If keep_data_uris is True, use base64 encoding for images
144 |                     if kwargs.get("keep_data_uris", False):
145 |                         blob = shape.image.blob
146 |                         content_type = shape.image.content_type or "image/png"
147 |                         b64_string = base64.b64encode(blob).decode("utf-8")
148 |                         md_content += f"\n![{alt_text}](data:{content_type};base64,{b64_string})\n"
149 |                     else:
150 |                         # A placeholder name
151 |                         filename = re.sub(r"\W", "", shape.name) + ".jpg"
152 |                         md_content += "\n![" + alt_text + "](" + filename + ")\n"
153 | 
154 |                 # Tables
155 |                 if self._is_table(shape):
156 |                     md_content += self._convert_table_to_markdown(shape.table, **kwargs)
157 | 
158 |                 # Charts
159 |                 if shape.has_chart:
160 |                     md_content += self._convert_chart_to_markdown(shape.chart)
161 | 
162 |                 # Text areas
163 |                 elif shape.has_text_frame:
164 |                     if shape == title:
165 |                         md_content += "# " + shape.text.lstrip() + "\n"
166 |                     else:
167 |                         md_content += shape.text + "\n"
168 | 
169 |                 # Group Shapes
170 |                 if shape.shape_type == pptx.enum.shapes.MSO_SHAPE_TYPE.GROUP:
171 |                     sorted_shapes = sorted(shape.shapes, key=attrgetter("top", "left"))
172 |                     for subshape in sorted_shapes:
173 |                         get_shape_content(subshape, **kwargs)
174 | 
175 |             sorted_shapes = sorted(slide.shapes, key=attrgetter("top", "left"))
176 |             for shape in sorted_shapes:
177 |                 get_shape_content(shape, **kwargs)
178 | 
179 |             md_content = md_content.strip()
180 | 
181 |             if slide.has_notes_slide:
182 |                 md_content += "\n\n### Notes:\n"
183 |                 notes_frame = slide.notes_slide.notes_text_frame
184 |                 if notes_frame is not None:
185 |                     md_content += notes_frame.text
186 |                 md_content = md_content.strip()
187 | 
188 |         return DocumentConverterResult(markdown=md_content.strip())
189 | 
190 |     def _is_picture(self, shape):
191 |         if shape.shape_type == pptx.enum.shapes.MSO_SHAPE_TYPE.PICTURE:
192 |             return True
193 |         if shape.shape_type == pptx.enum.shapes.MSO_SHAPE_TYPE.PLACEHOLDER:
194 |             if hasattr(shape, "image"):
195 |                 return True
196 |         return False
197 | 
198 |     def _is_table(self, shape):
199 |         if shape.shape_type == pptx.enum.shapes.MSO_SHAPE_TYPE.TABLE:
200 |             return True
201 |         return False
202 | 
203 |     def _convert_table_to_markdown(self, table, **kwargs):
204 |         # Write the table as HTML, then convert it to Markdown
205 |         html_table = "<html><body><table>"
206 |         first_row = True
207 |         for row in table.rows:
208 |             html_table += "<tr>"
209 |             for cell in row.cells:
210 |                 if first_row:
211 |                     html_table += "<th>" + html.escape(cell.text) + "</th>"
212 |                 else:
213 |                     html_table += "<td>" + html.escape(cell.text) + "</td>"
214 |             html_table += "</tr>"
215 |             first_row = False
216 |         html_table += "</table></body></html>"
217 | 
218 |         return (
219 |             self._html_converter.convert_string(html_table, **kwargs).markdown.strip()
220 |             + "\n"
221 |         )
222 | 
223 |     def _convert_chart_to_markdown(self, chart):
224 |         try:
225 |             md = "\n\n### Chart"
226 |             if chart.has_title:
227 |                 md += f": {chart.chart_title.text_frame.text}"
228 |             md += "\n\n"
229 |             data = []
230 |             category_names = [c.label for c in chart.plots[0].categories]
231 |             series_names = [s.name for s in chart.series]
232 |             data.append(["Category"] + series_names)
233 | 
234 |             for idx, category in enumerate(category_names):
235 |                 row = [category]
236 |                 for series in chart.series:
237 |                     row.append(series.values[idx])
238 |                 data.append(row)
239 | 
240 |             markdown_table = []
241 |             for row in data:
242 |                 markdown_table.append("| " + " | ".join(map(str, row)) + " |")
243 |             header = markdown_table[0]
244 |             separator = "|" + "|".join(["---"] * len(data[0])) + "|"
245 |             return md + "\n".join([header, separator] + markdown_table[1:])
246 |         except ValueError as e:
247 |             # Handle the specific error for unsupported chart types
248 |             if "unsupported plot type" in str(e):
249 |                 return "\n\n[unsupported chart]\n\n"
250 |         except Exception:
251 |             # Catch any other exceptions that might occur
252 |             return "\n\n[unsupported chart]\n\n"
253 | 


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/converters/_rss_converter.py:
--------------------------------------------------------------------------------
  1 | from xml.dom import minidom
  2 | from typing import BinaryIO, Any, Union
  3 | from bs4 import BeautifulSoup
  4 | 
  5 | from ._markdownify import _CustomMarkdownify
  6 | from .._stream_info import StreamInfo
  7 | from .._base_converter import DocumentConverter, DocumentConverterResult
  8 | 
  9 | PRECISE_MIME_TYPE_PREFIXES = [
 10 |     "application/rss",
 11 |     "application/rss+xml",
 12 |     "application/atom",
 13 |     "application/atom+xml",
 14 | ]
 15 | 
 16 | PRECISE_FILE_EXTENSIONS = [".rss", ".atom"]
 17 | 
 18 | CANDIDATE_MIME_TYPE_PREFIXES = [
 19 |     "text/xml",
 20 |     "application/xml",
 21 | ]
 22 | 
 23 | CANDIDATE_FILE_EXTENSIONS = [
 24 |     ".xml",
 25 | ]
 26 | 
 27 | 
 28 | class RssConverter(DocumentConverter):
 29 |     """Convert RSS / Atom type to markdown"""
 30 | 
 31 |     def __init__(self):
 32 |         super().__init__()
 33 |         self._kwargs = {}
 34 | 
 35 |     def accepts(
 36 |         self,
 37 |         file_stream: BinaryIO,
 38 |         stream_info: StreamInfo,
 39 |         **kwargs: Any,  # Options to pass to the converter
 40 |     ) -> bool:
 41 |         mimetype = (stream_info.mimetype or "").lower()
 42 |         extension = (stream_info.extension or "").lower()
 43 | 
 44 |         # Check for precise mimetypes and file extensions
 45 |         if extension in PRECISE_FILE_EXTENSIONS:
 46 |             return True
 47 | 
 48 |         for prefix in PRECISE_MIME_TYPE_PREFIXES:
 49 |             if mimetype.startswith(prefix):
 50 |                 return True
 51 | 
 52 |         # Check for precise mimetypes and file extensions
 53 |         if extension in CANDIDATE_FILE_EXTENSIONS:
 54 |             return self._check_xml(file_stream)
 55 | 
 56 |         for prefix in CANDIDATE_MIME_TYPE_PREFIXES:
 57 |             if mimetype.startswith(prefix):
 58 |                 return self._check_xml(file_stream)
 59 | 
 60 |         return False
 61 | 
 62 |     def _check_xml(self, file_stream: BinaryIO) -> bool:
 63 |         cur_pos = file_stream.tell()
 64 |         try:
 65 |             doc = minidom.parse(file_stream)
 66 |             return self._feed_type(doc) is not None
 67 |         except BaseException as _:
 68 |             pass
 69 |         finally:
 70 |             file_stream.seek(cur_pos)
 71 |         return False
 72 | 
 73 |     def _feed_type(self, doc: Any) -> str | None:
 74 |         if doc.getElementsByTagName("rss"):
 75 |             return "rss"
 76 |         elif doc.getElementsByTagName("feed"):
 77 |             root = doc.getElementsByTagName("feed")[0]
 78 |             if root.getElementsByTagName("entry"):
 79 |                 # An Atom feed must have a root element of <feed> and at least one <entry>
 80 |                 return "atom"
 81 |         return None
 82 | 
 83 |     def convert(
 84 |         self,
 85 |         file_stream: BinaryIO,
 86 |         stream_info: StreamInfo,
 87 |         **kwargs: Any,  # Options to pass to the converter
 88 |     ) -> DocumentConverterResult:
 89 |         self._kwargs = kwargs
 90 |         doc = minidom.parse(file_stream)
 91 |         feed_type = self._feed_type(doc)
 92 | 
 93 |         if feed_type == "rss":
 94 |             return self._parse_rss_type(doc)
 95 |         elif feed_type == "atom":
 96 |             return self._parse_atom_type(doc)
 97 |         else:
 98 |             raise ValueError("Unknown feed type")
 99 | 
100 |     def _parse_atom_type(self, doc: minidom.Document) -> DocumentConverterResult:
101 |         """Parse the type of an Atom feed.
102 | 
103 |         Returns None if the feed type is not recognized or something goes wrong.
104 |         """
105 |         root = doc.getElementsByTagName("feed")[0]
106 |         title = self._get_data_by_tag_name(root, "title")
107 |         subtitle = self._get_data_by_tag_name(root, "subtitle")
108 |         entries = root.getElementsByTagName("entry")
109 |         md_text = f"# {title}\n"
110 |         if subtitle:
111 |             md_text += f"{subtitle}\n"
112 |         for entry in entries:
113 |             entry_title = self._get_data_by_tag_name(entry, "title")
114 |             entry_summary = self._get_data_by_tag_name(entry, "summary")
115 |             entry_updated = self._get_data_by_tag_name(entry, "updated")
116 |             entry_content = self._get_data_by_tag_name(entry, "content")
117 | 
118 |             if entry_title:
119 |                 md_text += f"\n## {entry_title}\n"
120 |             if entry_updated:
121 |                 md_text += f"Updated on: {entry_updated}\n"
122 |             if entry_summary:
123 |                 md_text += self._parse_content(entry_summary)
124 |             if entry_content:
125 |                 md_text += self._parse_content(entry_content)
126 | 
127 |         return DocumentConverterResult(
128 |             markdown=md_text,
129 |             title=title,
130 |         )
131 | 
132 |     def _parse_rss_type(self, doc: minidom.Document) -> DocumentConverterResult:
133 |         """Parse the type of an RSS feed.
134 | 
135 |         Returns None if the feed type is not recognized or something goes wrong.
136 |         """
137 |         root = doc.getElementsByTagName("rss")[0]
138 |         channel_list = root.getElementsByTagName("channel")
139 |         if not channel_list:
140 |             raise ValueError("No channel found in RSS feed")
141 |         channel = channel_list[0]
142 |         channel_title = self._get_data_by_tag_name(channel, "title")
143 |         channel_description = self._get_data_by_tag_name(channel, "description")
144 |         items = channel.getElementsByTagName("item")
145 |         if channel_title:
146 |             md_text = f"# {channel_title}\n"
147 |         if channel_description:
148 |             md_text += f"{channel_description}\n"
149 |         for item in items:
150 |             title = self._get_data_by_tag_name(item, "title")
151 |             description = self._get_data_by_tag_name(item, "description")
152 |             pubDate = self._get_data_by_tag_name(item, "pubDate")
153 |             content = self._get_data_by_tag_name(item, "content:encoded")
154 | 
155 |             if title:
156 |                 md_text += f"\n## {title}\n"
157 |             if pubDate:
158 |                 md_text += f"Published on: {pubDate}\n"
159 |             if description:
160 |                 md_text += self._parse_content(description)
161 |             if content:
162 |                 md_text += self._parse_content(content)
163 | 
164 |         return DocumentConverterResult(
165 |             markdown=md_text,
166 |             title=channel_title,
167 |         )
168 | 
169 |     def _parse_content(self, content: str) -> str:
170 |         """Parse the content of an RSS feed item"""
171 |         try:
172 |             # using bs4 because many RSS feeds have HTML-styled content
173 |             soup = BeautifulSoup(content, "html.parser")
174 |             return _CustomMarkdownify(**self._kwargs).convert_soup(soup)
175 |         except BaseException as _:
176 |             return content
177 | 
178 |     def _get_data_by_tag_name(
179 |         self, element: minidom.Element, tag_name: str
180 |     ) -> Union[str, None]:
181 |         """Get data from first child element with the given tag name.
182 |         Returns None when no such element is found.
183 |         """
184 |         nodes = element.getElementsByTagName(tag_name)
185 |         if not nodes:
186 |             return None
187 |         fc = nodes[0].firstChild
188 |         if fc:
189 |             if hasattr(fc, "data"):
190 |                 return fc.data
191 |         return None
192 | 


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/converters/_transcribe_audio.py:
--------------------------------------------------------------------------------
 1 | import io
 2 | import sys
 3 | from typing import BinaryIO
 4 | from .._exceptions import MissingDependencyException
 5 | 
 6 | # Try loading optional (but in this case, required) dependencies
 7 | # Save reporting of any exceptions for later
 8 | _dependency_exc_info = None
 9 | try:
10 |     # Suppress some warnings on library import
11 |     import warnings
12 | 
13 |     with warnings.catch_warnings():
14 |         warnings.filterwarnings("ignore", category=DeprecationWarning)
15 |         warnings.filterwarnings("ignore", category=SyntaxWarning)
16 |         import speech_recognition as sr
17 |         import pydub
18 | except ImportError:
19 |     # Preserve the error and stack trace for later
20 |     _dependency_exc_info = sys.exc_info()
21 | 
22 | 
23 | def transcribe_audio(file_stream: BinaryIO, *, audio_format: str = "wav") -> str:
24 |     # Check for installed dependencies
25 |     if _dependency_exc_info is not None:
26 |         raise MissingDependencyException(
27 |             "Speech transcription requires installing MarkItdown with the [audio-transcription] optional dependencies. E.g., `pip install markitdown[audio-transcription]` or `pip install markitdown[all]`"
28 |         ) from _dependency_exc_info[
29 |             1
30 |         ].with_traceback(  # type: ignore[union-attr]
31 |             _dependency_exc_info[2]
32 |         )
33 | 
34 |     if audio_format in ["wav", "aiff", "flac"]:
35 |         audio_source = file_stream
36 |     elif audio_format in ["mp3", "mp4"]:
37 |         audio_segment = pydub.AudioSegment.from_file(file_stream, format=audio_format)
38 | 
39 |         audio_source = io.BytesIO()
40 |         audio_segment.export(audio_source, format="wav")
41 |         audio_source.seek(0)
42 |     else:
43 |         raise ValueError(f"Unsupported audio format: {audio_format}")
44 | 
45 |     recognizer = sr.Recognizer()
46 |     with sr.AudioFile(audio_source) as source:
47 |         audio = recognizer.record(source)
48 |         transcript = recognizer.recognize_google(audio).strip()
49 |         return "[No speech detected]" if transcript == "" else transcript
50 | 


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/converters/_wikipedia_converter.py:
--------------------------------------------------------------------------------
 1 | import io
 2 | import re
 3 | import bs4
 4 | from typing import Any, BinaryIO, Optional
 5 | 
 6 | from .._base_converter import DocumentConverter, DocumentConverterResult
 7 | from .._stream_info import StreamInfo
 8 | from ._markdownify import _CustomMarkdownify
 9 | 
10 | ACCEPTED_MIME_TYPE_PREFIXES = [
11 |     "text/html",
12 |     "application/xhtml",
13 | ]
14 | 
15 | ACCEPTED_FILE_EXTENSIONS = [
16 |     ".html",
17 |     ".htm",
18 | ]
19 | 
20 | 
21 | class WikipediaConverter(DocumentConverter):
22 |     """Handle Wikipedia pages separately, focusing only on the main document content."""
23 | 
24 |     def accepts(
25 |         self,
26 |         file_stream: BinaryIO,
27 |         stream_info: StreamInfo,
28 |         **kwargs: Any,  # Options to pass to the converter
29 |     ) -> bool:
30 |         """
31 |         Make sure we're dealing with HTML content *from* Wikipedia.
32 |         """
33 | 
34 |         url = stream_info.url or ""
35 |         mimetype = (stream_info.mimetype or "").lower()
36 |         extension = (stream_info.extension or "").lower()
37 | 
38 |         if not re.search(r"^https?:\/\/[a-zA-Z]{2,3}\.wikipedia.org\/", url):
39 |             # Not a Wikipedia URL
40 |             return False
41 | 
42 |         if extension in ACCEPTED_FILE_EXTENSIONS:
43 |             return True
44 | 
45 |         for prefix in ACCEPTED_MIME_TYPE_PREFIXES:
46 |             if mimetype.startswith(prefix):
47 |                 return True
48 | 
49 |         # Not HTML content
50 |         return False
51 | 
52 |     def convert(
53 |         self,
54 |         file_stream: BinaryIO,
55 |         stream_info: StreamInfo,
56 |         **kwargs: Any,  # Options to pass to the converter
57 |     ) -> DocumentConverterResult:
58 |         # Parse the stream
59 |         encoding = "utf-8" if stream_info.charset is None else stream_info.charset
60 |         soup = bs4.BeautifulSoup(file_stream, "html.parser", from_encoding=encoding)
61 | 
62 |         # Remove javascript and style blocks
63 |         for script in soup(["script", "style"]):
64 |             script.extract()
65 | 
66 |         # Print only the main content
67 |         body_elm = soup.find("div", {"id": "mw-content-text"})
68 |         title_elm = soup.find("span", {"class": "mw-page-title-main"})
69 | 
70 |         webpage_text = ""
71 |         main_title = None if soup.title is None else soup.title.string
72 | 
73 |         if body_elm:
74 |             # What's the title
75 |             if title_elm and isinstance(title_elm, bs4.Tag):
76 |                 main_title = title_elm.string
77 | 
78 |             # Convert the page
79 |             webpage_text = f"# {main_title}\n\n" + _CustomMarkdownify(
80 |                 **kwargs
81 |             ).convert_soup(body_elm)
82 |         else:
83 |             webpage_text = _CustomMarkdownify(**kwargs).convert_soup(soup)
84 | 
85 |         return DocumentConverterResult(
86 |             markdown=webpage_text,
87 |             title=main_title,
88 |         )
89 | 


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/converters/_xlsx_converter.py:
--------------------------------------------------------------------------------
  1 | import sys
  2 | from typing import BinaryIO, Any
  3 | from ._html_converter import HtmlConverter
  4 | from .._base_converter import DocumentConverter, DocumentConverterResult
  5 | from .._exceptions import MissingDependencyException, MISSING_DEPENDENCY_MESSAGE
  6 | from .._stream_info import StreamInfo
  7 | 
  8 | # Try loading optional (but in this case, required) dependencies
  9 | # Save reporting of any exceptions for later
 10 | _xlsx_dependency_exc_info = None
 11 | try:
 12 |     import pandas as pd
 13 |     import openpyxl
 14 | except ImportError:
 15 |     _xlsx_dependency_exc_info = sys.exc_info()
 16 | 
 17 | _xls_dependency_exc_info = None
 18 | try:
 19 |     import pandas as pd
 20 |     import xlrd
 21 | except ImportError:
 22 |     _xls_dependency_exc_info = sys.exc_info()
 23 | 
 24 | ACCEPTED_XLSX_MIME_TYPE_PREFIXES = [
 25 |     "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
 26 | ]
 27 | ACCEPTED_XLSX_FILE_EXTENSIONS = [".xlsx"]
 28 | 
 29 | ACCEPTED_XLS_MIME_TYPE_PREFIXES = [
 30 |     "application/vnd.ms-excel",
 31 |     "application/excel",
 32 | ]
 33 | ACCEPTED_XLS_FILE_EXTENSIONS = [".xls"]
 34 | 
 35 | 
 36 | class XlsxConverter(DocumentConverter):
 37 |     """
 38 |     Converts XLSX files to Markdown, with each sheet presented as a separate Markdown table.
 39 |     """
 40 | 
 41 |     def __init__(self):
 42 |         super().__init__()
 43 |         self._html_converter = HtmlConverter()
 44 | 
 45 |     def accepts(
 46 |         self,
 47 |         file_stream: BinaryIO,
 48 |         stream_info: StreamInfo,
 49 |         **kwargs: Any,  # Options to pass to the converter
 50 |     ) -> bool:
 51 |         mimetype = (stream_info.mimetype or "").lower()
 52 |         extension = (stream_info.extension or "").lower()
 53 | 
 54 |         if extension in ACCEPTED_XLSX_FILE_EXTENSIONS:
 55 |             return True
 56 | 
 57 |         for prefix in ACCEPTED_XLSX_MIME_TYPE_PREFIXES:
 58 |             if mimetype.startswith(prefix):
 59 |                 return True
 60 | 
 61 |         return False
 62 | 
 63 |     def convert(
 64 |         self,
 65 |         file_stream: BinaryIO,
 66 |         stream_info: StreamInfo,
 67 |         **kwargs: Any,  # Options to pass to the converter
 68 |     ) -> DocumentConverterResult:
 69 |         # Check the dependencies
 70 |         if _xlsx_dependency_exc_info is not None:
 71 |             raise MissingDependencyException(
 72 |                 MISSING_DEPENDENCY_MESSAGE.format(
 73 |                     converter=type(self).__name__,
 74 |                     extension=".xlsx",
 75 |                     feature="xlsx",
 76 |                 )
 77 |             ) from _xlsx_dependency_exc_info[
 78 |                 1
 79 |             ].with_traceback(  # type: ignore[union-attr]
 80 |                 _xlsx_dependency_exc_info[2]
 81 |             )
 82 | 
 83 |         sheets = pd.read_excel(file_stream, sheet_name=None, engine="openpyxl")
 84 |         md_content = ""
 85 |         for s in sheets:
 86 |             md_content += f"## {s}\n"
 87 |             html_content = sheets[s].to_html(index=False)
 88 |             md_content += (
 89 |                 self._html_converter.convert_string(
 90 |                     html_content, **kwargs
 91 |                 ).markdown.strip()
 92 |                 + "\n\n"
 93 |             )
 94 | 
 95 |         return DocumentConverterResult(markdown=md_content.strip())
 96 | 
 97 | 
 98 | class XlsConverter(DocumentConverter):
 99 |     """
100 |     Converts XLS files to Markdown, with each sheet presented as a separate Markdown table.
101 |     """
102 | 
103 |     def __init__(self):
104 |         super().__init__()
105 |         self._html_converter = HtmlConverter()
106 | 
107 |     def accepts(
108 |         self,
109 |         file_stream: BinaryIO,
110 |         stream_info: StreamInfo,
111 |         **kwargs: Any,  # Options to pass to the converter
112 |     ) -> bool:
113 |         mimetype = (stream_info.mimetype or "").lower()
114 |         extension = (stream_info.extension or "").lower()
115 | 
116 |         if extension in ACCEPTED_XLS_FILE_EXTENSIONS:
117 |             return True
118 | 
119 |         for prefix in ACCEPTED_XLS_MIME_TYPE_PREFIXES:
120 |             if mimetype.startswith(prefix):
121 |                 return True
122 | 
123 |         return False
124 | 
125 |     def convert(
126 |         self,
127 |         file_stream: BinaryIO,
128 |         stream_info: StreamInfo,
129 |         **kwargs: Any,  # Options to pass to the converter
130 |     ) -> DocumentConverterResult:
131 |         # Load the dependencies
132 |         if _xls_dependency_exc_info is not None:
133 |             raise MissingDependencyException(
134 |                 MISSING_DEPENDENCY_MESSAGE.format(
135 |                     converter=type(self).__name__,
136 |                     extension=".xls",
137 |                     feature="xls",
138 |                 )
139 |             ) from _xls_dependency_exc_info[
140 |                 1
141 |             ].with_traceback(  # type: ignore[union-attr]
142 |                 _xls_dependency_exc_info[2]
143 |             )
144 | 
145 |         sheets = pd.read_excel(file_stream, sheet_name=None, engine="xlrd")
146 |         md_content = ""
147 |         for s in sheets:
148 |             md_content += f"## {s}\n"
149 |             html_content = sheets[s].to_html(index=False)
150 |             md_content += (
151 |                 self._html_converter.convert_string(
152 |                     html_content, **kwargs
153 |                 ).markdown.strip()
154 |                 + "\n\n"
155 |             )
156 | 
157 |         return DocumentConverterResult(markdown=md_content.strip())
158 | 


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/converters/_youtube_converter.py:
--------------------------------------------------------------------------------
  1 | import sys
  2 | import json
  3 | import time
  4 | import io
  5 | import re
  6 | import bs4
  7 | from typing import Any, BinaryIO, Optional, Dict, List, Union
  8 | from urllib.parse import parse_qs, urlparse, unquote
  9 | 
 10 | from .._base_converter import DocumentConverter, DocumentConverterResult
 11 | from .._stream_info import StreamInfo
 12 | 
 13 | # Optional YouTube transcription support
 14 | try:
 15 |     # Suppress some warnings on library import
 16 |     import warnings
 17 | 
 18 |     with warnings.catch_warnings():
 19 |         warnings.filterwarnings("ignore", category=SyntaxWarning)
 20 |         # Patch submitted upstream to fix the SyntaxWarning
 21 |         from youtube_transcript_api import YouTubeTranscriptApi
 22 | 
 23 |     IS_YOUTUBE_TRANSCRIPT_CAPABLE = True
 24 | except ModuleNotFoundError:
 25 |     IS_YOUTUBE_TRANSCRIPT_CAPABLE = False
 26 | 
 27 | 
 28 | ACCEPTED_MIME_TYPE_PREFIXES = [
 29 |     "text/html",
 30 |     "application/xhtml",
 31 | ]
 32 | 
 33 | ACCEPTED_FILE_EXTENSIONS = [
 34 |     ".html",
 35 |     ".htm",
 36 | ]
 37 | 
 38 | 
 39 | class YouTubeConverter(DocumentConverter):
 40 |     """Handle YouTube specially, focusing on the video title, description, and transcript."""
 41 | 
 42 |     def accepts(
 43 |         self,
 44 |         file_stream: BinaryIO,
 45 |         stream_info: StreamInfo,
 46 |         **kwargs: Any,  # Options to pass to the converter
 47 |     ) -> bool:
 48 |         """
 49 |         Make sure we're dealing with HTML content *from* YouTube.
 50 |         """
 51 |         url = stream_info.url or ""
 52 |         mimetype = (stream_info.mimetype or "").lower()
 53 |         extension = (stream_info.extension or "").lower()
 54 | 
 55 |         url = unquote(url)
 56 |         url = url.replace(r"\?", "?").replace(r"\=", "=")
 57 | 
 58 |         if not url.startswith("https://www.youtube.com/watch?"):
 59 |             # Not a YouTube URL
 60 |             return False
 61 | 
 62 |         if extension in ACCEPTED_FILE_EXTENSIONS:
 63 |             return True
 64 | 
 65 |         for prefix in ACCEPTED_MIME_TYPE_PREFIXES:
 66 |             if mimetype.startswith(prefix):
 67 |                 return True
 68 | 
 69 |         # Not HTML content
 70 |         return False
 71 | 
 72 |     def convert(
 73 |         self,
 74 |         file_stream: BinaryIO,
 75 |         stream_info: StreamInfo,
 76 |         **kwargs: Any,  # Options to pass to the converter
 77 |     ) -> DocumentConverterResult:
 78 |         # Parse the stream
 79 |         encoding = "utf-8" if stream_info.charset is None else stream_info.charset
 80 |         soup = bs4.BeautifulSoup(file_stream, "html.parser", from_encoding=encoding)
 81 | 
 82 |         # Read the meta tags
 83 |         metadata: Dict[str, str] = {}
 84 | 
 85 |         if soup.title and soup.title.string:
 86 |             metadata["title"] = soup.title.string
 87 | 
 88 |         for meta in soup(["meta"]):
 89 |             if not isinstance(meta, bs4.Tag):
 90 |                 continue
 91 | 
 92 |             for a in meta.attrs:
 93 |                 if a in ["itemprop", "property", "name"]:
 94 |                     key = str(meta.get(a, ""))
 95 |                     content = str(meta.get("content", ""))
 96 |                     if key and content:  # Only add non-empty content
 97 |                         metadata[key] = content
 98 |                     break
 99 | 
100 |         # Try reading the description
101 |         try:
102 |             for script in soup(["script"]):
103 |                 if not isinstance(script, bs4.Tag):
104 |                     continue
105 |                 if not script.string:  # Skip empty scripts
106 |                     continue
107 |                 content = script.string
108 |                 if "ytInitialData" in content:
109 |                     match = re.search(r"var ytInitialData = ({.*?});", content)
110 |                     if match:
111 |                         data = json.loads(match.group(1))
112 |                         attrdesc = self._findKey(data, "attributedDescriptionBodyText")
113 |                         if attrdesc and isinstance(attrdesc, dict):
114 |                             metadata["description"] = str(attrdesc.get("content", ""))
115 |                     break
116 |         except Exception as e:
117 |             print(f"Error extracting description: {e}")
118 |             pass
119 | 
120 |         # Start preparing the page
121 |         webpage_text = "# YouTube\n"
122 | 
123 |         title = self._get(metadata, ["title", "og:title", "name"])  # type: ignore
124 |         assert isinstance(title, str)
125 | 
126 |         if title:
127 |             webpage_text += f"\n## {title}\n"
128 | 
129 |         stats = ""
130 |         views = self._get(metadata, ["interactionCount"])  # type: ignore
131 |         if views:
132 |             stats += f"- **Views:** {views}\n"
133 | 
134 |         keywords = self._get(metadata, ["keywords"])  # type: ignore
135 |         if keywords:
136 |             stats += f"- **Keywords:** {keywords}\n"
137 | 
138 |         runtime = self._get(metadata, ["duration"])  # type: ignore
139 |         if runtime:
140 |             stats += f"- **Runtime:** {runtime}\n"
141 | 
142 |         if len(stats) > 0:
143 |             webpage_text += f"\n### Video Metadata\n{stats}\n"
144 | 
145 |         description = self._get(metadata, ["description", "og:description"])  # type: ignore
146 |         if description:
147 |             webpage_text += f"\n### Description\n{description}\n"
148 | 
149 |         if IS_YOUTUBE_TRANSCRIPT_CAPABLE:
150 |             ytt_api = YouTubeTranscriptApi()
151 |             transcript_text = ""
152 |             parsed_url = urlparse(stream_info.url)  # type: ignore
153 |             params = parse_qs(parsed_url.query)  # type: ignore
154 |             if "v" in params and params["v"][0]:
155 |                 video_id = str(params["v"][0])
156 |                 try:
157 |                     youtube_transcript_languages = kwargs.get(
158 |                         "youtube_transcript_languages", ("en",)
159 |                     )
160 |                     # Retry the transcript fetching operation
161 |                     transcript = self._retry_operation(
162 |                         lambda: ytt_api.fetch(
163 |                             video_id, languages=youtube_transcript_languages
164 |                         ),
165 |                         retries=3,  # Retry 3 times
166 |                         delay=2,  # 2 seconds delay between retries
167 |                     )
168 |                     if transcript:
169 |                         transcript_text = " ".join(
170 |                             [part.text for part in transcript]
171 |                         )  # type: ignore
172 |                 except Exception as e:
173 |                     print(f"Error fetching transcript: {e}")
174 |             if transcript_text:
175 |                 webpage_text += f"\n### Transcript\n{transcript_text}\n"
176 | 
177 |         title = title if title else (soup.title.string if soup.title else "")
178 |         assert isinstance(title, str)
179 | 
180 |         return DocumentConverterResult(
181 |             markdown=webpage_text,
182 |             title=title,
183 |         )
184 | 
185 |     def _get(
186 |         self,
187 |         metadata: Dict[str, str],
188 |         keys: List[str],
189 |         default: Union[str, None] = None,
190 |     ) -> Union[str, None]:
191 |         """Get first non-empty value from metadata matching given keys."""
192 |         for k in keys:
193 |             if k in metadata:
194 |                 return metadata[k]
195 |         return default
196 | 
197 |     def _findKey(self, json: Any, key: str) -> Union[str, None]:  # TODO: Fix json type
198 |         """Recursively search for a key in nested dictionary/list structures."""
199 |         if isinstance(json, list):
200 |             for elm in json:
201 |                 ret = self._findKey(elm, key)
202 |                 if ret is not None:
203 |                     return ret
204 |         elif isinstance(json, dict):
205 |             for k, v in json.items():
206 |                 if k == key:
207 |                     return json[k]
208 |                 if result := self._findKey(v, key):
209 |                     return result
210 |         return None
211 | 
212 |     def _retry_operation(self, operation, retries=3, delay=2):
213 |         """Retries the operation if it fails."""
214 |         attempt = 0
215 |         while attempt < retries:
216 |             try:
217 |                 return operation()  # Attempt the operation
218 |             except Exception as e:
219 |                 print(f"Attempt {attempt + 1} failed: {e}")
220 |                 if attempt < retries - 1:
221 |                     time.sleep(delay)  # Wait before retrying
222 |                 attempt += 1
223 |         # If all attempts fail, raise the last exception
224 |         raise Exception(f"Operation failed after {retries} attempts.")
225 | 


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/converters/_zip_converter.py:
--------------------------------------------------------------------------------
  1 | import sys
  2 | import zipfile
  3 | import io
  4 | import os
  5 | 
  6 | from typing import BinaryIO, Any, TYPE_CHECKING
  7 | 
  8 | from .._base_converter import DocumentConverter, DocumentConverterResult
  9 | from .._stream_info import StreamInfo
 10 | from .._exceptions import UnsupportedFormatException, FileConversionException
 11 | 
 12 | # Break otherwise circular import for type hinting
 13 | if TYPE_CHECKING:
 14 |     from .._markitdown import MarkItDown
 15 | 
 16 | ACCEPTED_MIME_TYPE_PREFIXES = [
 17 |     "application/zip",
 18 | ]
 19 | 
 20 | ACCEPTED_FILE_EXTENSIONS = [".zip"]
 21 | 
 22 | 
 23 | class ZipConverter(DocumentConverter):
 24 |     """Converts ZIP files to markdown by extracting and converting all contained files.
 25 | 
 26 |     The converter extracts the ZIP contents to a temporary directory, processes each file
 27 |     using appropriate converters based on file extensions, and then combines the results
 28 |     into a single markdown document. The temporary directory is cleaned up after processing.
 29 | 
 30 |     Example output format:
 31 |     ```markdown
 32 |     Content from the zip file `example.zip`:
 33 | 
 34 |     ## File: docs/readme.txt
 35 | 
 36 |     This is the content of readme.txt
 37 |     Multiple lines are preserved
 38 | 
 39 |     ## File: images/example.jpg
 40 | 
 41 |     ImageSize: 1920x1080
 42 |     DateTimeOriginal: 2024-02-15 14:30:00
 43 |     Description: A beautiful landscape photo
 44 | 
 45 |     ## File: data/report.xlsx
 46 | 
 47 |     ## Sheet1
 48 |     | Column1 | Column2 | Column3 |
 49 |     |---------|---------|---------|
 50 |     | data1   | data2   | data3   |
 51 |     | data4   | data5   | data6   |
 52 |     ```
 53 | 
 54 |     Key features:
 55 |     - Maintains original file structure in headings
 56 |     - Processes nested files recursively
 57 |     - Uses appropriate converters for each file type
 58 |     - Preserves formatting of converted content
 59 |     - Cleans up temporary files after processing
 60 |     """
 61 | 
 62 |     def __init__(
 63 |         self,
 64 |         *,
 65 |         markitdown: "MarkItDown",
 66 |     ):
 67 |         super().__init__()
 68 |         self._markitdown = markitdown
 69 | 
 70 |     def accepts(
 71 |         self,
 72 |         file_stream: BinaryIO,
 73 |         stream_info: StreamInfo,
 74 |         **kwargs: Any,  # Options to pass to the converter
 75 |     ) -> bool:
 76 |         mimetype = (stream_info.mimetype or "").lower()
 77 |         extension = (stream_info.extension or "").lower()
 78 | 
 79 |         if extension in ACCEPTED_FILE_EXTENSIONS:
 80 |             return True
 81 | 
 82 |         for prefix in ACCEPTED_MIME_TYPE_PREFIXES:
 83 |             if mimetype.startswith(prefix):
 84 |                 return True
 85 | 
 86 |         return False
 87 | 
 88 |     def convert(
 89 |         self,
 90 |         file_stream: BinaryIO,
 91 |         stream_info: StreamInfo,
 92 |         **kwargs: Any,  # Options to pass to the converter
 93 |     ) -> DocumentConverterResult:
 94 |         file_path = stream_info.url or stream_info.local_path or stream_info.filename
 95 |         md_content = f"Content from the zip file `{file_path}`:\n\n"
 96 | 
 97 |         with zipfile.ZipFile(file_stream, "r") as zipObj:
 98 |             for name in zipObj.namelist():
 99 |                 try:
100 |                     z_file_stream = io.BytesIO(zipObj.read(name))
101 |                     z_file_stream_info = StreamInfo(
102 |                         extension=os.path.splitext(name)[1],
103 |                         filename=os.path.basename(name),
104 |                     )
105 |                     result = self._markitdown.convert_stream(
106 |                         stream=z_file_stream,
107 |                         stream_info=z_file_stream_info,
108 |                     )
109 |                     if result is not None:
110 |                         md_content += f"## File: {name}\n\n"
111 |                         md_content += result.markdown + "\n\n"
112 |                 except UnsupportedFormatException:
113 |                     pass
114 |                 except FileConversionException:
115 |                     pass
116 | 
117 |         return DocumentConverterResult(markdown=md_content.strip())
118 | 


--------------------------------------------------------------------------------
/packages/markitdown/src/markitdown/py.typed:
--------------------------------------------------------------------------------
https://raw.githubusercontent.com/microsoft/markitdown/3fcd48cdfc651cbf508071c8d2fb7d82aeb075de/packages/markitdown/src/markitdown/py.typed


--------------------------------------------------------------------------------
/packages/markitdown/tests/__init__.py:
--------------------------------------------------------------------------------
1 | # SPDX-FileCopyrightText: 2024-present Adam Fourney <adamfo@microsoft.com>
2 | #
3 | # SPDX-License-Identifier: MIT
4 | 


--------------------------------------------------------------------------------
/packages/markitdown/tests/_test_vectors.py:
--------------------------------------------------------------------------------
  1 | import dataclasses
  2 | from typing import List
  3 | 
  4 | 
  5 | @dataclasses.dataclass(frozen=True, kw_only=True)
  6 | class FileTestVector(object):
  7 |     filename: str
  8 |     mimetype: str | None
  9 |     charset: str | None
 10 |     url: str | None
 11 |     must_include: List[str]
 12 |     must_not_include: List[str]
 13 | 
 14 | 
 15 | GENERAL_TEST_VECTORS = [
 16 |     FileTestVector(
 17 |         filename="test.docx",
 18 |         mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
 19 |         charset=None,
 20 |         url=None,
 21 |         must_include=[
 22 |             "314b0a30-5b04-470b-b9f7-eed2c2bec74a",
 23 |             "49e168b7-d2ae-407f-a055-2167576f39a1",
 24 |             "## d666f1f7-46cb-42bd-9a39-9a39cf2a509f",
 25 |             "# Abstract",
 26 |             "# Introduction",
 27 |             "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation",
 28 |             "data:image/png;base64...",
 29 |         ],
 30 |         must_not_include=[
 31 |             "data:image/png;base64,iVBORw0KGgoAAAANSU",
 32 |         ],
 33 |     ),
 34 |     FileTestVector(
 35 |         filename="test.xlsx",
 36 |         mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
 37 |         charset=None,
 38 |         url=None,
 39 |         must_include=[
 40 |             "## 09060124-b5e7-4717-9d07-3c046eb",
 41 |             "6ff4173b-42a5-4784-9b19-f49caff4d93d",
 42 |             "affc7dad-52dc-4b98-9b5d-51e65d8a8ad0",
 43 |         ],
 44 |         must_not_include=[],
 45 |     ),
 46 |     FileTestVector(
 47 |         filename="test.xls",
 48 |         mimetype="application/vnd.ms-excel",
 49 |         charset=None,
 50 |         url=None,
 51 |         must_include=[
 52 |             "## 09060124-b5e7-4717-9d07-3c046eb",
 53 |             "6ff4173b-42a5-4784-9b19-f49caff4d93d",
 54 |             "affc7dad-52dc-4b98-9b5d-51e65d8a8ad0",
 55 |         ],
 56 |         must_not_include=[],
 57 |     ),
 58 |     FileTestVector(
 59 |         filename="test.pptx",
 60 |         mimetype="application/vnd.openxmlformats-officedocument.presentationml.presentation",
 61 |         charset=None,
 62 |         url=None,
 63 |         must_include=[
 64 |             "2cdda5c8-e50e-4db4-b5f0-9722a649f455",
 65 |             "04191ea8-5c73-4215-a1d3-1cfb43aaaf12",
 66 |             "44bf7d06-5e7a-4a40-a2e1-a2e42ef28c8a",
 67 |             "1b92870d-e3b5-4e65-8153-919f4ff45592",
 68 |             "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation",
 69 |             "a3f6004b-6f4f-4ea8-bee3-3741f4dc385f",  # chart title
 70 |             "2003",  # chart value
 71 |             "![This phrase of the caption is Human-written.](Picture4.jpg)",
 72 |         ],
 73 |         must_not_include=["data:image/jpeg;base64,/9j/4AAQSkZJRgABAQE"],
 74 |     ),
 75 |     FileTestVector(
 76 |         filename="test_outlook_msg.msg",
 77 |         mimetype="application/vnd.ms-outlook",
 78 |         charset=None,
 79 |         url=None,
 80 |         must_include=[
 81 |             "# Email Message",
 82 |             "**From:** test.sender@example.com",
 83 |             "**To:** test.recipient@example.com",
 84 |             "**Subject:** Test Email Message",
 85 |             "## Content",
 86 |             "This is the body of the test email message",
 87 |         ],
 88 |         must_not_include=[],
 89 |     ),
 90 |     FileTestVector(
 91 |         filename="test.pdf",
 92 |         mimetype="application/pdf",
 93 |         charset=None,
 94 |         url=None,
 95 |         must_include=[
 96 |             "While there is contemporaneous exploration of multi-agent approaches"
 97 |         ],
 98 |         must_not_include=[],
 99 |     ),
100 |     FileTestVector(
101 |         filename="test_blog.html",
102 |         mimetype="text/html",
103 |         charset="utf-8",
104 |         url="https://microsoft.github.io/autogen/blog/2023/04/21/LLM-tuning-math",
105 |         must_include=[
106 |             "Large language models (LLMs) are powerful tools that can generate natural language texts for various applications, such as chatbots, summarization, translation, and more. GPT-4 is currently the state of the art LLM in the world. Is model selection irrelevant? What about inference parameters?",
107 |             "an example where high cost can easily prevent a generic complex",
108 |         ],
109 |         must_not_include=[],
110 |     ),
111 |     FileTestVector(
112 |         filename="test_wikipedia.html",
113 |         mimetype="text/html",
114 |         charset="utf-8",
115 |         url="https://en.wikipedia.org/wiki/Microsoft",
116 |         must_include=[
117 |             "Microsoft entered the operating system (OS) business in 1980 with its own version of [Unix]",
118 |             'Microsoft was founded by [Bill Gates](/wiki/Bill_Gates "Bill Gates")',
119 |         ],
120 |         must_not_include=[
121 |             "You are encouraged to create an account and log in",
122 |             "154 languages",
123 |             "move to sidebar",
124 |         ],
125 |     ),
126 |     FileTestVector(
127 |         filename="test_serp.html",
128 |         mimetype="text/html",
129 |         charset="utf-8",
130 |         url="https://www.bing.com/search?q=microsoft+wikipedia",
131 |         must_include=[
132 |             "](https://en.wikipedia.org/wiki/Microsoft",
133 |             "Microsoft Corporation is **an American multinational corporation and technology company headquartered** in Redmond",
134 |             "1995–2007: Foray into the Web, Windows 95, Windows XP, and Xbox",
135 |         ],
136 |         must_not_include=[
137 |             "https://www.bing.com/ck/a?!&&p=",
138 |             "data:image/svg+xml,%3Csvg%20width%3D",
139 |         ],
140 |     ),
141 |     FileTestVector(
142 |         filename="test_mskanji.csv",
143 |         mimetype="text/csv",
144 |         charset="cp932",
145 |         url=None,
146 |         must_include=[
147 |             "名前,年齢,住所",
148 |             "佐藤太郎,30,東京",
149 |             "三木英子,25,大阪",
150 |             "髙橋淳,35,名古屋",
151 |         ],
152 |         must_not_include=[],
153 |     ),
154 |     FileTestVector(
155 |         filename="test.json",
156 |         mimetype="application/json",
157 |         charset="ascii",
158 |         url=None,
159 |         must_include=[
160 |             "5b64c88c-b3c3-4510-bcb8-da0b200602d8",
161 |             "9700dc99-6685-40b4-9a3a-5e406dcb37f3",
162 |         ],
163 |         must_not_include=[],
164 |     ),
165 |     FileTestVector(
166 |         filename="test_rss.xml",
167 |         mimetype="text/xml",
168 |         charset="utf-8",
169 |         url=None,
170 |         must_include=[
171 |             "# The Official Microsoft Blog",
172 |             "## Ignite 2024: Why nearly 70% of the Fortune 500 now use Microsoft 365 Copilot",
173 |             "In the case of AI, it is absolutely true that the industry is moving incredibly fast",
174 |         ],
175 |         must_not_include=["<rss", "<feed"],
176 |     ),
177 |     FileTestVector(
178 |         filename="test_notebook.ipynb",
179 |         mimetype="application/json",
180 |         charset="ascii",
181 |         url=None,
182 |         must_include=[
183 |             "# Test Notebook",
184 |             "```python",
185 |             'print("markitdown")',
186 |             "```",
187 |             "## Code Cell Below",
188 |         ],
189 |         must_not_include=[
190 |             "nbformat",
191 |             "nbformat_minor",
192 |         ],
193 |     ),
194 |     FileTestVector(
195 |         filename="test_files.zip",
196 |         mimetype="application/zip",
197 |         charset=None,
198 |         url=None,
199 |         must_include=[
200 |             "314b0a30-5b04-470b-b9f7-eed2c2bec74a",
201 |             "49e168b7-d2ae-407f-a055-2167576f39a1",
202 |             "## d666f1f7-46cb-42bd-9a39-9a39cf2a509f",
203 |             "# Abstract",
204 |             "# Introduction",
205 |             "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation",
206 |             "2cdda5c8-e50e-4db4-b5f0-9722a649f455",
207 |             "04191ea8-5c73-4215-a1d3-1cfb43aaaf12",
208 |             "44bf7d06-5e7a-4a40-a2e1-a2e42ef28c8a",
209 |             "1b92870d-e3b5-4e65-8153-919f4ff45592",
210 |             "## 09060124-b5e7-4717-9d07-3c046eb",
211 |             "6ff4173b-42a5-4784-9b19-f49caff4d93d",
212 |             "affc7dad-52dc-4b98-9b5d-51e65d8a8ad0",
213 |             "Microsoft entered the operating system (OS) business in 1980 with its own version of [Unix]",
214 |             'Microsoft was founded by [Bill Gates](/wiki/Bill_Gates "Bill Gates")',
215 |         ],
216 |         must_not_include=[],
217 |     ),
218 |     FileTestVector(
219 |         filename="test.epub",
220 |         mimetype="application/epub+zip",
221 |         charset=None,
222 |         url=None,
223 |         must_include=[
224 |             "**Authors:** Test Author",
225 |             "A test EPUB document for MarkItDown testing",
226 |             "# Chapter 1: Test Content",
227 |             "This is a **test** paragraph with some formatting",
228 |             "* A bullet point",
229 |             "* Another point",
230 |             "# Chapter 2: More Content",
231 |             "*different* style",
232 |             "> This is a blockquote for testing",
233 |         ],
234 |         must_not_include=[],
235 |     ),
236 | ]
237 | 
238 | 
239 | DATA_URI_TEST_VECTORS = [
240 |     FileTestVector(
241 |         filename="test.docx",
242 |         mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
243 |         charset=None,
244 |         url=None,
245 |         must_include=[
246 |             "314b0a30-5b04-470b-b9f7-eed2c2bec74a",
247 |             "49e168b7-d2ae-407f-a055-2167576f39a1",
248 |             "## d666f1f7-46cb-42bd-9a39-9a39cf2a509f",
249 |             "# Abstract",
250 |             "# Introduction",
251 |             "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation",
252 |             "data:image/png;base64,iVBORw0KGgoAAAANSU",
253 |         ],
254 |         must_not_include=[
255 |             "data:image/png;base64...",
256 |         ],
257 |     ),
258 |     FileTestVector(
259 |         filename="test.pptx",
260 |         mimetype="application/vnd.openxmlformats-officedocument.presentationml.presentation",
261 |         charset=None,
262 |         url=None,
263 |         must_include=[
264 |             "2cdda5c8-e50e-4db4-b5f0-9722a649f455",
265 |             "04191ea8-5c73-4215-a1d3-1cfb43aaaf12",
266 |             "44bf7d06-5e7a-4a40-a2e1-a2e42ef28c8a",
267 |             "1b92870d-e3b5-4e65-8153-919f4ff45592",
268 |             "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation",
269 |             "a3f6004b-6f4f-4ea8-bee3-3741f4dc385f",  # chart title
270 |             "2003",  # chart value
271 |             "![This phrase of the caption is Human-written.]",  # image caption
272 |             "data:image/jpeg;base64,/9j/4AAQSkZJRgABAQE",
273 |         ],
274 |         must_not_include=[
275 |             "![This phrase of the caption is Human-written.](Picture4.jpg)",
276 |         ],
277 |     ),
278 | ]
279 | 


--------------------------------------------------------------------------------
/packages/markitdown/tests/test_cli_misc.py:
--------------------------------------------------------------------------------
 1 | #!/usr/bin/env python3 -m pytest
 2 | import subprocess
 3 | import pytest
 4 | from markitdown import __version__
 5 | 
 6 | # This file contains CLI tests that are not directly tested by the FileTestVectors.
 7 | # This includes things like help messages, version numbers, and invalid flags.
 8 | 
 9 | 
10 | def test_version() -> None:
11 |     result = subprocess.run(
12 |         ["python", "-m", "markitdown", "--version"], capture_output=True, text=True
13 |     )
14 | 
15 |     assert result.returncode == 0, f"CLI exited with error: {result.stderr}"
16 |     assert __version__ in result.stdout, f"Version not found in output: {result.stdout}"
17 | 
18 | 
19 | def test_invalid_flag() -> None:
20 |     result = subprocess.run(
21 |         ["python", "-m", "markitdown", "--foobar"], capture_output=True, text=True
22 |     )
23 | 
24 |     assert result.returncode != 0, f"CLI exited with error: {result.stderr}"
25 |     assert (
26 |         "unrecognized arguments" in result.stderr
27 |     ), f"Expected 'unrecognized arguments' to appear in STDERR"
28 |     assert "SYNTAX" in result.stderr, f"Expected 'SYNTAX' to appear in STDERR"
29 | 
30 | 
31 | if __name__ == "__main__":
32 |     """Runs this file's tests from the command line."""
33 |     test_version()
34 |     test_invalid_flag()
35 |     print("All tests passed!")
36 | 


--------------------------------------------------------------------------------
/packages/markitdown/tests/test_cli_vectors.py:
--------------------------------------------------------------------------------
  1 | #!/usr/bin/env python3 -m pytest
  2 | import os
  3 | import time
  4 | import pytest
  5 | import subprocess
  6 | import locale
  7 | from typing import List
  8 | 
  9 | if __name__ == "__main__":
 10 |     from _test_vectors import (
 11 |         GENERAL_TEST_VECTORS,
 12 |         DATA_URI_TEST_VECTORS,
 13 |         FileTestVector,
 14 |     )
 15 | else:
 16 |     from ._test_vectors import (
 17 |         GENERAL_TEST_VECTORS,
 18 |         DATA_URI_TEST_VECTORS,
 19 |         FileTestVector,
 20 |     )
 21 | 
 22 | from markitdown import (
 23 |     MarkItDown,
 24 |     UnsupportedFormatException,
 25 |     FileConversionException,
 26 |     StreamInfo,
 27 | )
 28 | 
 29 | skip_remote = (
 30 |     True if os.environ.get("GITHUB_ACTIONS") else False
 31 | )  # Don't run these tests in CI
 32 | 
 33 | TEST_FILES_DIR = os.path.join(os.path.dirname(__file__), "test_files")
 34 | TEST_FILES_URL = "https://raw.githubusercontent.com/microsoft/markitdown/refs/heads/main/packages/markitdown/tests/test_files"
 35 | 
 36 | 
 37 | # Prepare CLI test vectors (remove vectors that require mockig the url)
 38 | CLI_TEST_VECTORS: List[FileTestVector] = []
 39 | for test_vector in GENERAL_TEST_VECTORS:
 40 |     if test_vector.url is not None:
 41 |         continue
 42 |     CLI_TEST_VECTORS.append(test_vector)
 43 | 
 44 | 
 45 | @pytest.fixture(scope="session")
 46 | def shared_tmp_dir(tmp_path_factory):
 47 |     return tmp_path_factory.mktemp("pytest_tmp")
 48 | 
 49 | 
 50 | @pytest.mark.parametrize("test_vector", CLI_TEST_VECTORS)
 51 | def test_output_to_stdout(shared_tmp_dir, test_vector) -> None:
 52 |     """Test that the CLI outputs to stdout correctly."""
 53 | 
 54 |     result = subprocess.run(
 55 |         [
 56 |             "python",
 57 |             "-m",
 58 |             "markitdown",
 59 |             os.path.join(TEST_FILES_DIR, test_vector.filename),
 60 |         ],
 61 |         capture_output=True,
 62 |         text=True,
 63 |     )
 64 | 
 65 |     assert result.returncode == 0, f"CLI exited with error: {result.stderr}"
 66 |     for test_string in test_vector.must_include:
 67 |         assert test_string in result.stdout
 68 |     for test_string in test_vector.must_not_include:
 69 |         assert test_string not in result.stdout
 70 | 
 71 | 
 72 | @pytest.mark.parametrize("test_vector", CLI_TEST_VECTORS)
 73 | def test_output_to_file(shared_tmp_dir, test_vector) -> None:
 74 |     """Test that the CLI outputs to a file correctly."""
 75 | 
 76 |     output_file = os.path.join(shared_tmp_dir, test_vector.filename + ".output")
 77 |     result = subprocess.run(
 78 |         [
 79 |             "python",
 80 |             "-m",
 81 |             "markitdown",
 82 |             "-o",
 83 |             output_file,
 84 |             os.path.join(TEST_FILES_DIR, test_vector.filename),
 85 |         ],
 86 |         capture_output=True,
 87 |         text=True,
 88 |     )
 89 | 
 90 |     assert result.returncode == 0, f"CLI exited with error: {result.stderr}"
 91 |     assert os.path.exists(output_file), f"Output file not created: {output_file}"
 92 | 
 93 |     with open(output_file, "r") as f:
 94 |         output_data = f.read()
 95 |         for test_string in test_vector.must_include:
 96 |             assert test_string in output_data
 97 |         for test_string in test_vector.must_not_include:
 98 |             assert test_string not in output_data
 99 | 
100 |     os.remove(output_file)
101 |     assert not os.path.exists(output_file), f"Output file not deleted: {output_file}"
102 | 
103 | 
104 | @pytest.mark.parametrize("test_vector", CLI_TEST_VECTORS)
105 | def test_input_from_stdin_without_hints(shared_tmp_dir, test_vector) -> None:
106 |     """Test that the CLI readds from stdin correctly."""
107 | 
108 |     test_input = b""
109 |     with open(os.path.join(TEST_FILES_DIR, test_vector.filename), "rb") as stream:
110 |         test_input = stream.read()
111 | 
112 |     result = subprocess.run(
113 |         [
114 |             "python",
115 |             "-m",
116 |             "markitdown",
117 |             os.path.join(TEST_FILES_DIR, test_vector.filename),
118 |         ],
119 |         input=test_input,
120 |         capture_output=True,
121 |         text=False,
122 |     )
123 | 
124 |     stdout = result.stdout.decode(locale.getpreferredencoding())
125 |     assert (
126 |         result.returncode == 0
127 |     ), f"CLI exited with error: {result.stderr.decode('utf-8')}"
128 |     for test_string in test_vector.must_include:
129 |         assert test_string in stdout
130 |     for test_string in test_vector.must_not_include:
131 |         assert test_string not in stdout
132 | 
133 | 
134 | @pytest.mark.skipif(
135 |     skip_remote,
136 |     reason="do not run tests that query external urls",
137 | )
138 | @pytest.mark.parametrize("test_vector", CLI_TEST_VECTORS)
139 | def test_convert_url(shared_tmp_dir, test_vector):
140 |     """Test the conversion of a stream with no stream info."""
141 |     # Note: tmp_dir is not used here, but is needed to match the signature
142 | 
143 |     markitdown = MarkItDown()
144 | 
145 |     time.sleep(1)  # Ensure we don't hit rate limits
146 |     result = subprocess.run(
147 |         ["python", "-m", "markitdown", TEST_FILES_URL + "/" + test_vector.filename],
148 |         capture_output=True,
149 |         text=False,
150 |     )
151 | 
152 |     stdout = result.stdout.decode(locale.getpreferredencoding())
153 |     assert result.returncode == 0, f"CLI exited with error: {result.stderr}"
154 |     for test_string in test_vector.must_include:
155 |         assert test_string in stdout
156 |     for test_string in test_vector.must_not_include:
157 |         assert test_string not in stdout
158 | 
159 | 
160 | @pytest.mark.parametrize("test_vector", DATA_URI_TEST_VECTORS)
161 | def test_output_to_file_with_data_uris(shared_tmp_dir, test_vector) -> None:
162 |     """Test CLI functionality when keep_data_uris is enabled"""
163 | 
164 |     output_file = os.path.join(shared_tmp_dir, test_vector.filename + ".output")
165 |     result = subprocess.run(
166 |         [
167 |             "python",
168 |             "-m",
169 |             "markitdown",
170 |             "--keep-data-uris",
171 |             "-o",
172 |             output_file,
173 |             os.path.join(TEST_FILES_DIR, test_vector.filename),
174 |         ],
175 |         capture_output=True,
176 |         text=True,
177 |     )
178 | 
179 |     assert result.returncode == 0, f"CLI exited with error: {result.stderr}"
180 |     assert os.path.exists(output_file), f"Output file not created: {output_file}"
181 | 
182 |     with open(output_file, "r") as f:
183 |         output_data = f.read()
184 |         for test_string in test_vector.must_include:
185 |             assert test_string in output_data
186 |         for test_string in test_vector.must_not_include:
187 |             assert test_string not in output_data
188 | 
189 |     os.remove(output_file)
190 |     assert not os.path.exists(output_file), f"Output file not deleted: {output_file}"
191 | 
192 | 
193 | if __name__ == "__main__":
194 |     import sys
195 |     import tempfile
196 | 
197 |     """Runs this file's tests from the command line."""
198 | 
199 |     with tempfile.TemporaryDirectory() as tmp_dir:
200 |         # General tests
201 |         for test_function in [
202 |             test_output_to_stdout,
203 |             test_output_to_file,
204 |             test_input_from_stdin_without_hints,
205 |             test_convert_url,
206 |         ]:
207 |             for test_vector in CLI_TEST_VECTORS:
208 |                 print(
209 |                     f"Running {test_function.__name__} on {test_vector.filename}...",
210 |                     end="",
211 |                 )
212 |                 test_function(tmp_dir, test_vector)
213 |                 print("OK")
214 | 
215 |         # Data URI tests
216 |         for test_function in [
217 |             test_output_to_file_with_data_uris,
218 |         ]:
219 |             for test_vector in DATA_URI_TEST_VECTORS:
220 |                 print(
221 |                     f"Running {test_function.__name__} on {test_vector.filename}...",
222 |                     end="",
223 |                 )
224 |                 test_function(tmp_dir, test_vector)
225 |                 print("OK")
226 | 
227 |     print("All tests passed!")
228 | 


--------------------------------------------------------------------------------
/packages/markitdown/tests/test_files/equations.docx:
--------------------------------------------------------------------------------
https://raw.githubusercontent.com/microsoft/markitdown/3fcd48cdfc651cbf508071c8d2fb7d82aeb075de/packages/markitdown/tests/test_files/equations.docx


--------------------------------------------------------------------------------
/packages/markitdown/tests/test_files/random.bin:
--------------------------------------------------------------------------------
https://raw.githubusercontent.com/microsoft/markitdown/3fcd48cdfc651cbf508071c8d2fb7d82aeb075de/packages/markitdown/tests/test_files/random.bin


--------------------------------------------------------------------------------
/packages/markitdown/tests/test_files/test.docx:
--------------------------------------------------------------------------------
https://raw.githubusercontent.com/microsoft/markitdown/3fcd48cdfc651cbf508071c8d2fb7d82aeb075de/packages/markitdown/tests/test_files/test.docx


--------------------------------------------------------------------------------
/packages/markitdown/tests/test_files/test.epub:
--------------------------------------------------------------------------------
https://raw.githubusercontent.com/microsoft/markitdown/3fcd48cdfc651cbf508071c8d2fb7d82aeb075de/packages/markitdown/tests/test_files/test.epub


--------------------------------------------------------------------------------
/packages/markitdown/tests/test_files/test.jpg:
--------------------------------------------------------------------------------
https://raw.githubusercontent.com/microsoft/markitdown/3fcd48cdfc651cbf508071c8d2fb7d82aeb075de/packages/markitdown/tests/test_files/test.jpg


--------------------------------------------------------------------------------
/packages/markitdown/tests/test_files/test.json:
--------------------------------------------------------------------------------
 1 | {
 2 |     "key1": "string_value",
 3 |     "key2": 1234,
 4 |     "key3": [
 5 |         "list_value1",
 6 |         "list_value2"
 7 |     ],
 8 |     "5b64c88c-b3c3-4510-bcb8-da0b200602d8": "uuid_key",
 9 |     "uuid_value": "9700dc99-6685-40b4-9a3a-5e406dcb37f3"
10 | }
11 | 


--------------------------------------------------------------------------------
/packages/markitdown/tests/test_files/test.m4a:
--------------------------------------------------------------------------------
https://raw.githubusercontent.com/microsoft/markitdown/3fcd48cdfc651cbf508071c8d2fb7d82aeb075de/packages/markitdown/tests/test_files/test.m4a


--------------------------------------------------------------------------------
/packages/markitdown/tests/test_files/test.mp3:
--------------------------------------------------------------------------------
https://raw.githubusercontent.com/microsoft/markitdown/3fcd48cdfc651cbf508071c8d2fb7d82aeb075de/packages/markitdown/tests/test_files/test.mp3


--------------------------------------------------------------------------------
/packages/markitdown/tests/test_files/test.pdf:
--------------------------------------------------------------------------------
https://raw.githubusercontent.com/microsoft/markitdown/3fcd48cdfc651cbf508071c8d2fb7d82aeb075de/packages/markitdown/tests/test_files/test.pdf


--------------------------------------------------------------------------------
/packages/markitdown/tests/test_files/test.pptx:
--------------------------------------------------------------------------------
https://raw.githubusercontent.com/microsoft/markitdown/3fcd48cdfc651cbf508071c8d2fb7d82aeb075de/packages/markitdown/tests/test_files/test.pptx


--------------------------------------------------------------------------------
/packages/markitdown/tests/test_files/test.wav:
--------------------------------------------------------------------------------
https://raw.githubusercontent.com/microsoft/markitdown/3fcd48cdfc651cbf508071c8d2fb7d82aeb075de/packages/markitdown/tests/test_files/test.wav


--------------------------------------------------------------------------------
/packages/markitdown/tests/test_files/test.xls:
--------------------------------------------------------------------------------
https://raw.githubusercontent.com/microsoft/markitdown/3fcd48cdfc651cbf508071c8d2fb7d82aeb075de/packages/markitdown/tests/test_files/test.xls


--------------------------------------------------------------------------------
/packages/markitdown/tests/test_files/test.xlsx:
--------------------------------------------------------------------------------
https://raw.githubusercontent.com/microsoft/markitdown/3fcd48cdfc651cbf508071c8d2fb7d82aeb075de/packages/markitdown/tests/test_files/test.xlsx


--------------------------------------------------------------------------------
/packages/markitdown/tests/test_files/test_files.zip:
--------------------------------------------------------------------------------
https://raw.githubusercontent.com/microsoft/markitdown/3fcd48cdfc651cbf508071c8d2fb7d82aeb075de/packages/markitdown/tests/test_files/test_files.zip


--------------------------------------------------------------------------------
/packages/markitdown/tests/test_files/test_llm.jpg:
--------------------------------------------------------------------------------
https://raw.githubusercontent.com/microsoft/markitdown/3fcd48cdfc651cbf508071c8d2fb7d82aeb075de/packages/markitdown/tests/test_files/test_llm.jpg


--------------------------------------------------------------------------------
/packages/markitdown/tests/test_files/test_mskanji.csv:
--------------------------------------------------------------------------------
https://raw.githubusercontent.com/microsoft/markitdown/3fcd48cdfc651cbf508071c8d2fb7d82aeb075de/packages/markitdown/tests/test_files/test_mskanji.csv


--------------------------------------------------------------------------------
/packages/markitdown/tests/test_files/test_notebook.ipynb:
--------------------------------------------------------------------------------
 1 | {
 2 |  "cells": [
 3 |   {
 4 |    "cell_type": "markdown",
 5 |    "id": "0f61db80",
 6 |    "metadata": {},
 7 |    "source": [
 8 |     "# Test Notebook"
 9 |    ]
10 |   },
11 |   {
12 |    "cell_type": "code",
13 |    "execution_count": 11,
14 |    "id": "3f2a5bbd",
15 |    "metadata": {},
16 |    "outputs": [
17 |     {
18 |      "name": "stdout",
19 |      "output_type": "stream",
20 |      "text": [
21 |       "markitdown\n"
22 |      ]
23 |     }
24 |    ],
25 |    "source": [
26 |     "print(\"markitdown\")"
27 |    ]
28 |   },
29 |   {
30 |    "cell_type": "markdown",
31 |    "id": "9b9c0468",
32 |    "metadata": {},
33 |    "source": [
34 |     "## Code Cell Below"
35 |    ]
36 |   },
37 |   {
38 |    "cell_type": "code",
39 |    "execution_count": 10,
40 |    "id": "37d8088a",
41 |    "metadata": {},
42 |    "outputs": [
43 |     {
44 |      "name": "stdout",
45 |      "output_type": "stream",
46 |      "text": [
47 |       "42\n"
48 |      ]
49 |     }
50 |    ],
51 |    "source": [
52 |     "# comment in code\n",
53 |     "print(42)"
54 |    ]
55 |   },
56 |   {
57 |    "cell_type": "markdown",
58 |    "id": "2e3177bd",
59 |    "metadata": {},
60 |    "source": [
61 |     "End\n",
62 |     "\n",
63 |     "---"
64 |    ]
65 |   }
66 |  ],
67 |  "metadata": {
68 |   "kernelspec": {
69 |    "display_name": "Python 3",
70 |    "language": "python",
71 |    "name": "python3"
72 |   },
73 |   "language_info": {
74 |    "codemirror_mode": {
75 |     "name": "ipython",
76 |     "version": 3
77 |    },
78 |    "file_extension": ".py",
79 |    "mimetype": "text/x-python",
80 |    "name": "python",
81 |    "nbconvert_exporter": "python",
82 |    "pygments_lexer": "ipython3",
83 |    "version": "3.12.8"
84 |   },
85 |   "title": "Test Notebook Title"
86 |  },
87 |  "nbformat": 4,
88 |  "nbformat_minor": 5
89 | }
90 | 


--------------------------------------------------------------------------------
/packages/markitdown/tests/test_files/test_outlook_msg.msg:
--------------------------------------------------------------------------------
https://raw.githubusercontent.com/microsoft/markitdown/3fcd48cdfc651cbf508071c8d2fb7d82aeb075de/packages/markitdown/tests/test_files/test_outlook_msg.msg


--------------------------------------------------------------------------------
/packages/markitdown/tests/test_files/test_with_comment.docx:
--------------------------------------------------------------------------------
https://raw.githubusercontent.com/microsoft/markitdown/3fcd48cdfc651cbf508071c8d2fb7d82aeb075de/packages/markitdown/tests/test_files/test_with_comment.docx


--------------------------------------------------------------------------------
/packages/markitdown/tests/test_module_vectors.py:
--------------------------------------------------------------------------------
  1 | #!/usr/bin/env python3 -m pytest
  2 | import os
  3 | import time
  4 | import pytest
  5 | import codecs
  6 | import base64
  7 | 
  8 | from pathlib import Path
  9 | 
 10 | if __name__ == "__main__":
 11 |     from _test_vectors import GENERAL_TEST_VECTORS, DATA_URI_TEST_VECTORS
 12 | else:
 13 |     from ._test_vectors import GENERAL_TEST_VECTORS, DATA_URI_TEST_VECTORS
 14 | 
 15 | from markitdown import (
 16 |     MarkItDown,
 17 |     UnsupportedFormatException,
 18 |     FileConversionException,
 19 |     StreamInfo,
 20 | )
 21 | 
 22 | skip_remote = (
 23 |     True if os.environ.get("GITHUB_ACTIONS") else False
 24 | )  # Don't run these tests in CI
 25 | 
 26 | TEST_FILES_DIR = os.path.join(os.path.dirname(__file__), "test_files")
 27 | TEST_FILES_URL = "https://raw.githubusercontent.com/microsoft/markitdown/refs/heads/main/packages/markitdown/tests/test_files"
 28 | 
 29 | 
 30 | @pytest.mark.parametrize("test_vector", GENERAL_TEST_VECTORS)
 31 | def test_guess_stream_info(test_vector):
 32 |     """Test the ability to guess stream info."""
 33 |     markitdown = MarkItDown()
 34 | 
 35 |     local_path = os.path.join(TEST_FILES_DIR, test_vector.filename)
 36 |     expected_extension = os.path.splitext(test_vector.filename)[1]
 37 | 
 38 |     with open(local_path, "rb") as stream:
 39 |         guesses = markitdown._get_stream_info_guesses(
 40 |             stream,
 41 |             base_guess=StreamInfo(
 42 |                 filename=os.path.basename(test_vector.filename),
 43 |                 local_path=local_path,
 44 |                 extension=expected_extension,
 45 |             ),
 46 |         )
 47 | 
 48 |         # For some limited exceptions, we can't guarantee the exact
 49 |         # mimetype or extension, so we'll special-case them here.
 50 |         if test_vector.filename in [
 51 |             "test_outlook_msg.msg",
 52 |         ]:
 53 |             return
 54 | 
 55 |         assert guesses[0].mimetype == test_vector.mimetype
 56 |         assert guesses[0].extension == expected_extension
 57 |         assert guesses[0].charset == test_vector.charset
 58 | 
 59 | 
 60 | @pytest.mark.parametrize("test_vector", GENERAL_TEST_VECTORS)
 61 | def test_convert_local(test_vector):
 62 |     """Test the conversion of a local file."""
 63 |     markitdown = MarkItDown()
 64 | 
 65 |     result = markitdown.convert(
 66 |         os.path.join(TEST_FILES_DIR, test_vector.filename), url=test_vector.url
 67 |     )
 68 |     for string in test_vector.must_include:
 69 |         assert string in result.markdown
 70 |     for string in test_vector.must_not_include:
 71 |         assert string not in result.markdown
 72 | 
 73 | 
 74 | @pytest.mark.parametrize("test_vector", GENERAL_TEST_VECTORS)
 75 | def test_convert_stream_with_hints(test_vector):
 76 |     """Test the conversion of a stream with full stream info."""
 77 |     markitdown = MarkItDown()
 78 | 
 79 |     stream_info = StreamInfo(
 80 |         extension=os.path.splitext(test_vector.filename)[1],
 81 |         mimetype=test_vector.mimetype,
 82 |         charset=test_vector.charset,
 83 |     )
 84 | 
 85 |     with open(os.path.join(TEST_FILES_DIR, test_vector.filename), "rb") as stream:
 86 |         result = markitdown.convert(
 87 |             stream, stream_info=stream_info, url=test_vector.url
 88 |         )
 89 |         for string in test_vector.must_include:
 90 |             assert string in result.markdown
 91 |         for string in test_vector.must_not_include:
 92 |             assert string not in result.markdown
 93 | 
 94 | 
 95 | @pytest.mark.parametrize("test_vector", GENERAL_TEST_VECTORS)
 96 | def test_convert_stream_without_hints(test_vector):
 97 |     """Test the conversion of a stream with no stream info."""
 98 |     markitdown = MarkItDown()
 99 | 
100 |     with open(os.path.join(TEST_FILES_DIR, test_vector.filename), "rb") as stream:
101 |         result = markitdown.convert(stream, url=test_vector.url)
102 |         for string in test_vector.must_include:
103 |             assert string in result.markdown
104 |         for string in test_vector.must_not_include:
105 |             assert string not in result.markdown
106 | 
107 | 
108 | @pytest.mark.skipif(
109 |     skip_remote,
110 |     reason="do not run tests that query external urls",
111 | )
112 | @pytest.mark.parametrize("test_vector", GENERAL_TEST_VECTORS)
113 | def test_convert_http_uri(test_vector):
114 |     """Test the conversion of an HTTP:// or HTTPS:// URI."""
115 |     markitdown = MarkItDown()
116 | 
117 |     time.sleep(1)  # Ensure we don't hit rate limits
118 | 
119 |     result = markitdown.convert(
120 |         TEST_FILES_URL + "/" + test_vector.filename,
121 |         url=test_vector.url,  # Mock where this file would be found
122 |     )
123 |     for string in test_vector.must_include:
124 |         assert string in result.markdown
125 |     for string in test_vector.must_not_include:
126 |         assert string not in result.markdown
127 | 
128 | 
129 | @pytest.mark.parametrize("test_vector", GENERAL_TEST_VECTORS)
130 | def test_convert_file_uri(test_vector):
131 |     """Test the conversion of a file:// URI."""
132 |     markitdown = MarkItDown()
133 | 
134 |     result = markitdown.convert(
135 |         Path(os.path.join(TEST_FILES_DIR, test_vector.filename)).as_uri(),
136 |         url=test_vector.url,
137 |     )
138 |     for string in test_vector.must_include:
139 |         assert string in result.markdown
140 |     for string in test_vector.must_not_include:
141 |         assert string not in result.markdown
142 | 
143 | 
144 | @pytest.mark.parametrize("test_vector", GENERAL_TEST_VECTORS)
145 | def test_convert_data_uri(test_vector):
146 |     """Test the conversion of a data URI."""
147 |     markitdown = MarkItDown()
148 | 
149 |     data = ""
150 |     with open(os.path.join(TEST_FILES_DIR, test_vector.filename), "rb") as stream:
151 |         data = base64.b64encode(stream.read()).decode("utf-8")
152 |     mimetype = test_vector.mimetype
153 |     data_uri = f"data:{mimetype};base64,{data}"
154 | 
155 |     result = markitdown.convert(
156 |         data_uri,
157 |         url=test_vector.url,
158 |     )
159 |     for string in test_vector.must_include:
160 |         assert string in result.markdown
161 |     for string in test_vector.must_not_include:
162 |         assert string not in result.markdown
163 | 
164 | 
165 | @pytest.mark.parametrize("test_vector", DATA_URI_TEST_VECTORS)
166 | def test_convert_keep_data_uris(test_vector):
167 |     """Test API functionality when keep_data_uris is enabled"""
168 |     markitdown = MarkItDown()
169 | 
170 |     # Test local file conversion
171 |     result = markitdown.convert(
172 |         os.path.join(TEST_FILES_DIR, test_vector.filename),
173 |         keep_data_uris=True,
174 |         url=test_vector.url,
175 |     )
176 | 
177 |     for string in test_vector.must_include:
178 |         assert string in result.markdown
179 |     for string in test_vector.must_not_include:
180 |         assert string not in result.markdown
181 | 
182 | 
183 | @pytest.mark.parametrize("test_vector", DATA_URI_TEST_VECTORS)
184 | def test_convert_stream_keep_data_uris(test_vector):
185 |     """Test the conversion of a stream with no stream info."""
186 |     markitdown = MarkItDown()
187 | 
188 |     stream_info = StreamInfo(
189 |         extension=os.path.splitext(test_vector.filename)[1],
190 |         mimetype=test_vector.mimetype,
191 |         charset=test_vector.charset,
192 |     )
193 | 
194 |     with open(os.path.join(TEST_FILES_DIR, test_vector.filename), "rb") as stream:
195 |         result = markitdown.convert(
196 |             stream, stream_info=stream_info, keep_data_uris=True, url=test_vector.url
197 |         )
198 | 
199 |         for string in test_vector.must_include:
200 |             assert string in result.markdown
201 |         for string in test_vector.must_not_include:
202 |             assert string not in result.markdown
203 | 
204 | 
205 | if __name__ == "__main__":
206 |     import sys
207 | 
208 |     """Runs this file's tests from the command line."""
209 | 
210 |     # General tests
211 |     for test_function in [
212 |         test_guess_stream_info,
213 |         test_convert_local,
214 |         test_convert_stream_with_hints,
215 |         test_convert_stream_without_hints,
216 |         test_convert_http_uri,
217 |         test_convert_file_uri,
218 |         test_convert_data_uri,
219 |     ]:
220 |         for test_vector in GENERAL_TEST_VECTORS:
221 |             print(
222 |                 f"Running {test_function.__name__} on {test_vector.filename}...", end=""
223 |             )
224 |             test_function(test_vector)
225 |             print("OK")
226 | 
227 |     # Data URI tests
228 |     for test_function in [
229 |         test_convert_keep_data_uris,
230 |         test_convert_stream_keep_data_uris,
231 |     ]:
232 |         for test_vector in DATA_URI_TEST_VECTORS:
233 |             print(
234 |                 f"Running {test_function.__name__} on {test_vector.filename}...", end=""
235 |             )
236 |             test_function(test_vector)
237 |             print("OK")
238 | 
239 |     print("All tests passed!")
240 | 


--------------------------------------------------------------------------------
